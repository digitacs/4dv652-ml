{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aware-instrument",
   "metadata": {},
   "source": [
    "# Classify using start=0 mid = 1 end = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sunset-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-recruitment",
   "metadata": {},
   "source": [
    "## 1. Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suspended-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '../../datasets/marked_start_mid_end/'\n",
    "suffix = '.csv'\n",
    "\n",
    "def read_from_file( file_name, rand_num):\n",
    "    \n",
    "    try:\n",
    "        full_file_name = file_name + str(rand_num)\n",
    "\n",
    "        file_at_path = dirname + full_file_name + suffix\n",
    "\n",
    "        data = pd.read_csv(file_at_path)\n",
    "        data = data.drop( columns=['FrameNo'] )\n",
    "\n",
    "        #target_labels = [col for col in data.columns if '_z' in col]\n",
    "        target_labels = ['status']\n",
    "        \n",
    "        target_data = data[target_labels]\n",
    "        input_data = data.drop(columns=target_labels)\n",
    "\n",
    "        return input_data, target_data, full_file_name\n",
    "    \n",
    "    except IOError as e:\n",
    "        print(e)\n",
    "        return None,None,None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-savage",
   "metadata": {},
   "source": [
    "## 2. Read files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-timing",
   "metadata": {},
   "source": [
    "### 2.1 The A series (A1-A159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consolidated-victoria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229, 26)\n",
      "(229, 1)\n",
      "[Errno 2] No such file or directory: '../../datasets/marked_start_mid_end/A60.csv'\n",
      "[Errno 2] No such file or directory: '../../datasets/marked_start_mid_end/A107.csv'\n",
      "(33093, 26)\n",
      "(33093, 1)\n"
     ]
    }
   ],
   "source": [
    "X, y, full_file_name = read_from_file(\"A\", 1)\n",
    "\n",
    "#print(full_file_name)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "for i in range(2,160):\n",
    "    input_data, target_data, full_file_name = read_from_file(\"A\", i)\n",
    "    \n",
    "    if(full_file_name is None):\n",
    "        continue\n",
    "    else:\n",
    "        #print(full_file_name)\n",
    "        X = X.append(input_data, ignore_index = True)\n",
    "        y = y.append(target_data, ignore_index = True)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-graph",
   "metadata": {},
   "source": [
    "### 2.2 The B series (B1-B22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reserved-victoria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38488, 26)\n",
      "(38488, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,23):\n",
    "    input_data, target_data, full_file_name = read_from_file(\"B\", i)\n",
    "    \n",
    "    if(full_file_name is None):\n",
    "        continue\n",
    "    else:\n",
    "        #print(full_file_name)\n",
    "        X = X.append(input_data, ignore_index = True)\n",
    "        y = y.append(target_data, ignore_index = True)\n",
    "        \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "representative-savings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8108\n",
      "23233\n",
      "7147\n"
     ]
    }
   ],
   "source": [
    "start_0, mid_1, end_2 = np.bincount(y['status'])\n",
    "print(start_0)\n",
    "print(mid_1)\n",
    "print(end_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moving-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import shuffle\n",
    "#X, y = shuffle(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fixed-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y_train, y_test, X_train, X_test  = train_test_split(y, X, train_size = 0.8, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-storm",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Normalize the input features using the sklearn StandardScaler. This will set the mean to 0 and standard deviation to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legitimate-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adapted-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "front-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mediterranean-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense( units=26, input_dim=X_train.shape[-1], activation='relu' ),\n",
    "        keras.layers.Dense( units=64, activation='relu' ),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense( units=1, activation='sigmoid',bias_initializer=output_bias)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "controlled-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_prc', verbose=1,patience=10,mode='max',restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "intensive-oasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1728      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,495\n",
      "Trainable params: 2,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "olympic-investigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.799633  ],\n",
       "       [0.75626415],\n",
       "       [0.75695443],\n",
       "       [0.79063326],\n",
       "       [0.7957703 ],\n",
       "       [0.82468104],\n",
       "       [0.7897667 ],\n",
       "       [0.7740098 ],\n",
       "       [0.77953386],\n",
       "       [0.78608716]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "weighted-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5880\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
