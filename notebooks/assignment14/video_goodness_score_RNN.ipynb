{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advised-donor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# MLflow dashboard\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://35.228.45.76:5000')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='../../keys/mlflow-312506-8cfad529f4fd.json'\n",
    "\n",
    "# Import data augmentation\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from augmentation.methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consistent-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "everyday-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 47\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dying-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices( 'GPU' )\n",
    "print( 'Num GPUs Available: ', len( physical_devices ) )\n",
    "if len( physical_devices ) > 0:\n",
    "    tf.config.experimental.set_memory_growth( physical_devices[0], True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-dryer",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "## 1.1 Load the Posenet files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "general-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../datasets/'\n",
    "files = [\n",
    "    'posenet_scored_all_1.csv',\n",
    "    'posenet_scored_all_2.csv',\n",
    "    'posenet_scored_all_3.csv',\n",
    "    'posenet_scored_all_4.csv',\n",
    "]\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "french-campus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225092, 54)\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    try:\n",
    "        dataset = pd.read_csv(data_path + file)\n",
    "\n",
    "        if df is None:\n",
    "            df = dataset\n",
    "        else:\n",
    "            df = df.append(dataset, ignore_index=True)  \n",
    "\n",
    "    except IOError as e:\n",
    "        print('Error in reading file: ', e)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eastern-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['ConfidenceScore', 'GoodnessScore'])\n",
    "y = df[['ConfidenceScore', 'GoodnessScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beginning-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "classified-russia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (202582, 2)\n",
      "Test labels shape: (22510, 2) \n",
      "\n",
      "Training features shape: (202582, 52)\n",
      "Test features shape: (22510, 52)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "print('Training labels shape:', y_train.shape)\n",
    "print('Test labels shape:', y_test.shape, '\\n')\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Test features shape:', X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
