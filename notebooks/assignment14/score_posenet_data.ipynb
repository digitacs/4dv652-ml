{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "viral-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-round",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "demographic-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset_path = '../../datasets/posenet-uncut/'\n",
    "ugly_dataset_path = '../../datasets/good_ugly_posenet/'\n",
    "subjective_score = pd.read_csv('../../datasets/VideoScoring.csv')\n",
    "\n",
    "all_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "forced-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_scores(file_name,ugly=False):\n",
    "    path = normal_dataset_path\n",
    "    prefix = ''\n",
    "    \n",
    "    if ugly:\n",
    "        path = ugly_dataset_path\n",
    "        prefix = 'U' \n",
    "        \n",
    "    df = pd.read_csv(path+file_name)\n",
    "    df['ConfidenceScore'] = df[list(df.filter(regex='_score'))].mean(axis=1) * df['score']\n",
    "    sub_score = subjective_score.loc[subjective_score['FileName'] == prefix + file_name.replace('.csv', '')]['AVG']\n",
    "    df['GoodnessScore'] = int(sub_score)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-double",
   "metadata": {},
   "source": [
    "## Add Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "composed-cholesterol",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add scores to the original videos\n",
    "for file in os.listdir(normal_dataset_path):\n",
    "    if not file.find(\".csv\",0) == -1:\n",
    "        df = add_scores(file,False)\n",
    "        \n",
    "        if all_data is None:\n",
    "            all_data = df\n",
    "        else:\n",
    "            all_data = all_data.append(df, ignore_index=True)  \n",
    "\n",
    "# Add scores to augmented videos\n",
    "for file in os.listdir(ugly_dataset_path):\n",
    "    if not file.find(\".csv\",0) == -1:\n",
    "        df = add_scores(file,True)\n",
    "        \n",
    "        if all_data is None:\n",
    "            all_data = df\n",
    "        else:\n",
    "            all_data = all_data.append(df, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-interim",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "infinite-classics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dataset with 225092 has been saved in /datasets/posenet_scored_all.csv\n"
     ]
    }
   ],
   "source": [
    "slice_size = 4\n",
    "cut_size = int(len(all_data) / slice_size)\n",
    "q = 0\n",
    "\n",
    "for i in range(slice_size):\n",
    "    temp = all_data.loc[cut_size*i:cut_size*(i+1)-1,:]\n",
    "    temp.to_csv('../../datasets/posenet_scored_all_{}.csv'.format(i+1), index=False)\n",
    "    \n",
    "    \n",
    "print('A dataset with {} has been saved in /datasets/posenet_scored_all.csv'.format(len(all_data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
