{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Model for Kinect data\n",
    "\n",
    "\n",
    "## Section for Configurations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tempfile\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow import keras\n",
    "\n",
    "# MLflow dashboard\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://35.228.45.76:5000')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='../../keys/mlflow-312506-8cfad529f4fd.json'\n",
    "\n",
    "# Import data augmentation\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from augmentation.methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 47\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Prepared Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../datasets/exercise_score/'\n",
    "train_files = [\n",
    "    'kinect_train_dataset_1.csv',\n",
    "    'kinect_train_dataset_2.csv',\n",
    "    'kinect_train_dataset_3.csv',\n",
    "    'kinect_train_dataset_4.csv',\n",
    "    'kinect_train_dataset_5.csv',\n",
    "]\n",
    "\n",
    "test_files = [\n",
    "    'kinect_test_dataset_1.csv',\n",
    "    'kinect_test_dataset_2.csv',\n",
    "    'kinect_test_dataset_3.csv',\n",
    "]\n",
    "df_train = None\n",
    "df_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895495, 40) \n",
      "\n",
      "     head_x   head_y    head_z  left_shoulder_x  left_shoulder_y  \\\n",
      "0  0.014747  0.75019  0.018200         -0.15129          0.45769   \n",
      "1  0.014747  0.75019  0.018200         -0.15129          0.45769   \n",
      "2  0.014747  0.75019  0.018200         -0.15129          0.45769   \n",
      "3  0.014747  0.75019  0.018200         -0.15129          0.45769   \n",
      "4  0.015055  0.75015  0.018535         -0.15084          0.45749   \n",
      "\n",
      "   left_shoulder_z  left_elbow_x  left_elbow_y  left_elbow_z  \\\n",
      "0         0.016585      -0.18173       0.19971      0.034093   \n",
      "1         0.016585      -0.18173       0.19971      0.034093   \n",
      "2         0.016585      -0.18173       0.19971      0.034093   \n",
      "3         0.016585      -0.18173       0.19971      0.034093   \n",
      "4         0.017340      -0.18173       0.19967      0.034144   \n",
      "\n",
      "   right_shoulder_x  ...  right_knee_x  right_knee_y  right_knee_z  \\\n",
      "0           0.16628  ...       0.12415      -0.41084     -0.025178   \n",
      "1           0.16628  ...       0.12415      -0.41084     -0.025178   \n",
      "2           0.16628  ...       0.12415      -0.41084     -0.025178   \n",
      "3           0.16628  ...       0.12415      -0.41084     -0.025178   \n",
      "4           0.16665  ...       0.12431      -0.41098     -0.025021   \n",
      "\n",
      "   left_foot_x  left_foot_y  left_foot_z  right_foot_x  right_foot_y  \\\n",
      "0     -0.12549     -0.74586    -0.037080       0.13581      -0.75529   \n",
      "1     -0.12549     -0.74586    -0.037080       0.13581      -0.75529   \n",
      "2     -0.12549     -0.74586    -0.037080       0.13581      -0.75529   \n",
      "3     -0.12549     -0.74586    -0.037080       0.13581      -0.75529   \n",
      "4     -0.12539     -0.74513    -0.037584       0.13578      -0.75527   \n",
      "\n",
      "   right_foot_z  ExreciseScore  \n",
      "0     -0.049814       3.651582  \n",
      "1     -0.049814       3.651582  \n",
      "2     -0.049814       3.651582  \n",
      "3     -0.049814       3.651582  \n",
      "4     -0.049818       3.651582  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "for file in train_files:\n",
    "    try:\n",
    "        dataset_train = pd.read_csv(data_path + file)\n",
    "        if df_train is None:\n",
    "            df_train = dataset_train\n",
    "        else:\n",
    "            df_train = df_train.append(dataset_train, ignore_index=True)  \n",
    "    except IOError as e:\n",
    "        print('Error in reading file: ', e)\n",
    "print(df_train.shape, '\\n')\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106134, 40) \n",
      "\n",
      "     head_x   head_y    head_z  left_shoulder_x  left_shoulder_y  \\\n",
      "0 -0.000956  0.70872  0.004201         -0.17179          0.48246   \n",
      "1 -0.000956  0.70872  0.004201         -0.17179          0.48246   \n",
      "2 -0.000956  0.70872  0.004201         -0.17179          0.48246   \n",
      "3 -0.000956  0.70872  0.004201         -0.17179          0.48246   \n",
      "4 -0.000983  0.70887  0.004283         -0.17177          0.48234   \n",
      "\n",
      "   left_shoulder_z  left_elbow_x  left_elbow_y  left_elbow_z  \\\n",
      "0         0.037272      -0.35875       0.62571      0.059937   \n",
      "1         0.037272      -0.35875       0.62571      0.059937   \n",
      "2         0.037272      -0.35875       0.62571      0.059937   \n",
      "3         0.037272      -0.35875       0.62571      0.059937   \n",
      "4         0.035379      -0.35855       0.62601      0.059772   \n",
      "\n",
      "   right_shoulder_x  ...  right_knee_x  right_knee_y  right_knee_z  \\\n",
      "0           0.15655  ...       0.11736      -0.45209     -0.018903   \n",
      "1           0.15655  ...       0.11736      -0.45209     -0.018903   \n",
      "2           0.15655  ...       0.11736      -0.45209     -0.018903   \n",
      "3           0.15655  ...       0.11736      -0.45209     -0.018903   \n",
      "4           0.15662  ...       0.11734      -0.45216     -0.018948   \n",
      "\n",
      "   left_foot_x  left_foot_y  left_foot_z  right_foot_x  right_foot_y  \\\n",
      "0     -0.12115     -0.78793    -0.036693       0.13131      -0.79743   \n",
      "1     -0.12115     -0.78793    -0.036693       0.13131      -0.79743   \n",
      "2     -0.12115     -0.78793    -0.036693       0.13131      -0.79743   \n",
      "3     -0.12115     -0.78793    -0.036693       0.13131      -0.79743   \n",
      "4     -0.12123     -0.78945    -0.038249       0.13133      -0.79743   \n",
      "\n",
      "   right_foot_z  ExreciseScore  \n",
      "0     -0.045202       3.735287  \n",
      "1     -0.045202       3.735287  \n",
      "2     -0.045202       3.735287  \n",
      "3     -0.045202       3.735287  \n",
      "4     -0.045186       3.735287  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "for file in test_files:\n",
    "    try:\n",
    "        dataset_test = pd.read_csv(data_path + file)\n",
    "        if df_test is None:\n",
    "            df_test = dataset_test\n",
    "        else:\n",
    "            df_test = df_test.append(dataset_test, ignore_index=True)  \n",
    "    except IOError as e:\n",
    "        print('Error in reading file: ', e)\n",
    "print(df_test.shape, '\\n')\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['ExreciseScore'])\n",
    "y_train = df_train[['ExreciseScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=['ExreciseScore'])\n",
    "y_test = df_test[['ExreciseScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12985349,  0.76834911,  0.41129358, ...,  0.80660346,\n",
       "        -0.31175237, -0.03609619],\n",
       "       [ 0.12985349,  0.76834911,  0.41129358, ...,  0.80660346,\n",
       "        -0.31175237, -0.03609619],\n",
       "       [ 0.12985349,  0.76834911,  0.41129358, ...,  0.80660346,\n",
       "        -0.31175237, -0.03609619],\n",
       "       ...,\n",
       "       [-2.49810947, -0.48774584, -1.81067614, ..., -1.48957967,\n",
       "         0.85921328, -1.70529331],\n",
       "       [-2.49989261, -0.48802301, -1.811214  , ..., -1.4914728 ,\n",
       "         0.85917697, -1.70238976],\n",
       "       [-2.49989261, -0.48802301, -1.811214  , ..., -1.4914728 ,\n",
       "         0.85917697, -1.70238976]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mean_train = X_train.mean()\n",
    "input_std_train = X_train.std()\n",
    "\n",
    "X_train = (X_train - input_mean_train) / input_std_train\n",
    "\n",
    "X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00896688,  0.61916997,  0.30675028, ...,  0.84583339,\n",
       "        -0.49666032, -0.05300222],\n",
       "       [-0.00896688,  0.61916997,  0.30675028, ...,  0.84583339,\n",
       "        -0.49666032, -0.05300222],\n",
       "       [-0.00896688,  0.61916997,  0.30675028, ...,  0.84583339,\n",
       "        -0.49666032, -0.05300222],\n",
       "       ...,\n",
       "       [ 0.19849536, -0.49376604,  0.2378672 , ..., -0.32632686,\n",
       "         0.72065229,  0.46261344],\n",
       "       [ 0.19849536, -0.49376604,  0.2378672 , ..., -0.32632686,\n",
       "         0.72065229,  0.46261344],\n",
       "       [ 0.19655651, -0.49385467,  0.23743938, ..., -0.32581958,\n",
       "         0.72061446,  0.46183837]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_mean_test = X_test.mean()\n",
    "input_std_test = X_test.std()\n",
    "\n",
    "X_test = (X_test - input_mean_test) / input_std_test\n",
    "\n",
    "X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50825937],\n",
       "       [ 0.50825937],\n",
       "       [ 0.50825937],\n",
       "       ...,\n",
       "       [-2.12138077],\n",
       "       [-2.12138077],\n",
       "       [-2.12138077]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_mean_train = y_train.mean()\n",
    "output_std_train = y_train.std()\n",
    "\n",
    "y_train = (y_train - output_mean_train) / output_std_train\n",
    "\n",
    "y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (895495, 39)\n",
      "Training labels shape: (895495, 1) \n",
      "\n",
      "Test features shape: (106134, 39)\n",
      "Test labels shape: (106134, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training features shape:', X_train.shape)\n",
    "print('Training labels shape:', y_train.shape, '\\n')\n",
    "\n",
    "print('Test features shape:', X_test.shape)\n",
    "print('Test labels shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the Model\n",
    "\n",
    "### 3.1 Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "BATCH_SIZE = 150\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "output_size = 1\n",
    "\n",
    "activation = 'relu'\n",
    "#kernel_initializer = 'he_uniform'\n",
    "kernel_initializer = 'normal'\n",
    "#output_activation = 'sigmoid'\n",
    "output_activation = 'linear'\n",
    "\n",
    "#optimizer = 'SGD'\n",
    "#optimizer = 'RMSprop'\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "\n",
    "METRICS = [\n",
    "    MeanSquaredError(name=\"mse\", dtype=None),\n",
    "    MeanAbsoluteError(name=\"mae\", dtype=None),\n",
    "    RootMeanSquaredError(name=\"rmse\", dtype=None),\n",
    "]\n",
    "\n",
    "def make_model(input_dim, loss, optimizer, learning_rate=0.001, metrics=METRICS):\n",
    "    #MODEL 3 - Champ\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dim, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    model.add(Dense(64, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    model.add(Dense(64, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    model.add(Dense(output_size, activation=output_activation))\n",
    "    #http://35.228.45.76:5000/#/experiments/0/runs/0b6786ed5d8f4860a817b4d514aa4de5\n",
    "    \n",
    "    #MODEL 2\n",
    "    #model.add(Dense(128, input_dim=input_dim, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    #model.add(Dense(64, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    #model.add(Dense(32, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    #model.add(Dense(8, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    #model.add(Dense(output_size, activation=output_activation))\n",
    "    #http://35.228.45.76:5000/#/experiments/0/runs/12172f32a5d64cbfbd906c9d486cb90e\n",
    "    \n",
    "    #MODEL 1\n",
    "    #model.add(Dense(64, input_dim=input_dim, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    #model.add(Dense(64, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    #model.add(Dense(32, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    #model.add(Dense(8, kernel_initializer=kernel_initializer, activation=activation))\n",
    "    #model.add(Dense(output_size, activation=output_activation))\n",
    "    #http://35.228.45.76:5000/#/experiments/0/runs/b7f73a3ba8944e139b5280c0e13cf505\n",
    "    \n",
    "    \n",
    "    optimizer = tf.keras.optimizers.get(optimizer)\n",
    "    optimizer.learning_rate.assign(learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=metrics)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MLflow Experimentation\n",
    "\n",
    "### 4.1 Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "input_schema = Schema([\n",
    "    ColSpec(\"double\", \"head_x\"),\n",
    "    ColSpec(\"double\", \"head_y\"),\n",
    "    ColSpec(\"double\", \"head_z\"),\n",
    "    ColSpec(\"double\", \"left_shoulder_x\"),\n",
    "    ColSpec(\"double\", \"left_shoulder_y\"),\n",
    "    ColSpec(\"double\", \"left_shoulder_z\"),\n",
    "    ColSpec(\"double\", \"left_elbow_x\"),\n",
    "    ColSpec(\"double\", \"left_elbow_y\"),\n",
    "    ColSpec(\"double\", \"left_elbow_z\"),\n",
    "    ColSpec(\"double\", \"right_shoulder_x\"),\n",
    "    ColSpec(\"double\", \"right_shoulder_y\"),\n",
    "    ColSpec(\"double\", \"right_shoulder_z\"),\n",
    "    ColSpec(\"double\", \"right_elbow_x\"),\n",
    "    ColSpec(\"double\", \"right_elbow_y\"),\n",
    "    ColSpec(\"double\", \"right_elbow_z\"),\n",
    "    ColSpec(\"double\", \"left_hand_x\"),\n",
    "    ColSpec(\"double\", \"left_hand_y\"),\n",
    "    ColSpec(\"double\", \"left_hand_z\"),\n",
    "    ColSpec(\"double\", \"right_hand_x\"),\n",
    "    ColSpec(\"double\", \"right_hand_y\"),\n",
    "    ColSpec(\"double\", \"right_hand_z\"),\n",
    "    ColSpec(\"double\", \"left_hip_x\"),\n",
    "    ColSpec(\"double\", \"left_hip_y\"),\n",
    "    ColSpec(\"double\", \"left_hip_z\"),\n",
    "    ColSpec(\"double\", \"right_hip_x\"),\n",
    "    ColSpec(\"double\", \"right_hip_y\"),\n",
    "    ColSpec(\"double\", \"right_hip_z\"),\n",
    "    ColSpec(\"double\", \"left_knee_x\"),\n",
    "    ColSpec(\"double\", \"left_knee_y\"),\n",
    "    ColSpec(\"double\", \"left_knee_z\"),\n",
    "    ColSpec(\"double\", \"right_knee_x\"),\n",
    "    ColSpec(\"double\", \"right_knee_y\"),\n",
    "    ColSpec(\"double\", \"right_knee_z\"),\n",
    "    ColSpec(\"double\", \"left_foot_x\"),\n",
    "    ColSpec(\"double\", \"left_foot_y\"),\n",
    "    ColSpec(\"double\", \"left_foot_z\"),\n",
    "    ColSpec(\"double\", \"right_foot_x\"),\n",
    "    ColSpec(\"double\", \"right_foot_y\"),\n",
    "    ColSpec(\"double\", \"right_foot_z\"),\n",
    "])\n",
    "output_schema = Schema([\n",
    "    ColSpec(\"double\", \"ExreciseScore\"),\n",
    "])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "def plot_train_history(history, title):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    msa = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    variance = explained_variance_score(actual, pred)\n",
    "    return mse, msa, r2, variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Start Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               5120      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,601\n",
      "Trainable params: 17,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.3878 - mse: 0.3878 - mae: 0.4636 - rmse: 0.6136 - val_loss: 0.1526 - val_mse: 0.1526 - val_mae: 0.2700 - val_rmse: 0.3906\n",
      "Epoch 2/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.1231 - mse: 0.1231 - mae: 0.2316 - rmse: 0.3508 - val_loss: 0.1135 - val_mse: 0.1135 - val_mae: 0.2218 - val_rmse: 0.3368\n",
      "Epoch 3/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0900 - mse: 0.0900 - mae: 0.1891 - rmse: 0.2999 - val_loss: 0.0879 - val_mse: 0.0879 - val_mae: 0.1857 - val_rmse: 0.2964\n",
      "Epoch 4/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0708 - mse: 0.0708 - mae: 0.1621 - rmse: 0.2661 - val_loss: 0.0751 - val_mse: 0.0751 - val_mae: 0.1683 - val_rmse: 0.2740\n",
      "Epoch 5/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0602 - mse: 0.0602 - mae: 0.1473 - rmse: 0.2453 - val_loss: 0.0888 - val_mse: 0.0888 - val_mae: 0.1845 - val_rmse: 0.2980\n",
      "Epoch 6/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0533 - mse: 0.0533 - mae: 0.1362 - rmse: 0.2309 - val_loss: 0.0543 - val_mse: 0.0543 - val_mae: 0.1458 - val_rmse: 0.2331\n",
      "Epoch 7/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1280 - rmse: 0.2200 - val_loss: 0.0475 - val_mse: 0.0475 - val_mae: 0.1346 - val_rmse: 0.2181\n",
      "Epoch 8/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0441 - mse: 0.0441 - mae: 0.1210 - rmse: 0.2100 - val_loss: 0.0400 - val_mse: 0.0400 - val_mae: 0.1214 - val_rmse: 0.1999\n",
      "Epoch 9/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0399 - mse: 0.0399 - mae: 0.1133 - rmse: 0.1998 - val_loss: 0.0403 - val_mse: 0.0403 - val_mae: 0.1246 - val_rmse: 0.2008\n",
      "Epoch 10/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0368 - mse: 0.0368 - mae: 0.1084 - rmse: 0.1917 - val_loss: 0.0375 - val_mse: 0.0375 - val_mae: 0.1177 - val_rmse: 0.1938\n",
      "Epoch 11/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0355 - mse: 0.0355 - mae: 0.1056 - rmse: 0.1883 - val_loss: 0.0417 - val_mse: 0.0417 - val_mae: 0.1245 - val_rmse: 0.2042\n",
      "Epoch 12/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0330 - mse: 0.0330 - mae: 0.1014 - rmse: 0.1817 - val_loss: 0.0479 - val_mse: 0.0479 - val_mae: 0.1261 - val_rmse: 0.2189\n",
      "Epoch 13/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0320 - mse: 0.0320 - mae: 0.1000 - rmse: 0.1789 - val_loss: 0.0290 - val_mse: 0.0290 - val_mae: 0.1040 - val_rmse: 0.1704\n",
      "Epoch 14/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0304 - mse: 0.0304 - mae: 0.0961 - rmse: 0.1742 - val_loss: 0.0293 - val_mse: 0.0293 - val_mae: 0.1034 - val_rmse: 0.1711\n",
      "Epoch 15/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0297 - mse: 0.0297 - mae: 0.0940 - rmse: 0.1721 - val_loss: 0.0279 - val_mse: 0.0279 - val_mae: 0.0987 - val_rmse: 0.1670\n",
      "Epoch 16/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0268 - mse: 0.0268 - mae: 0.0900 - rmse: 0.1636 - val_loss: 0.0274 - val_mse: 0.0274 - val_mae: 0.0987 - val_rmse: 0.1656\n",
      "Epoch 17/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0256 - mse: 0.0256 - mae: 0.0874 - rmse: 0.1599 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.0886 - val_rmse: 0.1482\n",
      "Epoch 18/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0239 - mse: 0.0239 - mae: 0.0848 - rmse: 0.1545 - val_loss: 0.0280 - val_mse: 0.0280 - val_mae: 0.0981 - val_rmse: 0.1674\n",
      "Epoch 19/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0233 - mse: 0.0233 - mae: 0.0837 - rmse: 0.1525 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.0879 - val_rmse: 0.1466\n",
      "Epoch 20/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0229 - mse: 0.0229 - mae: 0.0818 - rmse: 0.1513 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.0916 - val_rmse: 0.1526\n",
      "Epoch 21/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0218 - mse: 0.0218 - mae: 0.0801 - rmse: 0.1476 - val_loss: 0.0352 - val_mse: 0.0352 - val_mae: 0.1089 - val_rmse: 0.1877\n",
      "Epoch 22/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0209 - mse: 0.0209 - mae: 0.0787 - rmse: 0.1447 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.0907 - val_rmse: 0.1517\n",
      "Epoch 23/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0231 - mse: 0.0231 - mae: 0.0804 - rmse: 0.1519 - val_loss: 0.0298 - val_mse: 0.0298 - val_mae: 0.1011 - val_rmse: 0.1725\n",
      "Epoch 24/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0188 - mse: 0.0188 - mae: 0.0744 - rmse: 0.1369 - val_loss: 0.0281 - val_mse: 0.0281 - val_mae: 0.0942 - val_rmse: 0.1677\n",
      "Epoch 25/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0225 - mse: 0.0225 - mae: 0.0793 - rmse: 0.1499 - val_loss: 0.0241 - val_mse: 0.0241 - val_mae: 0.0905 - val_rmse: 0.1553\n",
      "Epoch 26/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0201 - mse: 0.0201 - mae: 0.0750 - rmse: 0.1417 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0808 - val_rmse: 0.1417\n",
      "Epoch 27/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0168 - mse: 0.0168 - mae: 0.0708 - rmse: 0.1293 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.0858 - val_rmse: 0.1527\n",
      "Epoch 28/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.0720 - rmse: 0.1322 - val_loss: 0.0347 - val_mse: 0.0347 - val_mae: 0.1063 - val_rmse: 0.1863\n",
      "Epoch 29/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0176 - mse: 0.0176 - mae: 0.0722 - rmse: 0.1324 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.0763 - val_rmse: 0.1275\n",
      "Epoch 30/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.0709 - rmse: 0.1324 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0767 - val_rmse: 0.1333\n",
      "Epoch 31/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0179 - mse: 0.0179 - mae: 0.0708 - rmse: 0.1337 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0738 - val_rmse: 0.1257\n",
      "Epoch 32/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0676 - rmse: 0.1268 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.0730 - val_rmse: 0.1274\n",
      "Epoch 33/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0148 - mse: 0.0148 - mae: 0.0659 - rmse: 0.1217 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0721 - val_rmse: 0.1236\n",
      "Epoch 34/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0676 - rmse: 0.1257 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0748 - val_rmse: 0.1270\n",
      "Epoch 35/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0664 - rmse: 0.1239 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0735 - val_rmse: 0.1228\n",
      "Epoch 36/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0149 - mse: 0.0149 - mae: 0.0660 - rmse: 0.1218 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0804 - val_rmse: 0.1327\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.0645 - rmse: 0.1191 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0763 - val_rmse: 0.1276\n",
      "Epoch 38/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0618 - rmse: 0.1132 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.0721 - val_rmse: 0.1344\n",
      "Epoch 39/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0618 - rmse: 0.1132 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0709 - val_rmse: 0.1160\n",
      "Epoch 40/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0621 - rmse: 0.1140 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0758 - val_rmse: 0.1255\n",
      "Epoch 41/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0604 - rmse: 0.1098 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0667 - val_rmse: 0.1062\n",
      "Epoch 42/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0625 - rmse: 0.1171 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0665 - val_rmse: 0.1168\n",
      "Epoch 43/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0611 - rmse: 0.1142 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0684 - val_rmse: 0.1160\n",
      "Epoch 44/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0581 - rmse: 0.1049 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0671 - val_rmse: 0.1094\n",
      "Epoch 45/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0575 - rmse: 0.1049 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0669 - val_rmse: 0.1118\n",
      "Epoch 46/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0614 - rmse: 0.1124 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0670 - val_rmse: 0.1104\n",
      "Epoch 47/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0562 - rmse: 0.1028 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0661 - val_rmse: 0.1129\n",
      "Epoch 48/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0575 - rmse: 0.1028 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0626 - val_rmse: 0.1021\n",
      "Epoch 49/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0560 - rmse: 0.1013 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0686 - val_rmse: 0.1100\n",
      "Epoch 50/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0594 - rmse: 0.1089 - val_loss: 0.0119 - val_mse: 0.0119 - val_mae: 0.0664 - val_rmse: 0.1090\n",
      "Epoch 51/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0579 - rmse: 0.1059 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0621 - val_rmse: 0.1036\n",
      "Epoch 52/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0557 - rmse: 0.0988 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0735 - val_rmse: 0.1228\n",
      "Epoch 53/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0531 - rmse: 0.0936 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0669 - val_rmse: 0.1150\n",
      "Epoch 54/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0542 - rmse: 0.0982 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0632 - val_rmse: 0.1066\n",
      "Epoch 55/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0560 - rmse: 0.1027 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0588 - val_rmse: 0.0954\n",
      "Epoch 56/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0542 - rmse: 0.0971 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0716 - val_rmse: 0.1193\n",
      "Epoch 57/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0540 - rmse: 0.0987 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.0780 - val_rmse: 0.1548\n",
      "Epoch 58/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0562 - rmse: 0.1018 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0624 - val_rmse: 0.1114\n",
      "Epoch 59/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0543 - rmse: 0.0982 - val_loss: 0.0078 - val_mse: 0.0078 - val_mae: 0.0584 - val_rmse: 0.0886\n",
      "Epoch 60/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0510 - rmse: 0.0898 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0648 - val_rmse: 0.1158\n",
      "Epoch 61/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0517 - rmse: 0.0933 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0594 - val_rmse: 0.0986\n",
      "Epoch 62/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0509 - rmse: 0.0896 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0642 - val_rmse: 0.1023\n",
      "Epoch 63/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0498 - rmse: 0.0880 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0698 - val_rmse: 0.1133\n",
      "Epoch 64/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0514 - rmse: 0.0900 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.0708 - val_rmse: 0.1453\n",
      "Epoch 65/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0546 - rmse: 0.1023 - val_loss: 0.0074 - val_mse: 0.0074 - val_mae: 0.0556 - val_rmse: 0.0861\n",
      "Epoch 66/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0484 - rmse: 0.0857 - val_loss: 0.0082 - val_mse: 0.0082 - val_mae: 0.0556 - val_rmse: 0.0908\n",
      "Epoch 67/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0523 - rmse: 0.0947 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0617 - val_rmse: 0.1077\n",
      "Epoch 68/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0514 - rmse: 0.0977 - val_loss: 0.0064 - val_mse: 0.0064 - val_mae: 0.0536 - val_rmse: 0.0800\n",
      "Epoch 69/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0481 - rmse: 0.0853 - val_loss: 0.0326 - val_mse: 0.0326 - val_mae: 0.0841 - val_rmse: 0.1804\n",
      "Epoch 70/500\n",
      "4776/4776 [==============================] - 5s 1ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0571 - rmse: 0.1100 - val_loss: 0.0080 - val_mse: 0.0080 - val_mae: 0.0592 - val_rmse: 0.0896\n",
      "Epoch 71/500\n",
      "4776/4776 [==============================] - 5s 1ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0479 - rmse: 0.0844 - val_loss: 0.0060 - val_mse: 0.0060 - val_mae: 0.0525 - val_rmse: 0.0775\n",
      "Epoch 72/500\n",
      "4776/4776 [==============================] - 5s 1ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0521 - rmse: 0.0965 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0618 - val_rmse: 0.1028\n",
      "Epoch 73/500\n",
      "4776/4776 [==============================] - 5s 1ms/step - loss: 0.0086 - mse: 0.0086 - mae: 0.0507 - rmse: 0.0925 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0621 - val_rmse: 0.0986\n",
      "Epoch 74/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0504 - rmse: 0.0906 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0657 - val_rmse: 0.1075\n",
      "Epoch 75/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0514 - rmse: 0.0926 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0575 - val_rmse: 0.0961\n",
      "Epoch 76/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0483 - rmse: 0.0884 - val_loss: 0.0069 - val_mse: 0.0069 - val_mae: 0.0547 - val_rmse: 0.0831\n",
      "Epoch 77/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0466 - rmse: 0.0808 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0600 - val_rmse: 0.0944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0497 - rmse: 0.0948 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0618 - val_rmse: 0.1046\n",
      "Epoch 79/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0467 - rmse: 0.0818 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0669 - val_rmse: 0.1269\n",
      "Epoch 80/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0469 - rmse: 0.0830 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0606 - val_rmse: 0.0914\n",
      "Epoch 81/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0471 - rmse: 0.0834 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0525 - val_rmse: 0.0767\n",
      "Epoch 82/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0478 - rmse: 0.0862 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0651 - val_rmse: 0.1226\n",
      "Epoch 83/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0497 - rmse: 0.0933 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0523 - val_rmse: 0.0786\n",
      "Epoch 84/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0480 - rmse: 0.0890 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0507 - val_rmse: 0.0739\n",
      "Epoch 85/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0491 - rmse: 0.0890 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0502 - val_rmse: 0.0738\n",
      "Epoch 86/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0454 - rmse: 0.0792 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0514 - val_rmse: 0.0752\n",
      "Epoch 87/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0538 - rmse: 0.1056 - val_loss: 0.0088 - val_mse: 0.0088 - val_mae: 0.0554 - val_rmse: 0.0936\n",
      "Epoch 88/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0472 - rmse: 0.0851 - val_loss: 0.0087 - val_mse: 0.0087 - val_mae: 0.0546 - val_rmse: 0.0932\n",
      "Epoch 89/500\n",
      "4776/4776 [==============================] - 5s 1ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0438 - rmse: 0.0756 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0592 - val_rmse: 0.0912\n",
      "Epoch 90/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0478 - rmse: 0.0848 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0518 - val_rmse: 0.0769\n",
      "Epoch 91/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0423 - rmse: 0.0696 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0533 - val_rmse: 0.0910\n",
      "Epoch 92/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0451 - rmse: 0.0809 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0499 - val_rmse: 0.0739\n",
      "Epoch 93/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0441 - rmse: 0.0794 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0490 - val_rmse: 0.0704\n",
      "Epoch 94/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0436 - rmse: 0.0760 - val_loss: 0.0054 - val_mse: 0.0054 - val_mae: 0.0518 - val_rmse: 0.0736\n",
      "Epoch 95/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0463 - rmse: 0.0841 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0514 - val_rmse: 0.0766\n",
      "Epoch 96/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0427 - rmse: 0.0738 - val_loss: 0.0083 - val_mse: 0.0083 - val_mae: 0.0574 - val_rmse: 0.0910\n",
      "Epoch 97/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0496 - rmse: 0.0913 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0637 - val_rmse: 0.1075\n",
      "Epoch 98/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0441 - rmse: 0.0761 - val_loss: 0.0066 - val_mse: 0.0066 - val_mae: 0.0529 - val_rmse: 0.0810\n",
      "Epoch 99/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0440 - rmse: 0.0778 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0634 - val_rmse: 0.1136\n",
      "Epoch 100/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0456 - rmse: 0.0824 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0489 - val_rmse: 0.0727\n",
      "Epoch 101/500\n",
      "4776/4776 [==============================] - 6s 1ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0400 - rmse: 0.0654 - val_loss: 0.0055 - val_mse: 0.0055 - val_mae: 0.0517 - val_rmse: 0.0742\n",
      "Epoch 102/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0448 - rmse: 0.0804 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0480 - val_rmse: 0.0687\n",
      "Epoch 103/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0420 - rmse: 0.0738 - val_loss: 0.0053 - val_mse: 0.0053 - val_mae: 0.0496 - val_rmse: 0.0731\n",
      "Epoch 104/500\n",
      "4776/4776 [==============================] - 9s 2ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0481 - rmse: 0.0904 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0486 - val_rmse: 0.0707\n",
      "Epoch 105/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0394 - rmse: 0.0656 - val_loss: 0.0062 - val_mse: 0.0062 - val_mae: 0.0523 - val_rmse: 0.0789\n",
      "Epoch 106/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0435 - rmse: 0.0782 - val_loss: 0.0059 - val_mse: 0.0059 - val_mae: 0.0507 - val_rmse: 0.0770\n",
      "Epoch 107/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0413 - rmse: 0.0698 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0490 - val_rmse: 0.0705\n",
      "Epoch 108/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0412 - rmse: 0.0712 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0463 - val_rmse: 0.0661\n",
      "Epoch 109/500\n",
      "4776/4776 [==============================] - 7s 1ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0433 - rmse: 0.0805 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0527 - val_rmse: 0.0821\n",
      "Epoch 110/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0403 - rmse: 0.0679 - val_loss: 0.0042 - val_mse: 0.0042 - val_mae: 0.0460 - val_rmse: 0.0650\n",
      "Epoch 111/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0430 - rmse: 0.0789 - val_loss: 0.0048 - val_mse: 0.0048 - val_mae: 0.0479 - val_rmse: 0.0695\n",
      "Epoch 112/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0442 - rmse: 0.0812 - val_loss: 0.0067 - val_mse: 0.0067 - val_mae: 0.0547 - val_rmse: 0.0816\n",
      "Epoch 113/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0433 - rmse: 0.0772 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0469 - val_rmse: 0.0661\n",
      "Epoch 114/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0391 - rmse: 0.0666 - val_loss: 0.0052 - val_mse: 0.0052 - val_mae: 0.0481 - val_rmse: 0.0720\n",
      "Epoch 115/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0404 - rmse: 0.0691 - val_loss: 0.0049 - val_mse: 0.0049 - val_mae: 0.0480 - val_rmse: 0.0700\n",
      "Epoch 116/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0398 - rmse: 0.0711 - val_loss: 0.0045 - val_mse: 0.0045 - val_mae: 0.0477 - val_rmse: 0.0669\n",
      "Epoch 117/500\n",
      "4776/4776 [==============================] - 7s 2ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0402 - rmse: 0.0676 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0471 - val_rmse: 0.0662\n",
      "Epoch 118/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0405 - rmse: 0.0702 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0607 - val_rmse: 0.1117\n",
      "Epoch 119/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0400 - rmse: 0.0698 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0470 - val_rmse: 0.0664\n",
      "Epoch 120/500\n",
      "4776/4776 [==============================] - 8s 2ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0424 - rmse: 0.0760 - val_loss: 0.0047 - val_mse: 0.0047 - val_mae: 0.0486 - val_rmse: 0.0687\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00120: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAF1CAYAAAAnXamsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABJbUlEQVR4nO3dd3hUZfrG8e9DEnoPvQmK9N4VRRQLxRXrCirq2rura9+fgrrqWtZ1XXvvIuqKKGAXBbEAiiiCUqUjvZeU5/fHOyGFBAKEzEzm/lxXrsyc+s7JZO55yznH3B0RERGJTaWiXQAREREpmIJaREQkhimoRUREYpiCWkREJIYpqEVERGKYglpERCSGKailRDGzc81sQo7nG83swGiWaVfM7Akzu7Wol40mMxtnZhfsh+3ON7OjI49vMbNnCrPsXuzncDP7dW/LuYvtNjYzN7Pkot62lGx6w8h+Y2bzgdpABpAGTAQucfeFxVUGd69Y1Ns0s+nAAZGn5QivLT3y/G53v7uw23L3S/bHsiXdnhzj3TEzBw5299mRbY8HmhfV9kX2lWrUsr/9KRKWdYHlwH+jXJ595u6t3b1i5HWNB67Iep4zQFRzEpGioKCWYuHuW4G3gFZZ08xsgJn9YGbrzWyhmQ3LMa+smb1iZqvMbK2ZTTKz2pF5VczsWTNbamaLzewfZpaU334jTY1NI49fMLNHzWy0mW0ws2/N7KAcy7Yws4/NbLWZ/Wpmf96T15ijafN8M1sAfBaZ/qaZLTOzdWb2pZm1zrHOC2b2j8jj3ma2yMz+ZmZ/RF7fX/Zy2VQzey9ybCdFjtGOLoF8yr67Mu7quB1jZjMj6z4CWAH7qGdmW8yseo5pHc1spZmlmNlBZvZZ5G++0sxeNbOqBWxrmJm9kuP5EDP7PbLu3/Ms283Mvo68j5aa2SNmVjoy78vIYj9a6CY5PevY5li/pYXm/LVmNt3MTijssdmVyPEYFXm/zTazC/OUeXLk77fczB6MTC/w/0JKLgW1FAszKw+cDnyTY/Im4GygKjAAuNTMTozMOweoAjQEUoFLgC2ReS8QmpqbAh2BY4HC9okOAm4HqgGzgbsi5asAfAy8BtSKLPeYmbUqYDu7cgTQEjgu8nwscHBku98Dr+5i3TqE110fOB941Myq7cWyjxKObx3CsTxnN2XeXRkLOm41gP8B/wfUAOYAPfPbgbsvAb4GTskx+QzgLXdPIwT8PUA9wvFrCAzbTbmJ/I0eB4ZE1k0FGuRYJAO4JlK+Q4A+wGWRMvWKLNM+0iLyRp5tpwDvAR8Rjs2VwKtmlrNpPN9jUwjDgUWRMp8K3G1mR0Xm/Qf4j7tXBg4CRkSm7+r/QkooBbXsbyPNbC2wDjgGuD9rhruPc/ef3D3T3acBrxNCDkK/byrQ1N0z3H2Ku6+P1B76A391903u/gfwb8KHZWG84+7fuXs6IYw6RKYfD8x39+fdPd3dfwDeBk7bi9c8LFK2LZHX+Zy7b3D3bYTgaW9mVQpYNw24w93T3H0MsJGC+0vzXdZC68IpwFB33+zuvwAv7qrAhShjQcetPzDd3bPC9iFg2S529RowGMDMjPB3ey1Shtnu/rG7b3P3FcCDZL8fduVU4H13/zJS/luBzByvbYq7fxP5u84HnizkdgF6ABWBf7r7dnf/DHg/6zVEFHRsCmRmDQlfaG50963uPhV4hvDFFcLftqmZ1XD3je7+TY7pO/1fFPK1SJxSUMv+dqK7VwXKAlcAX5hZHQAz625mn5vZCjNbR6gd1Iis9zLwITDczJaY2X2R2s0BQAqwNNL0t5bwwVurkOXJGSKbCR/CRLbbPWubke2eSaiR7qkdg+XMLMnM/mlmc8xsPTA/MqtGvmvCqsgHfn5lLOyyNQkDRXMO2itwAF8hy1jQcauXc9se7vKzq8GCbwOHmFldoBchUMdHylHbzIZb6M5YD7xCwccpp7xl2ASsyvH6mpnZ+5Gm/fXA3YXc7o5tu3tmjmm/E1oxshR0bHa33dXuvqGA7Z4PNANmRpq3j49ML+j/QkowBbUUi8i3//8RmiEPi0x+DRgFNHT3KsATRPo3I7XE2929FXAoocZ7NuEDeRtQw92rRn4qu3tr9s1C4Isc26waaQq9dC+2lfOWdGcAA4GjCU2WjSPT8+3HLSIrCF0DOZt/G+5i+X0p49Kc247Ukgvcl7uvITQjnx7Z73DPvoXf3YRj1zbS5HvWXpahPKHWmeVxYCZhZHdl4JZCbhdgCdDQzHJ+VjYCFhdy/V1tt7qZVcpvu+4+y90HE76A3gu8ZWYVdvF/ISWYglqKhQUDCf14MyKTKxFqFVvNrBvhgztr+SPNrG2kGXc9ockv092XEj7o/2Vmlc2sVGQQUmGbMgvyPtAsMigpJfLT1cxa7uN2KxG+WKwCyhPCaL9y9wxCv/EwMytvZi3Y9Yf5vpRxNNDazE62MMr9KnbfCvFapDynRh7nLMdGYJ2Z1QeuL2QZ3gKON7PDIoPE7iD3Z1slwntoY+RY5P3ytRwo6Fz7bwm15Bsi74newJ8I/ct7LXKK4kTgnsgAsXaEWvQrAGZ2lpnVjNTk10ZWyyzo/2JfyiKxT0Et+9t7ZraR8KFyF3COu0+PzLsMuMPMNgC3kT1gBsKH/VuR9WYAXxCa/SB8yJcGfgHWRJaruy+FjDRBHkvoM11CaM68FyizL9sFXiI0aS4mlPebXS9eZK4g1I6XEY7b64Qwzs9el9HdVxL68f9JCPqDga92s9qoyHLL3P3HHNNvBzoRxjOMJnzZKEwZpgOXE0J/KeE9sSjHItcRvgRuAJ4G3siziWHAi5Euj1wj/d19OyGY+wErgceAs919ZmHKthuDCa0XS4B3CGMKPonM6wtMj/zv/AcYFBnzsKv/CymhLLvVSURKKjO7F6jj7rsb/S0iMUY1apESyMI54e0iXQ7dCM2q70S7XCKy53TlJJGSqRKhubseoQ/2X8C7US2RiOwVNX2LiIjEMDV9i4iIxDAFtYiISAyLuT7qGjVqeOPGjaNdDBERkWIzZcqUle5eM795MRfUjRs3ZvLkydEuhoiISLExs98LmqembxERkRimoBYREYlhCmoREZEYFnN91CIismfS0tJYtGgRW7dujXZRZDfKli1LgwYNSEkp/N1JFdQiInFu0aJFVKpUicaNGxPuNCqxyN1ZtWoVixYtokmTJoVeT03fIiJxbuvWraSmpiqkY5yZkZqausctHwpqEZESQCEdH/bm76SgFhGRfbJq1So6dOhAhw4dqFOnDvXr19/xfPv27btcd/LkyVx11VW73cehhx5aJGUdN24cxx9/fJFsq7ioj1pERPZJamoqU6dOBWDYsGFUrFiR6667bsf89PR0kpPzj5suXbrQpUuX3e5j4sSJRVLWeFSoGrWZ9TWzX81stpndlM/8a83sFzObZmafmtkBOeZlmNnUyM+ooiy8iIjEpnPPPZdLLrmE7t27c8MNN/Ddd99xyCGH0LFjRw499FB+/fVXIHcNd9iwYZx33nn07t2bAw88kIcffnjH9ipWrLhj+d69e3PqqafSokULzjzzTLLuAjlmzBhatGhB586dueqqq3Zbc169ejUnnngi7dq1o0ePHkybNg2AL774YkeLQMeOHdmwYQNLly6lV69edOjQgTZt2jB+/PgiP2YF2W2N2sySgEeBY4BFwCQzG+Xuv+RY7Aegi7tvNrNLgfuA0yPztrh7h6IttoiI5Oevf4VI5bbIdOgADz205+stWrSIiRMnkpSUxPr16xk/fjzJycl88skn3HLLLbz99ts7rTNz5kw+//xzNmzYQPPmzbn00kt3OpXphx9+YPr06dSrV4+ePXvy1Vdf0aVLFy6++GK+/PJLmjRpwuDBg3dbvqFDh9KxY0dGjhzJZ599xtlnn83UqVN54IEHePTRR+nZsycbN26kbNmyPPXUUxx33HH8/e9/JyMjg82bN+/5AdlLhalRdwNmu/tcd98ODAcG5lzA3T9396xSfwM0KNpi7p3MTBg7FmbNinZJREQSz2mnnUZSUhIA69at47TTTqNNmzZcc801TJ8+Pd91BgwYQJkyZahRowa1atVi+fLlOy3TrVs3GjRoQKlSpejQoQPz589n5syZHHjggTtOeypMUE+YMIEhQ4YAcNRRR7Fq1SrWr19Pz549ufbaa3n44YdZu3YtycnJdO3aleeff55hw4bx008/UalSpb09LHusMH3U9YGFOZ4vArrvYvnzgbE5npc1s8lAOvBPdx+ZdwUzuwi4CKBRo0aFKFLhuEP//nD77XDbbUW2WRGRmLU3Nd/9pUKFCjse33rrrRx55JG88847zJ8/n969e+e7TpkyZXY8TkpKIj09fa+W2Rc33XQTAwYMYMyYMfTs2ZMPP/yQXr168eWXXzJ69GjOPfdcrr32Ws4+++wi3W9BinTUt5mdBXQB7s8x+QB37wKcATxkZgflXc/dn3L3Lu7epWbNfO/ytVeSkqBUKUhLK7JNiojIXli3bh3169cH4IUXXijy7Tdv3py5c+cyf/58AN54443drnP44Yfz6quvAqHvu0aNGlSuXJk5c+bQtm1bbrzxRrp27crMmTP5/fffqV27NhdeeCEXXHAB33//fZG/hoIUJqgXAw1zPG8QmZaLmR0N/B04wd23ZU1398WR33OBcUDHfSjvHktJgd2cHSAiIvvZDTfcwM0330zHjh2LvAYMUK5cOR577DH69u1L586dqVSpElWqVNnlOsOGDWPKlCm0a9eOm266iRdffBGAhx56iDZt2tCuXTtSUlLo168f48aNo3379nTs2JE33niDq6++ushfQ0Esa7RcgQuYJQO/AX0IAT0JOMPdp+dYpiPwFtDX3WflmF4N2Ozu28ysBvA1MDDPQLRcunTp4kV5P+pKleDCC+HBB4tskyIiMWXGjBm0bNky2sWIuo0bN1KxYkXcncsvv5yDDz6Ya665JtrF2kl+fy8zmxJpfd7JbmvU7p4OXAF8CMwARrj7dDO7w8xOiCx2P1AReDPPaVgtgclm9iPwOaGPusCQ3h9SUtT0LSKSCJ5++mk6dOhA69atWbduHRdffHG0i1QkCnXBE3cfA4zJM+22HI+PLmC9iUDbfSngvipdWk3fIiKJ4JprronJGvS+KvGXEFWNWkRE4pmCWkREJIaV+KBW07eIiMSzEh/UqlGLiEg8U1CLiMg+OfLII/nwww9zTXvooYe49NJLC1ynd+/eZJ2K279/f9auXbvTMsOGDeOBBx7Y5b5HjhzJL79kn0x022238cknn+xB6fMXS7fDLPFBXbq0glpEZH8aPHgww4cPzzVt+PDhhbreNoS7XlWtWnWv9p03qO+44w6OPjrfE5HiVokPal2ZTERk/zr11FMZPXo02yMftvPnz2fJkiUcfvjhXHrppXTp0oXWrVszdOjQfNdv3LgxK1euBOCuu+6iWbNmHHbYYTtuhQnhHOmuXbvSvn17TjnlFDZv3szEiRMZNWoU119/PR06dGDOnDmce+65vPXWWwB8+umndOzYkbZt23Leeeexbdu2HfsbOnQonTp1om3btsycOXOXry/at8Ms1HnU8UxN3yKSUKJwn8vq1avTrVs3xo4dy8CBAxk+fDh//vOfMTPuuusuqlevTkZGBn369GHatGm0a9cu3+1MmTKF4cOHM3XqVNLT0+nUqROdO3cG4OSTT+bCCy8E4P/+7/949tlnufLKKznhhBM4/vjjOfXUU3Nta+vWrZx77rl8+umnNGvWjLPPPpvHH3+cv/71rwDUqFGD77//nscee4wHHniAZ555psDXF+3bYSZEjVpBLSKyf+Vs/s7Z7D1ixAg6depEx44dmT59eq5m6rzGjx/PSSedRPny5alcuTInnHDCjnk///wzhx9+OG3btuXVV18t8DaZWX799VeaNGlCs2bNADjnnHP48ssvd8w/+eSTAejcufOOG3kUJNq3wyzxNWqdniUiCSVK97kcOHAg11xzDd9//z2bN2+mc+fOzJs3jwceeIBJkyZRrVo1zj33XLZu3bpX2z/33HMZOXIk7du354UXXmDcuHH7VN6sW2Xuy20yi+t2mKpRi4jIPqtYsSJHHnkk55133o7a9Pr166lQoQJVqlRh+fLljB07dpfb6NWrFyNHjmTLli1s2LCB9957b8e8DRs2ULduXdLS0nbcmhKgUqVKbNiwYadtNW/enPnz5zN79mwAXn75ZY444oi9em3Rvh1mia9RK6hFRIrH4MGDOemkk3Y0gWfdFrJFixY0bNiQnj177nL9Tp06cfrpp9O+fXtq1apF165dd8y788476d69OzVr1qR79+47wnnQoEFceOGFPPzwwzsGkQGULVuW559/ntNOO4309HS6du3KJZdcsleva9iwYZx33nm0a9eO8uXL57od5ueff06pUqVo3bo1/fr1Y/jw4dx///2kpKRQsWJFXnrppb3aZ067vc1lcSvq21wOGQJffQVz5xbZJkVEYopucxlfivw2l/FONWoREYlnCmoREZEYVuKDWlcmExGReFbig1pXJhORRBBr440kf3vzd0qIoFaNWkRKsrJly7Jq1SqFdYxzd1atWkXZsmX3aD2dniUiEucaNGjAokWLWLFiRbSLIrtRtmxZGjRosEfrlPigLl0aMjMhIwOSkqJdGhGRopeSkkKTJk2iXQzZTxKi6RtUqxYRkfikoBYREYlhJT6oS5cOvzXyW0RE4lGJD2rVqEVEJJ4pqEVERGJYiQ/qrKZvBbWIiMSjEh/UWTVq9VGLiEg8SpigVo1aRETikYJaREQkhpX4oNbpWSIiEs9KfFCrRi0iIvFMQS0iIhLDSnxQq+lbRETiWYkPatWoRUQknimoRUREYliJD2o1fYuISDwr8UGtGrWIiMQzBbWIiEgMU1CLiIjEsBIf1OqjFhGReFbig1o1ahERiWcKahERkRhW4oNaTd8iIhLPSnxQJyWF36pRi4hIPCrxQW0Wmr8V1CIiEo9KfFBDaP5W07eIiMSjhAhq1ahFRCReKahFRERimIJaREQkhiVEUKuPWkRE4lVCBLVq1CIiEq8KFdRm1tfMfjWz2WZ2Uz7zrzWzX8xsmpl9amYH5Jh3jpnNivycU5SFLywFtYiIxKvdBrWZJQGPAv2AVsBgM2uVZ7EfgC7u3g54C7gvsm51YCjQHegGDDWzakVX/MJR07eIiMSrwtSouwGz3X2uu28HhgMDcy7g7p+7++bI02+ABpHHxwEfu/tqd18DfAz0LZqiF55q1CIiEq8KE9T1gYU5ni+KTCvI+cDYvVx3v1BQi4hIvEouyo2Z2VlAF+CIPVzvIuAigEaNGhVlkQA1fYuISPwqTI16MdAwx/MGkWm5mNnRwN+BE9x9256s6+5PuXsXd+9Ss2bNwpa90FSjFhGReFWYoJ4EHGxmTcysNDAIGJVzATPrCDxJCOk/csz6EDjWzKpFBpEdG5lWrBTUIiISr3bb9O3u6WZ2BSFgk4Dn3H26md0BTHb3UcD9QEXgTTMDWODuJ7j7ajO7kxD2AHe4++r98kp2oXRpBbWIiMSnQvVRu/sYYEyeabfleHz0LtZ9DnhubwtYFFJS1EctIiLxSVcmExERiWEKahERkRiWEEGt07NERCReJURQq0YtIiLxSkEtIiISwxIiqNX0LSIi8Sohglo1ahERiVcJE9QZGZCZGe2SiIiI7JmECOrSpcNv1apFRCTeJERQp6SE3wpqERGJNwpqERGRGKagFhERiWEJEdRZfdQ6RUtEROJNQgS1atQiIhKvFNQiIiIxLCGCWk3fIiISrxIiqFWjFhGReKWgFhERiWEJEdRq+hYRkXiVEEGtGrWIiMQrBbWIiEgMU1CLiIjEsIQIavVRi4hIvEqIoFaNWkRE4pWCWkREJIYlRFCr6VtEROJVQgS1atQiIhKvFNQiIiIxLCGCWk3fIiISrxIiqFWjFhGReKWgFhERiWEKahERkRiWEEFtBsnJ6qMWEZH4kxBBDaFWrRq1iIjEGwW1iIhIDEuYoC5dWk3fIiISfxImqFWjFhGReKSgFhERiWEJE9Rq+hYRkXiUMEGtGrWIiMQjBbWIiEgMS6igVtO3iIjEm4QJ6tKlVaMWEZH4kzBBraZvERGJRwpqERGRGJYwQa3Ts0REJB4lTFCrRi0iIvFIQS0iIhLDEiao1fQtIiLxKGGCWjVqERGJRwpqERGRGFayg3rrVujWDZ55RlcmExGRuFSooDazvmb2q5nNNrOb8pnfy8y+N7N0Mzs1z7wMM5sa+RlVVAUvlDJlYOpUmD1bVyYTEZG4lLy7BcwsCXgUOAZYBEwys1Hu/kuOxRYA5wLX5bOJLe7eYd+LuhfMIDUVVq8mpbKCWkRE4k9hatTdgNnuPtfdtwPDgYE5F3D3+e4+DcjcD2XcN9Wrw6pV6qMWEZG4VJigrg8szPF8UWRaYZU1s8lm9o2ZnZjfAmZ2UWSZyStWrNiDTRdCpEad1fTtXrSbFxER2Z+KYzDZAe7eBTgDeMjMDsq7gLs/5e5d3L1LzZo1i3bvOWrUAOnpRbt5ERGR/akwQb0YaJjjeYPItEJx98WR33OBcUDHPSjfvsvqo44EtZq/RUQknhQmqCcBB5tZEzMrDQwCCjV628yqmVmZyOMaQE/gl12vVcQiNerSpcNTnaIlIiLxZLdB7e7pwBXAh8AMYIS7TzezO8zsBAAz62pmi4DTgCfNbHpk9ZbAZDP7Efgc+Gee0eL7X2oqbN1KWd8CqEYtIiLxZbenZwG4+xhgTJ5pt+V4PInQJJ53vYlA230s476pXh2ASttXAQ0U1CIiEldK9pXJINSogQrbVgNq+hYRkfhS8oM6UqOuuG0VoKZvERGJLyU/qCM16vJbQ41aQS0iIvGk5Ad1pEZdbrNq1CIiEn9KflBHatTltqiPWkRE4k/JD+py5aBsWcpuUo1aRETiT8kPaoDUVMpsUh+1iIjEn8QI6urVKbMx1KjV9C0iIvEkMYI6NZWUjapRi4hI/EmMoK5enZT16qMWEZH4kxhBnZpK8jo1fYuISPxJjKCuXp3k9asBV41aRETiSmIEdWoqlpZGRTYqqEVEJK4kRlBHrk5WndVq+hYRkbiSGEEduTpZKqtUoxYRkbiSGEGdo0atoBYRkXiSGEGtGrWIiMSpxAhq9VGLiEicSqigVo1aRETiTWIEdZkyUKECqeqjFhGROJMYQQ2QmkrNUqvU9C0iInElcYK6enVSTTVqERGJL4kT1KmppJr6qEVEJL4kTlBXr04116hvERGJL4kT1KmpVHfVqEVEJL4kTlBXr07VzNWkb8+MdklEREQKLXGCOjWVJDJJ3rw+2iUREREptMQJ6shFT8psWh3lgoiIiBRe4gR15Hrf5TavinJBRERECi9xgjpSoy63RTVqERGJH4kT1JEadfktqlGLiEj8SJygjtSoy29TjVpEROJHwgV1xW2qUYuISPxInKBOTmZTcmUqqkYtIiJxJHGCGthYOpXKaapRi4hI/EisoC5TnUppqlGLiEj8SKig3lQ2lSrpqlGLiEj8SKig3lK2OlUyVKMWEZH4kVBBvbVyLWpkLIt2MURERAotoYI6o24DKrGRzct0Yw4REYkPCRXUSQc0AGDV1IVRLomIiEjhJFRQl2naEID1vyyKcklEREQKJ6GCunKrUKPeOltBLSIi8SGhgjq1bT0yMdLnK6hFRCQ+JFRQ16hXmuXUJmmJ+qhFRCQ+JFRQJyXB8pQGlFmpGrWIiMSHhApqgDXlG1BpnYJaRETiQ8IF9caqDUjdoqAWEZH4kHBBva1WQyplrIMNG6JdFBERkd1KuKD2+uEUrYzfVasWEZHYl3BBndQ4BPW66QpqERGJfYUKajPra2a/mtlsM7spn/m9zOx7M0s3s1PzzDvHzGZFfs4pqoLvrfLNwtXJNs5UUIuISOzbbVCbWRLwKNAPaAUMNrNWeRZbAJwLvJZn3erAUKA70A0YambV9r3Ye69Ky3oAbJutc6lFRCT2FaZG3Q2Y7e5z3X07MBwYmHMBd5/v7tOAzDzrHgd87O6r3X0N8DHQtwjKvdfqHFCG5dQic4Fq1CIiEvsKE9T1gZzVz0WRaYVRqHXN7CIzm2xmk1esWFHITe+dOnVgIQ1JWqagFhGR2BcTg8nc/Sl37+LuXWrWrLlf91WuHCxPbkC5VQpqERGJfYUJ6sVAwxzPG0SmFca+rLvfrK3YgCrr1UctIiKxrzBBPQk42MyamFlpYBAwqpDb/xA41syqRQaRHRuZFlWbqjWgYtpa2Lgx2kURERHZpd0GtbunA1cQAnYGMMLdp5vZHWZ2AoCZdTWzRcBpwJNmNj2y7mrgTkLYTwLuiEyLqrQ6kUr+4qhX7kVERHYpuTALufsYYEyeabfleDyJ0Kyd37rPAc/tQxmLXoNQVF+4CGvePMqFERERKVhMDCYrbqUPDEG9VedSi4hIjEvIoC5/cDhDbJOuTiYiIjGuUE3fJU3tA8ryBzVJn6egFhGR2JaQNeo6dWARDWChglpERGJbQgZ13bohqFOWq49aRERiW0IGdfXqsLhUQ8qvVo1aRERiW0IGtRmsr9SACltXw+bN0S6OiIhIgRIyqAG2pEZO+87voic//QR9+yrERUQk6hI2qHdcnWxhPv3UI0bAhx/CrFnFWygREZE8Ejao0w9sFh789NPOMydPDr/38y03RUREdidhg7rcQfVYQEMyv/o69wx3mDQpPFZQi4hIlCVsUNetC19zCJkT8wT1/PmwalV4rKAWEZEoS+ig/oYeJC9eAEuWZM/Iqk2DglpERKIuoYP6aw4JT775JnvGpElQujRUraqgFhGRqEvYoG7WDH6gI+lJpXMH9eTJ0L491KunoBYRkahL2KCuUgVqNyzDvGqd4OtIP3VmJkyZAl27Qs2aCmoREYm6hA1qgDZt4Ft6hFp0Whr8+its2KCgFhGRmJHwQT1mzSGwdSv8+GP2QLIuXRTUIiISExI+qCdk9AhPvvkm1KwrVICWLUNQr14NGRnRLaSIiCS0hA/qhTRkS7V6oZ960iTo1AmSkkJQu2efUy0iIhIFCR3ULVuCmTGvziEwYQJMnRr6pyEENaj5W0REoiqhg7pcOWjaFCYn94AFC0JfdZcuYaaCWkREYkBCBzVA27Ywdu0h2RNUoxYRkRiS8EHdpg2MWtQJT06GatXgoIPCDAW1iIjEgORoFyDa2rSBzV6OTe17UrFhNTALM1JTw28FtYiIRJGCuk34PfriUZw+OEcDQ0pKqGErqEVEJIoSvum7adNwD44f5lSGihVzz6xRQ0EtIiJRlfBBnZICLVrATz/lM1NXJxMRkShL+KCG0Pz988/5zFBQi4hIlCmoCUG9YAGsX59nhoJaRESiTEFNOJcaYPr0PDNq1oSVK8PtL0VERKJAQU32yO+dmr9r1gw35Vi7triLJCIiAiioAWjUKAz4zjeoQc3fIiISNQpqoFSp0PyddTvqHRTUIiISZQrqiKOPhm+/Dbeg3kFBLSIiUaagjujfP4wZ++ijHBMV1CIiEmUK6oiuXcPlvceMyTFRQS0iIlGmoI5ISoK+fWHs2DDQG4CyZcMoMwW1iIhEiYI6hwEDwmnTkyfnmKiLnoiISBQpqHM49tgwAnyn5m8FtYiIRImCOofUVOjRQ0EtIiKxQ0GdR//+oel72bLIBAW1iIhEkYI6jwEDwu8PPohMyApq96iVSUREEpeCOo/27aFu3RzN3zVrwvbtsGFDVMslIiKJSUGdh1lo/v7wQ0hLQ+dSi4hIVCmo83HyyeHe1K+9hoJaRESiSkGdj379oFMnGDYM0qoqqEVEJHoU1Pkwg3/8A+bPhxGfK6hFRCR6FNQF6NsXDj0Uhj2qoBYRkehRUBcgq1Y9e1kFtpWpBDNmRLtIIiKSgBTUu3DkkdCnj/GmnY6PGAFr1kS7SCIikmAKFdRm1tfMfjWz2WZ2Uz7zy5jZG5H535pZ48j0xma2xcymRn6eKOLy73d33gkPbL0c27IFXnwx2sUREZEEs9ugNrMk4FGgH9AKGGxmrfIsdj6wxt2bAv8G7s0xb467d4j8XFJE5S42hxwC9fp14LvkQ8h85DHIzIx2kUREJIEUpkbdDZjt7nPdfTswHBiYZ5mBQFZ18y2gj5lZ0RUzum69Ff6Tfjml5syCTz+NdnFERCSBFCao6wMLczxfFJmW7zLung6sA1Ij85qY2Q9m9oWZHb6P5Y2KQw6BtX1OZaXVJP3hR6NdHBERSSD7ezDZUqCRu3cErgVeM7PKeRcys4vMbLKZTV4Ro6dB3TysDE/5BZQa/R4sWBDt4oiISIIoTFAvBhrmeN4gMi3fZcwsGagCrHL3be6+CsDdpwBzgGZ5d+DuT7l7F3fvUjPrkp0x5rDD4KdDLsYd0h55ct82Nn8+vPJKkZRLRERKtsIE9STgYDNrYmalgUHAqDzLjALOiTw+FfjM3d3MakYGo2FmBwIHA3OLpujF7+K7D+B9jiftiWcid+zYS1deCUOGwLp1RVc4EREpkXYb1JE+5yuAD4EZwAh3n25md5jZCZHFngVSzWw2oYk76xSuXsA0M5tKGGR2ibuvLuLXUGx694ZvWl9A+Q1/sP6NsXu3kRkz4P33w+NZs4qsbCIiUjKZu0e7DLl06dLFJ0+eHO1iFOiH79Ko170Bv9U8jEOXvk1S0h5u4MIL4ZlnwuNXX4UzzijyMoqISHwxsynu3iW/eboy2R7q2C2FFcecSfcV73HPdav2bOVly+Cll+AvfwnXKP311/1TSBERKTEU1Huhzf3nUJo0lj30Ou++uwcrPvpo6Nu++WZo3Bh++21/FVFEREoIBfXeaN+ezPYduKz8i5x9NsycWYh1Nm2Cxx6DE0+Egw+GZs0U1CIislsK6r1U6txzaLV5Mu2Tp3PccbA47wlreb3wAqxeDdddF55nBXWMjREQEZHYoqDeW2ecAcnJvHn8i6xZA8cdF3I4X5s2wf33h0ucHXpomNa8OWzcCEuXFluRRUQk/iio91atWtCvH7U/foX3hm+C337jzsM/YsuM+Tsve+ON4Wpm//xn9rRmkeu+qPlbRER2QUG9L849F5Yu5YgBFfk5rTn//uU4Mtu2Y8snX2Uv88knYRDZX/8KvXplT1dQi4hIISRHuwBx7U9/gv/7P0hJgcaN+fDHOjR+8EoaHncca/83mqq9O8B554Vm7rvuyr1uw4ZQtqxO0RIRkV1SUO+LlBS4884dT48Dxrb5gszzj6LxSf3YcsghlFu8GCZOhHLlcq9bqlQY/a0atYiI7IKavotYv7/UYd3Iccy1gyg38TOWnXsTdO+e/8I6RUtERHZDQb0f9DihFvb559xY7SmavzaUN94oYMHmzWHu3H27wYeIiJRoCur9pFWvGlw740Ladi7NoEGhKzszM89CzZpBejrMm1d8BVu3LpwuJiIicUFBvR/Vrg2ffgrnnx/Gkp1wAqxZk2OBaIz87ts3XGt8f3nzzUJeqk1ERApDQb2flSkDTz8NjzwCH30EnTrBjpuDNW8efhdXUK9dC99+G04Z26l6XwQ2bIDBg+Hee4t+2yIiCUpBXQzM4PLLYfx4yMiAnj3hiSfAq1WH1NTiC+qJE8MlS9es2T+13q++Ci9Qp5yJiBQZBXUx6t4dfvgBjjoKLr0UBgyAbY2bFV+wjR+f/XjChKLf/rhx4ffMmbqGuezehg3Qps3+eS+KlCAK6mKWmgqjR8N//wtffAFvT2vGpqm/kZ5eDDufMAG6dYOaNUPtt6h98UX4vWYNrFxZ9NuXkuW332D6dPjyy2iXRCSm6YInUVCqFFxxRRjX9enRzanw+4tULbuROk0r0qwZNG0abld9wAHQsmX2mLN9snUrfPcdXHkl1KtX9EG9cSNMmgQdOsDUqaGVoGbNot2HlCxZt5xbuDC65RCJcapRR1HTpnDh/SGF7xzyG61bw7w5mTzxuHP11eHW1c2bw/PPF8HOJk+G7dvh8MNDJ/mcObBsWe5lHnkExozZu+1n9U9ffHF4rn5q2Z1Fi8LvBQuiWw6RGKegjrJSLUJQX/n5ybz9dT1++q0Mm2oewPp7HmXS+K0ceWToz/7++33cUVb/dM+ecNhh4XHOWvWUKaG2PWAA9O+/50H7xReQnBxu/1m6tIJadi8rqFWjFtklBXW0tWgBgwZB+/YhJK+/HmvUiEo3X0GX0w/i3d4PckSVqQw+aWvB97sGeO01WLKk4PkTJoR29Bo1wjliZcvmDupHH4Xy5eGee8L0Nm1g6NDCv45x46BrV6hcOVzDXOdSy+5kNX2rRi2ya+4eUz+dO3f2hJeZ6f7pp+69ermH8dOeTilfUKG5Z7z86s7LT5gQljvrrPy3l57uXqWK+4UXZk87/HD3bt3C45Ur3cuWdb/44vB82TL3wYPDNl95Zffl3bjRPTnZ/aabwvOTT3Zv1qzQL1cS1FFH7Xh/+/r10S6NSFQBk72AXFSNOhaZhXO4vvgCZsyAN97g+37/x9pNKWw57zJ+n7om9/JZFxh54w1YunTn7U2fHi4devjh2dN69gzt6Zs3h07wrVvDyd4QLqn20ktw6KFw2WXw+++7Lu/EieFSqL17h+e6hrkUxqJFobsE1PwtsgsK6ljXogX8+c90GX07n53/GuXS1vNapwc455yQ4UyfDu+9B0OGhLB84omdt5HVP53VN531OD09XKns8cdDiLdtmz0/ORleeSXUd4YMCQPFCjJuHCQlhWDPKnN6eghrkfy4h6bvTp3CczV/ixRIQR0nzODqZ9qydeDpXJv8H7548w9atYIPjrqP9NLl2XzXv0Mf9xNPwLZtuVeeMAHq1w/nfGU55JDw+7bbQqBeccXOO23SJIwEHz8e7ruv4MJ98QV06QKVKoXnWZdGVT+1FCTr5jBZ70PVqEUKpKCOM+XvHUaZjC38cvY/efTGBfT54zUe3X4Bddukcv/2q+GPP0h/ZXj2Cu4haA87LKR9lurVoVWrEOJ168JJJ+W/wyFD4M9/DoE+ZcrO8zdtCudnZzV7Q3ZQa+R39LjD/ffD7NnRLkn+skZ8d+0aLiygGrVIgRTU8aZ5czjnHMq/8BiXzbue5GToPvxaTjwR/vF1H36mNdMv+g/n/cXDzT/Gjg1NjDn7p7P07Bl+X3QRpKTkvz+zUEuvUwfOPDP0aef0wQehL/qII7KnVa0KtWopqKPp55/hhhvgP/+JdknylzXiu3HjcAEe1ahFCqSgjke33RbufjViBDZ4MD1OP4AXX4Q/Vhh+xVW0z/yBza+/y/Su58CAAayr1ZTPqp3Cxx/DZ5/BihWR7QwcGAL1ootwh48/hj/+yGd/1arBCy+E4L3hhuzpv/wS7uHZsmXuGjWELxQK6ugZPTr8jtXLc2bVqOvXh4YNVaMW2QUFdTxq3BguvDDUdnMEZ5ky0Pbes6BaNYZvO4mzSr3GE9Vvoc4f0+hzZh2OPRb69IEDDwytotuPGQDLlzNnSz2OOw6OPRZ69coR5DnMatSHzKuvCedbjx0brmrWvz+UKxeelyuXe4UWLdRHHU1ZV5j76Sd2fQL+Pli/fu/XzQrqevWgUSPVqEV2QUEdrx54IFxbu02b3NPLl4c774R+/Uj68QcuXnkX30wtx1dfha7qjz8Old8bboB27cLvNm3C4O+bbw4Vm759w1gfCF3Q558frjfecezdrG3YBj/vvDBwbcUKeP/9cFHyvJo3h1Wrwo8UrzVrwilzvXplj1EoajNmhIvnfPjh3q2/eHE4DbB06VCjXrhQd1wTKYCCOl6VKwedO+c/7/LLQ42qTRvMwkXPDj00jCc7+uhwNtf774czru6/P1SMf/kF7r4b3noLpk2DE06Ab74Ju3j++XAJ7/Tkshyx8BXSlq/Gp04N520XVAYNKIuejz4Kf9xhw0Izy/5o/n711TA24bPP9m79RYtCszeEGvW2bfk35YiIgjpRDRgQxhv9+CO8/Xb2Z2b//uH06fHjw5kz69fDJ5+E8WTTpsGNr7bn8jr/Y6C/y79nHV9wJUhBHT1jxoRR/b16QY8e2bcfLSruMDxyZsGkSXu3jUWLoEGD8Lhhw/Bb/dQi+VJQJ7AyZULzd16nnw4vvgh/+UsI8qOOCtOTksI9Nx6aNYCUk47n2mvhkksKuABZkyZhJHnOoF67tniaN91DWP300/7fV6zJzAxjBvr2DX+wI46AH37Yt/7kvL7/Ptx9rUaNcMpeZuaeb2Px4uygbtQo/FY/tUi+FNSSryFD4Lnn8r+ldIUK8OaboU/7qadCn/edd4Ym8o8/hnnzILNUcriP58yZZM5fwLqT/4JXr86izgN596nlvPNOaFrfvn0vC7h1K5x9NnTsGC53mvVtYe5c6Ncv+y5gGzfu7SGIT1OmhCbk/v3D8169QpAW5f3Hhw8PV667+ebwBeC33/Zs/c2bwwC3rGYc1ahFdq2gi4BH60c35YgvL77oXrdu9r0Vsn4qVHD/rOqJvimpom+hjG+ltL/GIN9CGV9OTR/IO2G5suk+qPtcf+K8b33iF9s9PT1725mZ7r/9kuZfjV7j27bl2OmaNe5HHBF21LRp+N2okfull4abi1Sq5P63v4Xpf/tbMR+RKBs61N3MfcWK8HzTpnDDlBtvLJrtZ2aGYz1ggPtPP4Vj/NJLe7aN334L6734YvY2y5aN7t9qy5ZQDpEoQTflkP3l7LPD3TW3bAmtoePGhVr2BRfAvNSulM3YxA/NBjHy3t9o+cPrLHt/CpVa1GckJ7Gh9kGsTSvP698eyMXPdaf5EbUZXv487j1iDP/q9gZvlzuL6q1q02NAdb4u34fHu7/A6H/NJPOwXmFU8yuvhNrc+++HWtnjj2ePjHvggXAhl4ceCu33Wdatg2uuCVdTK4nGjAn90jVqhOfly4erfxXVgLJvvgk139NPD+fPV6iw5/3UWRc7yWr6NovuudTLl4fa/YMPRmf/IrtTUIJH60c16hJk27Zwy8z8pt9xR7gd5g03uD/9tG987g2f12uIb0qpvKNavr5Mqv/WY4jPPOUWX17poB3TN1DRnz/z4503vWZN7uerVrnXrOl+yCHuGRnuM2aE22+Ce+PG4facsWjFCvfevd3vvtt9+/bCr7dsWXhtd96Ze/pNN4VadVG83quuci9Txn3duvD88MPde/TYs228/HIo58yZ2dP69Nnz7RSVSy4J5Tn44N3Xqu+4w/3BB4unXJJQ2EWNOurBnPdHQZ3gtmxxHzMm3GM7Tzt4+viJPvfsoX7lET+6mXvp0u6HHureqpV7rVqhxfuCC3J//vuLL4a3+fnnu1euHIL7/vvDtOuvz7XrjAz36Z8t89UzlnnutvZiduaZofka3Dt2dP/hh8Kt9/TTYZ0pU3JPHzMmTP/kk30rV3p66Oc46aTsaddcE5qt9+QLxT33hPJs2JA97dxz3evV27fy7Y0ZM9yTktwPPDCU6ZtvCl520yb3cuXcq1d3T0srvjJKQthVUKvpW2JL2bJhMFjPnmHUchYzkg47hCYvDuPhce2YOTM0rycnh4ugnXhiuK/IK6+EFtmTTgrnhV/53RCm1zgCnn2WuUlNGXr8FO7adh1zjroAf/BBtn/7A0uWwF3/cB5OvZ1WR9WhWss6UKYMW5MrsLj1sWyfsIfN5Onpe//6R48O5ygPHRpOal+yJDRd33rrzndFy2nbNrjrrnDSfIcOuef17BlufFHQaVrXXQe33777sk2YEO53fvrp2dO6dg0D+6ZP3/36WRYvDteDr1gxe1qjRmHbxX0P85tvDt0DH30U3nsvv1zwsp98Evp4Vq+O3UuzFpVly/bfFe1kzxWU4NH6UY1a9sXy5e633uperVqoIFWt6n5k0wX+n0YPeOsDN3vlSMt6VVb7Umr7JDp7lVLrfTh/dgef1f1M/3Dgo/56m3/4c5Wu8uXUdAf/tc1JvmnsF+6vvx5q4sce63788Z556WX+2/n3+JTT7/X0U/8camZJSe5//evOta7t292//NJ90iT3efNy1yjd3deuda9f371Nm+wa/apV7kOGhEK3bh3Wzc+//hWW+eij/Od37ux+2GE7T//22x1dCv7yywUf2MWL3Tt1CqMEczahz5oV1n3qqYLXzevEE8NrySmrNWDevMJvZ1+NHx/2+Y9/hOennx5qywW1ppx3XmiVKVfO/fLLi6+cxS0tLbyP+/SJdkmiJyPD/bLL3L/6qth2iZq+JdFs2+a+eXP+8zZtcp861X3ClcPdwddXqO2ZZu733ZerjzIz0/2zd9f7801u93VU2hFoaUmlfWOLTv5Hvfa+plS1HdMXJh/gv3c9xTMHDQ7TjjnGffXqsLFPPglt9HmGx29t2cH9scdCn+9FF7mXKuX+3Xc7F/r990PTcFJS6HPOGSarV4dvJsceW/ABufvusM+PP849/bjj3FNTQ4iXLx9Gcuc1aVLYd8WK7u+9l3teZmbY94UX5r/fjAz3228PX1CydOkS9pvThx+G8uVcrjCWLw/H49tv92y9zMzQJ16vXnhDuLuPHh3KMHLkzsunp4duk8GDQ9N//frhtcWzjz7K/wvWiBHZ79G5c4u/XLFgwoTw+vv3L7ZdKqhF8pOZ6f6nP4UAevfdXS465cMV/sTRI3xAwx89me07Psd69HB//ekN/vEbq7xDhzCtfXv3J7o+49stxRdXaOqTG53kDr6h9oE+7cZX/In+7/rVlZ71m7nLp9DRHXx76fLu4IsGX+fPPRdaBUaMCJXsHdasCX3t4N6zp/vSpWH6ddeFPu2pU/N9iT//7P7f+7f4mppNPaPpwWEcgHv2h9F997kvWeJeu7Z78+bu69eH+Zs2uT//fKhBNmrk/uOP+R+cY45x79Ah/3k33ug7Tp/L2m/duuF15PTLL2G5V17JfztffBHCfOvW7Bf2yivhSwaEAW6FPU0sI8N92LCw3rPPZk9PSwuDHU4+eed1so7V66+H/eyuPzvWjR8fBnnAzl9yevTIPufyjjuiU75ou+yy8PqTk7NPddzPFNQiBdm2LTQv74Hff3d/9dWdx2xlZITs6Nw55N2ZjSf4yuRavsnK+y38w8uwxSHk3mmnub/xhvs9d2f6SQ2+86c530fTz8uxKVelOzk5tEDedFP4zLzvPvfRZw/3bSnlfW2l+v7SCSM8Lam0/9zlHH/uuVCuf/0rnJJ82mm5z3Hvw8fu4NP/PCw0HPTpE4Ipqyl73LhQYz/ssHCeekpKWPHQQ0PNtSC33BLWy9uE8fzz7uDrOvd2B8+8/4HQ/G/mftttuZfdsCF8Ubninp23P2NGdlkqVAg12r59w/Pu3UMtvHfYh19/fe5BiHktWuR+1FFh2dNP33nZq68OAZbVEpLl+utDGdauDfOSk8MZC/Fo1qzwBefgg8OXs549s1uSJk4Mx+a//w3HtGnTxDu/PC0ttJ60bRuOxeOPF8tuFdQi0bJypfvy5b5+vfvkye5jx+7cNZ2ZGSqMDz0UWrhnzQoVx/HjQxa0ahVyMGeAt2Oqz6GJO/hmynp9FuaaX66c+0EHuQ8a5P7MM6Hr95NP3N+vcoZvpbTfc1DoEx55xIP+97+Hiu9ll7m/2vlfnoH5nKqd/N0W1/s9vT/wa67Y7v/6l/tbb7l//312xdg95NaHl77jDn7LkRN98eLIjC+/9MyUFJ/VuI8ns93HcpyvKVXNH7vkxxDaTz6VaxtXXum+imr+KJf5rbfm6N7PzPTtPXv7lnJV/fPLRnjGRZeEZufy5d3//e/soN2+PbsW1L9/nqaIiJEjQx90+fKe+cyzvnFDPgE0ZUrYxhNP5J7erFloOchy7LF7HWIbFq7xDWPHhy6OqVPDBWAK6qcpaitXhoCuUSO80Z56KrzeESPC/FNPDQM7NmzY8UXLJ0wonrLFig8+CK/7nXfcW7Z079WrWHaroBYpAdLSQuV39erwuZ65YqX7GWd4xn8f8bVrQ3fijBmhhbyg/EhbuNS3lqviDr60VF2vUWGzJyWFSmRqaji9vF3zrd6yZWgVOOig0DOQ80tAUlL4/Dr22HBmVj0WuYNfm/Ifb11loX93wZOeUT3VF1Zs7lVZ7Rdc4D7i/6Z6Bubj6OUOflb10T5kSOg6r107VLIXprb3HxoM2FGJnzLFfcSfwul1F/LkjlOdX3k509O37nx61OrV7vNvetwzkpL9j5ot/W8DZ/lxx7k/99+NnvaXCz3rdLfJr8707t3DPvv3D13TO7qbMzPDN6MOHbL7rmfMCOs+8kj2zp54wh18/cR8+vR34bfPFvqipIa5D2jWT506odn5ued2XnHlyjBAMW8zzp5Yty60lpQpkx2+6enu7dqFP/yMGWGMRNZV7NavD1+IChp/UFKdfbZ7lSrh2/Idd4S/zYIF+323CmoRyfbYY76jebMQMjNDCE6dGipet97qPnBgGJx+2WWhYphZt65nlK+wI3RmlWrmzUrN8ocfzvGlIWv0Ovj1x/3oNcOAeu/WLbQ2+JAh7qVK+bSTh3q1SmlenZX+BzX819RD/KcfM3zkyJApkN2d3rp1KEe17DF9fgSf+wpSfY1V89tqPuYzaeYZmH9x6I3+5xO3OYQxZFdeGbIRwheSoUNDN3zma6+HFO/WzdMWL/eV1//THfzthxb43Xe7n3OO+7HtlnoG5rdyux97rPv//hcq9du2uX/2WWgpv/ji3Lk68f1VPqNUK19nlf2RXm/4wOT3/ST+5//u9JIvv+ofod8+a6DD3/7mK5al+6RJ7pm/zMi+VG6VKns0cG7KFPeHH3bf+tvvoSk3OTm79pzlk0/Cths0CPMXLsyeN2RI2Ode1PinTHGfPn2PV4uuzZvDBRnOOy88zzqr4f779/uuFdQiki0zM4zkLsq+x9tvdz/ySE//533+5NXTvXmzzJ3PFJs/P3sA06pVnpERJu2oza5btyPMt3Q+1H9qcapnJiXlGsSWkRFy5qyzQhfzKaeEs70uvdT9gQdCa+W0ae6bf54TUhx8S80Gfsuhn7tZaB24887sbvlt29yHDw/dsVnXmDnoIPe7uo30zVbO59DEf6aVT6ZTrorvMce4z63X05fUaucN6mfu+PKQ1fqQkhIqo+B+5JHu9w7d5BPtEN9qZXzJa5+7e7iQ3G23hZbmpKTQPb5mRZpv/MsV7uDvJp3of+JdX1eqim+pVNPTXhvhfuCBnlGpsk9+9Bt/8skwPOCMM0KX/QMPZFf8li51/8tfwmvqzCT/I7mOp1eqkmvU/5QpoTtjxgz3jOP/FAp75pm5/mQbRoYQf+OU4dndGjksWRKGNuTsafjxR/cTTvAdXTDvveeh5j5jRhjrUMjR8hlbt/uCP//NF//pIs/cvKXgBbMGFl54YWh52BdvvhkKnvPiQN26hQsP7We7CmoL82NHly5dfPLkydEuhojsD7feGu6h+vvv4Rrf+XntNbj00nBnruuvh/vu27t9bdgAr78Op50G1aqxaFG4tkn16vkvvnw5jBoV7s++YAEMqPkdQycfT8XNK5h7zu2k33Ib9euHy5sD4Try11yDN2rEwqZHMmr9kWTUrkfXrtCho+HbtjPunTV8M3Y1R659hyP4gs0vvEmlc07Otd+VK8NhefJJqFYNNm2CS7Y/zIP+V0rh/FamDcdse5/tdQ6gbvpC3lzZmxqsZDCvM6HUEaQ2qkD58uES9yls55R2syn12wwO2j6TE5vPoN2c/7E4vTanlBnNZY+0Ij09XI9/ypTsMrQuPYs3kwbx364vsfWg1tSoEe4S+9knmcxKb8wMWnJz+Ye57uw/OK3PatbUas5dbzXnyadsx3V4WjR32tVaxnvjq1K6SjmuvRY+H7mOjlOfY1iNR6i8Yi4AnpLCttR6/NH0UOZ1PZ35LfqSmVKG1FRITQ233/3g9TUc+eip9Nz2GQBTKh7BksdGMuDMqmzYEC45//XXsPXX3xn05aV0WDIWgCWlG3NJ3XeZvL0dBxwQbq7XsWO4vs68eeHmegsWhOsDpadDRga0bRtu19u+PXDKKWR+NZF/X7uIZ19IolMneKjJQ9T4xzUwYwa0aEFaGnz2GRx6KFSqtHdvzfyY2RR375LvPAW1iBQb9/AJmZKy6+XmzYM33oCrrgrpGi1z58I//xmu3Fa3bu556enwzDPhimXjxsGqVQVuJjOlNBn/eZSUSy8ocJmpU8NuatWCG26Ag34bCx9+SObtdzJ2QiWefTYETo/6Cznr2SMpv3QOboY1bQoHHcT2Wb+TNG8WSZk5rozXqBF0786Sm//LoKtrM358mNy2LVx8MXTrFgJ+2rTwe/ly+OOPcKfU+vXhlFPgryv+Tv0X796pvPM5gPnN+1K7+wGUmvQtted8TdXtf4TXW7MWpQ5ohM+ciW3cyAR68vsR57Bt3VbWzlhCnW2/cywfUYNVrKMyoxnARA7lO7qxmfK8zSkcaPOYcvHTbMkoTc+nz+E3mnFW6gfMWlWdTkyhj33G9dwPwH/r3M2c6l25Z/apVExfywuHP8e0NQ1pMmMMR20fSz2WsIw6rEqpy4Yq9VlWsSmLK7ZgQbnmfDytNmu3laVXt228P6UOzyZdzKXb/0OPHuF+PjXSljI/vT5zTrmB5/kLMz9aSOUNixj48NGcdGWDwryLCkVBLSKyP2VmhhrX2rXhywiE69tWrx6qiVWqhOdFZd26UK2bNi38zJkDjRtDq1bhp2VLaN4812Va09NDa8EBB0D37gU3aEB4CTvmr10bWiYqV2bS/Jo8/WZVepb/gVMqfkDFrz8J93w/+OBQxezcObSE/P57+Klfn7SLL+fCxzvz4otQr164wV2/ftD0gDSq/fAp1T4YTtkvPiB55fId+8+oXoOkd9+Bww4Lzz/6lMwTTyItDcpmbKaUZ4QF+/ULd8074IDwfOnS8O3i66/D6yhViq0dD2Fzw+ZU3rKclBVLYdGi8G2kALcc9Q0n39udLl3CFXzvuANOe/Jo+vBpruW2v/YWpQefUqg/V2EoqEVEpOht3x7a6qtV2+Vi7iEba9Uq4AuCewjQ774Lt64dNAiaNMm9zNSp4fa1jRuHW7l26xY2mNe2bfDss+FWr8cck3/Z1q2DX3+FmTPDNc23bsW3bGVbpRqU/dvlOxXy97G/sO1/o2l8aD1KH9gg3KK1YUMoXXqXr3tPKKhFRERi2K6CulB3zzKzvmb2q5nNNrOb8plfxszeiMz/1swa55h3c2T6r2Z23F6/ChERkQS026A2syTgUaAf0AoYbGat8ix2PrDG3ZsC/wbujazbChgEtAb6Ao9FticiIiKFUJgadTdgtrvPdfftwHBgYJ5lBgIvRh6/BfQxM4tMH+7u29x9HjA7sj0REREphMIEdX1gYY7niyLT8l3G3dOBdUBqIdfFzC4ys8lmNnnFihWFL72IiEgJV6g+6v3N3Z9y9y7u3qVmzZrRLo6IiEjMKExQLwYa5njeIDIt32XMLBmoAqwq5LoiIiJSgMIE9STgYDNrYmalCYPDRuVZZhRwTuTxqcBnkWuXjgIGRUaFNwEOBr4rmqKLiIiUfLu9VI67p5vZFcCHQBLwnLtPN7M7CBcRHwU8C7xsZrOB1YQwJ7LcCOAXIB243D3rkjIiIiKyO7rgiYiISJTt8wVPREREJDoU1CIiIjFMQS0iIhLDFNQiIiIxLOYGk5nZCuD3It5sDWBlEW8znul45KbjkZuOx850THLT8citKI7HAe6e7xW/Yi6o9wczm1zQaLpEpOORm45HbjoeO9MxyU3HI7f9fTzU9C0iIhLDFNQiIiIxLFGC+qloFyDG6HjkpuORm47HznRMctPxyG2/Ho+E6KMWERGJV4lSoxYREYlLJTqozayvmf1qZrPN7KZol6e4mVlDM/vczH4xs+lmdnVkenUz+9jMZkV+V4t2WYuTmSWZ2Q9m9n7keRMz+zbyPnkjcpe4hGFmVc3sLTObaWYzzOyQRH6PmNk1kf+Xn83sdTMrm0jvETN7zsz+MLOfc0zL9/1gwcOR4zLNzDpFr+T7TwHH5P7I/8w0M3vHzKrmmHdz5Jj8ambH7ev+S2xQm1kS8CjQD2gFDDazVtEtVbFLB/7m7q2AHsDlkWNwE/Cpux8MfBp5nkiuBmbkeH4v8G93bwqsAc6PSqmi5z/AB+7eAmhPODYJ+R4xs/rAVUAXd29DuGPgIBLrPfIC0DfPtILeD/0Ity8+GLgIeLyYyljcXmDnY/Ix0Mbd2wG/ATcDRD5jBwGtI+s8FsmjvVZigxroBsx297nuvh0YDgyMcpmKlbsvdffvI483ED6A6xOOw4uRxV4EToxKAaPAzBoAA4BnIs8NOAp4K7JIoh2PKkAvwq1qcfft7r6WBH6PEG7/W87MkoHywFIS6D3i7l8SblecU0Hvh4HASx58A1Q1s7rFUtBilN8xcfeP3D098vQboEHk8UBguLtvc/d5wGxCHu21khzU9YGFOZ4vikxLSGbWGOgIfAvUdvelkVnLgNrRKlcUPATcAGRGnqcCa3P8wyXa+6QJsAJ4PtId8IyZVSBB3yPuvhh4AFhACOh1wBQS+z0CBb8f9DkbnAeMjTwu8mNSkoNaIsysIvA28Fd3X59znodh/wkx9N/Mjgf+cPcp0S5LDEkGOgGPu3tHYBN5mrkT7D1SjVAjagLUAyqwc5NnQkuk90NhmNnfCd2Mr+6vfZTkoF4MNMzxvEFkWkIxsxRCSL/q7v+LTF6e1TwV+f1HtMpXzHoCJ5jZfEJXyFGE/tmqkWZOSLz3ySJgkbt/G3n+FiG4E/U9cjQwz91XuHsa8D/C+yaR3yNQ8PshoT9nzexc4HjgTM8+17nIj0lJDupJwMGR0ZqlCZ37o6JcpmIV6X99Fpjh7g/mmDUKOCfy+Bzg3eIuWzS4+83u3sDdGxPeD5+5+5nA58CpkcUS5ngAuPsyYKGZNY9M6gP8QoK+RwhN3j3MrHzk/yfreCTseySioPfDKODsyOjvHsC6HE3kJZqZ9SV0o53g7ptzzBoFDDKzMmbWhDDQ7rt92pm7l9gfoD9hNN4c4O/RLk8UXv9hhCaqacDUyE9/Qr/sp8As4BOgerTLGoVj0xt4P/L4wMg/0mzgTaBMtMtXzMeiAzA58j4ZCVRL5PcIcDswE/gZeBkok0jvEeB1Qv98GqHF5fyC3g+AEc6umQP8RBgtH/XXUEzHZDahLzrrs/WJHMv/PXJMfgX67ev+dWUyERGRGFaSm75FRETinoJaREQkhimoRUREYpiCWkREJIYpqEVERGKYglpERCSGKahFRERimIJaREQkhv0/8hS6udGNfuQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  6.968963843249808\n",
      "MAE:  2.4432913039452773\n",
      "R-Squared:  -5.969029505803806\n",
      "Explained Variance Score:  -0.0038173452578897926\n"
     ]
    }
   ],
   "source": [
    "model_name = 'dense_model_kinect_ExreciseScore'\n",
    "\n",
    "with mlflow.start_run(run_name=model_name) as run:\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    model = make_model(metrics=METRICS, \n",
    "                        loss='mean_squared_error', \n",
    "                        optimizer=optimizer, \n",
    "                        learning_rate=learning_rate, \n",
    "                        input_dim=input_dim)\n",
    "    \n",
    "    with tf.device('/CPU:0'):\n",
    "        history = model.fit(\n",
    "            x=X_train, \n",
    "            y=y_train, \n",
    "            shuffle=True, \n",
    "            epochs=EPOCHS, \n",
    "            verbose=1,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stopping])\n",
    "\n",
    "    # Plot training history\n",
    "    plot_train_history(history, 'Baseline Training and validation loss')\n",
    "    plt.savefig(\"training_history.jpg\")\n",
    "    mlflow.log_artifact(\"training_history.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Log model, scaler, model parameters to MLflow\n",
    "    #mlflow.log_param(\"activation\", activation)\n",
    "    #mlflow.log_param(\"kernel_initializer\", kernel_initializer)\n",
    "    #mlflow.log_param(\"output activation\", output_activation)\n",
    "    #mlflow.log_param(\"optimizer\", optimizer)\n",
    "    #mlflow.log_param(\"learning rate\", learning_rate)\n",
    "    #mlflow.log_param(\"batch size\", BATCH_SIZE)\n",
    "    #mlflow.log_param(\"epochs\", early_stopping.stopped_epoch)\n",
    "        \n",
    "    #mlflow.log_param(\"input_mean_train\", input_mean_train)\n",
    "    #mlflow.log_param(\"input_std_train\", input_std_train)\n",
    "    #mlflow.log_param(\"input_mean_test\", input_mean_test)\n",
    "    #mlflow.log_param(\"input_std_test\", input_std_test)\n",
    "    #mlflow.log_param(\"output_mean\", output_mean)\n",
    "    #mlflow.log_param(\"output_std\", output_std)\n",
    "\n",
    "    # Log model performance\n",
    "    process_time = [None] * 10\n",
    "    \n",
    "    for i in range(10):\n",
    "        start_time = time.time()\n",
    "        predictions = model.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        process_time[i] = (end_time - start_time) * 1000\n",
    "    \n",
    "    predictions = (predictions * output_std_train.to_numpy()) + output_mean_train.to_numpy()\n",
    "    \n",
    "    output_mean_test = y_test.mean()\n",
    "    output_std_test = y_test.std()\n",
    "    y_test = (y_test - output_mean_test) / output_std_test\n",
    "    y_test.to_numpy()\n",
    "    \n",
    "    (mse, mae, r2, variance) = eval_metrics(y_test, predictions)\n",
    "    #mlflow.log_metric(\"mse\", mse)\n",
    "    #mlflow.log_metric(\"mae\", mae)\n",
    "    #mlflow.log_metric(\"R-squared\", r2)\n",
    "    #mlflow.log_metric(\"variance\", variance)\n",
    "    #mlflow.log_param(\"total params\", model.count_params())\n",
    "    #mlflow.log_metric(\"process time\", np.mean(process_time)) \n",
    "    \n",
    "    #mlflow.keras.log_model(model, model_name, signature=signature)\n",
    "\n",
    "    # Print metrics\n",
    "    print('MSE: ', mse)\n",
    "    print('MAE: ', mae)\n",
    "    print('R-Squared: ', r2)\n",
    "    print('Explained Variance Score: ', variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = \"runs:/{}/{}\".format(run.info.run_id, model_name)\n",
    "mv = mlflow.register_model(model_uri, model_name)\n",
    "print(\"Name: {}\".format(mv.name))\n",
    "print(\"Version: {}\".format(mv.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
