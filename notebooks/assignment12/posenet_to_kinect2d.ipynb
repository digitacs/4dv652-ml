{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd04cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# PoseNet 2D to Kinect 2D"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://35.228.45.76:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 47\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "posenetDataPath = '../../datasets/posenet-uncut/'\n",
    "kinectDataPath = '../../datasets/kinect_good_preprocessed_not_cut/'\n",
    "\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "train_test_ratio = 0.8"
   ]
  },
  {
   "source": [
    "## 1. Data Preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Load matching files from PoseNet and Kinect"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(30502, 26)\n(30502, 26)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for file in os.listdir(posenetDataPath):\n",
    "    if file.endswith('.csv'):\n",
    "        try:\n",
    "            posenetData = pd.read_csv(posenetDataPath + file)\n",
    "            kinectData = pd.read_csv(kinectDataPath + '{}_kinect.csv'.format(file.replace('.csv', '')))\n",
    "            # Check amount of frames\n",
    "            if (len(posenetData) == len(kinectData)):\n",
    "                posenetData.drop(columns=['FrameNo'], inplace=True)\n",
    "                if X is None:\n",
    "                    X = posenetData\n",
    "                else:\n",
    "                    X = pd.concat((X, posenetData), ignore_index=True)\n",
    "\n",
    "                # Drop Z-columns from Kinect\n",
    "                z = []\n",
    "                for c in kinectData.columns:\n",
    "                    if re.search(\"^.*_z$\", c):\n",
    "                        z.append(c)\n",
    "                kinectData.drop(columns=z, inplace=True)\n",
    "                kinectData.drop(columns=['FrameNo'], inplace=True)\n",
    "                if y is None:\n",
    "                    y = kinectData\n",
    "                else:\n",
    "                    y = pd.concat((y, kinectData), ignore_index=True)\n",
    "        except IOError as e:\n",
    "            print('Error in reading file: ', e)\n",
    "            logger.exception(\n",
    "            \"Unable to download training & test CSV, check your internet connection. Error: %s\", e)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "source": [
    "### Training and test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(24401, 26)\n(24401, 26)\n(6101, 26)\n(6101, 26)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, train_size=train_test_ratio, random_state=random_state)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "source": [
    "### Scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(y_train)"
   ]
  },
  {
   "source": [
    "## 2. DL Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Early Stopping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-959fb65cefde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Early stopping parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Early stopping parameters\n",
    "monitor = 'val_loss'\n",
    "verbose = 1\n",
    "patience = 20\n",
    "mode = 'min'\n",
    "restore_best_weights = True\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor, \n",
    "    verbose=verbose,\n",
    "    patience=patience,\n",
    "    mode=mode,\n",
    "    restore_best_weights=restore_best_weights)"
   ]
  },
  {
   "source": [
    "### Layer Factory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Dropout, Flatten\n",
    "\n",
    "def layerFactory(type, nodes, activation):\n",
    "    if type == 'Dense':\n",
    "        if not activation:\n",
    "            return Dense(units=nodes)\n",
    "        else:\n",
    "            return Dense(units=nodes, activation=activation)\n",
    "    if type == 'Conv1D':\n",
    "        if not activation:\n",
    "            return Conv1D(units=nodes)\n",
    "        else:\n",
    "            return Conv1D(units=nodes, activation=activation)\n",
    "    if type == 'MaxPooling1D':\n",
    "        if not activation:\n",
    "            return MaxPooling1D(units=nodes)\n",
    "        else:\n",
    "            return MaxPooling1D(units=nodes, activation=activation)\n",
    "    if type == 'Dropout':\n",
    "        if not activation:\n",
    "            return Dropout(units=nodes)\n",
    "        else:\n",
    "            return Dropout(units=nodes, activation=activation)\n",
    "    if type == 'Flatten':\n",
    "        if not activation:\n",
    "            return Flatten(units=nodes)\n",
    "        else:\n",
    "            return Flatten(units=nodes, activation=activation)\n",
    "    \n",
    "    # otherwise return dense as default\n",
    "    return Dense(units=nodes, activation=activation)"
   ]
  },
  {
   "source": [
    "### Model Architecture"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "\n",
    "def create_model(optimizer):\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=(input_dim))\n",
    "    ])\n",
    "\n",
    "    for layer in layers:\n",
    "        model.add(layerFactory(layer['type'], layer['nodes'], layer['activation']))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.get(optimizer)\n",
    "    optimizer.learning_rate.assign(learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "source": [
    "## 3. Evaluation metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, mean_absolute_error\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    msa = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    variance = explained_variance_score(actual, pred)\n",
    "    return mse, msa, r2, variance"
   ]
  },
  {
   "source": [
    "## 4. MLFlow Experimentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                1728      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                1690      \n",
      "=================================================================\n",
      "Total params: 7,578\n",
      "Trainable params: 7,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "1220/1220 [==============================] - 1s 892us/step - loss: 0.3946 - mae: 0.4032 - val_loss: 0.1399 - val_mae: 0.2496\n",
      "Epoch 2/500\n",
      "1220/1220 [==============================] - 1s 756us/step - loss: 0.1390 - mae: 0.2456 - val_loss: 0.1149 - val_mae: 0.2253\n",
      "Epoch 3/500\n",
      "1220/1220 [==============================] - 1s 702us/step - loss: 0.1099 - mae: 0.2192 - val_loss: 0.0986 - val_mae: 0.2136\n",
      "Epoch 4/500\n",
      "1220/1220 [==============================] - 1s 721us/step - loss: 0.1026 - mae: 0.2111 - val_loss: 0.0920 - val_mae: 0.2031\n",
      "Epoch 5/500\n",
      "1220/1220 [==============================] - 1s 754us/step - loss: 0.0938 - mae: 0.2019 - val_loss: 0.0856 - val_mae: 0.1955\n",
      "Epoch 6/500\n",
      "1220/1220 [==============================] - 1s 725us/step - loss: 0.0887 - mae: 0.1964 - val_loss: 0.0924 - val_mae: 0.1945\n",
      "Epoch 7/500\n",
      "1220/1220 [==============================] - 1s 697us/step - loss: 0.0850 - mae: 0.1916 - val_loss: 0.0790 - val_mae: 0.1885\n",
      "Epoch 8/500\n",
      "1220/1220 [==============================] - 1s 746us/step - loss: 0.0794 - mae: 0.1874 - val_loss: 0.0746 - val_mae: 0.1848\n",
      "Epoch 9/500\n",
      "1220/1220 [==============================] - 1s 746us/step - loss: 0.0802 - mae: 0.1860 - val_loss: 0.0808 - val_mae: 0.1860\n",
      "Epoch 10/500\n",
      "1220/1220 [==============================] - 1s 746us/step - loss: 0.0773 - mae: 0.1832 - val_loss: 0.0697 - val_mae: 0.1779\n",
      "Epoch 11/500\n",
      "1220/1220 [==============================] - 1s 745us/step - loss: 0.0715 - mae: 0.1781 - val_loss: 0.0714 - val_mae: 0.1784\n",
      "Epoch 12/500\n",
      "1220/1220 [==============================] - 1s 709us/step - loss: 0.0695 - mae: 0.1766 - val_loss: 0.0724 - val_mae: 0.1814\n",
      "Epoch 13/500\n",
      "1220/1220 [==============================] - 1s 794us/step - loss: 0.0723 - mae: 0.1776 - val_loss: 0.0654 - val_mae: 0.1731\n",
      "Epoch 14/500\n",
      "1220/1220 [==============================] - 1s 795us/step - loss: 0.0676 - mae: 0.1728 - val_loss: 0.0739 - val_mae: 0.1759\n",
      "Epoch 15/500\n",
      "1220/1220 [==============================] - 1s 683us/step - loss: 0.0688 - mae: 0.1729 - val_loss: 0.0638 - val_mae: 0.1703\n",
      "Epoch 16/500\n",
      "1220/1220 [==============================] - 1s 686us/step - loss: 0.0666 - mae: 0.1715 - val_loss: 0.0648 - val_mae: 0.1719\n",
      "Epoch 17/500\n",
      "1220/1220 [==============================] - 1s 677us/step - loss: 0.0636 - mae: 0.1695 - val_loss: 0.0698 - val_mae: 0.1704\n",
      "Epoch 18/500\n",
      "1220/1220 [==============================] - 1s 883us/step - loss: 0.0634 - mae: 0.1679 - val_loss: 0.0667 - val_mae: 0.1703\n",
      "Epoch 19/500\n",
      "1220/1220 [==============================] - 1s 752us/step - loss: 0.0629 - mae: 0.1675 - val_loss: 0.0606 - val_mae: 0.1686\n",
      "Epoch 20/500\n",
      "1220/1220 [==============================] - 1s 714us/step - loss: 0.0618 - mae: 0.1664 - val_loss: 0.0615 - val_mae: 0.1669\n",
      "Epoch 21/500\n",
      "1220/1220 [==============================] - 1s 882us/step - loss: 0.0591 - mae: 0.1639 - val_loss: 0.0590 - val_mae: 0.1639\n",
      "Epoch 22/500\n",
      "1220/1220 [==============================] - 1s 753us/step - loss: 0.0611 - mae: 0.1652 - val_loss: 0.0593 - val_mae: 0.1645\n",
      "Epoch 23/500\n",
      "1220/1220 [==============================] - 1s 803us/step - loss: 0.0599 - mae: 0.1638 - val_loss: 0.0616 - val_mae: 0.1646\n",
      "Epoch 24/500\n",
      "1220/1220 [==============================] - 1s 862us/step - loss: 0.0599 - mae: 0.1620 - val_loss: 0.0633 - val_mae: 0.1646\n",
      "Epoch 25/500\n",
      "1220/1220 [==============================] - 1s 687us/step - loss: 0.0599 - mae: 0.1621 - val_loss: 0.0565 - val_mae: 0.1626\n",
      "Epoch 26/500\n",
      "1220/1220 [==============================] - 1s 706us/step - loss: 0.0573 - mae: 0.1604 - val_loss: 0.0591 - val_mae: 0.1648\n",
      "Epoch 27/500\n",
      "1220/1220 [==============================] - 1s 689us/step - loss: 0.0598 - mae: 0.1622 - val_loss: 0.0565 - val_mae: 0.1612\n",
      "Epoch 28/500\n",
      "1220/1220 [==============================] - 1s 706us/step - loss: 0.0576 - mae: 0.1600 - val_loss: 0.0561 - val_mae: 0.1601\n",
      "Epoch 29/500\n",
      "1220/1220 [==============================] - 1s 721us/step - loss: 0.0592 - mae: 0.1592 - val_loss: 0.0565 - val_mae: 0.1600\n",
      "Epoch 30/500\n",
      "1220/1220 [==============================] - 1s 714us/step - loss: 0.0568 - mae: 0.1592 - val_loss: 0.0557 - val_mae: 0.1593\n",
      "Epoch 31/500\n",
      "1220/1220 [==============================] - 1s 837us/step - loss: 0.0574 - mae: 0.1586 - val_loss: 0.0553 - val_mae: 0.1583\n",
      "Epoch 32/500\n",
      "1220/1220 [==============================] - 1s 708us/step - loss: 0.0566 - mae: 0.1581 - val_loss: 0.0640 - val_mae: 0.1635\n",
      "Epoch 33/500\n",
      "1220/1220 [==============================] - 1s 778us/step - loss: 0.0549 - mae: 0.1571 - val_loss: 0.0561 - val_mae: 0.1590\n",
      "Epoch 34/500\n",
      "1220/1220 [==============================] - 1s 839us/step - loss: 0.0540 - mae: 0.1560 - val_loss: 0.0535 - val_mae: 0.1566\n",
      "Epoch 35/500\n",
      "1220/1220 [==============================] - 1s 689us/step - loss: 0.0523 - mae: 0.1546 - val_loss: 0.0518 - val_mae: 0.1539\n",
      "Epoch 36/500\n",
      "1220/1220 [==============================] - 1s 697us/step - loss: 0.0544 - mae: 0.1565 - val_loss: 0.0543 - val_mae: 0.1579\n",
      "Epoch 37/500\n",
      "1220/1220 [==============================] - 1s 694us/step - loss: 0.0548 - mae: 0.1564 - val_loss: 0.0559 - val_mae: 0.1589\n",
      "Epoch 38/500\n",
      "1220/1220 [==============================] - 1s 701us/step - loss: 0.0540 - mae: 0.1551 - val_loss: 0.0545 - val_mae: 0.1580\n",
      "Epoch 39/500\n",
      "1220/1220 [==============================] - 1s 701us/step - loss: 0.0534 - mae: 0.1537 - val_loss: 0.0540 - val_mae: 0.1576\n",
      "Epoch 40/500\n",
      "1220/1220 [==============================] - 1s 710us/step - loss: 0.0513 - mae: 0.1525 - val_loss: 0.0538 - val_mae: 0.1576\n",
      "Epoch 41/500\n",
      "1220/1220 [==============================] - 1s 698us/step - loss: 0.0513 - mae: 0.1531 - val_loss: 0.0539 - val_mae: 0.1557\n",
      "Epoch 42/500\n",
      "1220/1220 [==============================] - 1s 702us/step - loss: 0.0511 - mae: 0.1518 - val_loss: 0.0572 - val_mae: 0.1614\n",
      "Epoch 43/500\n",
      "1220/1220 [==============================] - 1s 699us/step - loss: 0.0501 - mae: 0.1516 - val_loss: 0.0523 - val_mae: 0.1528\n",
      "Epoch 44/500\n",
      "1220/1220 [==============================] - 1s 698us/step - loss: 0.0520 - mae: 0.1529 - val_loss: 0.0517 - val_mae: 0.1549\n",
      "Epoch 45/500\n",
      "1220/1220 [==============================] - 1s 736us/step - loss: 0.0506 - mae: 0.1518 - val_loss: 0.0499 - val_mae: 0.1522\n",
      "Epoch 46/500\n",
      "1220/1220 [==============================] - 1s 799us/step - loss: 0.0508 - mae: 0.1509 - val_loss: 0.0509 - val_mae: 0.1529\n",
      "Epoch 47/500\n",
      "1220/1220 [==============================] - 1s 736us/step - loss: 0.0501 - mae: 0.1510 - val_loss: 0.0526 - val_mae: 0.1539\n",
      "Epoch 48/500\n",
      "1220/1220 [==============================] - 1s 812us/step - loss: 0.0511 - mae: 0.1519 - val_loss: 0.0508 - val_mae: 0.1511\n",
      "Epoch 49/500\n",
      "1220/1220 [==============================] - 1s 817us/step - loss: 0.0505 - mae: 0.1504 - val_loss: 0.0515 - val_mae: 0.1522\n",
      "Epoch 50/500\n",
      "1220/1220 [==============================] - 1s 707us/step - loss: 0.0498 - mae: 0.1507 - val_loss: 0.0548 - val_mae: 0.1597\n",
      "Epoch 51/500\n",
      "1220/1220 [==============================] - 1s 1ms/step - loss: 0.0495 - mae: 0.1497 - val_loss: 0.0496 - val_mae: 0.1506\n",
      "Epoch 52/500\n",
      "1220/1220 [==============================] - 1s 706us/step - loss: 0.0501 - mae: 0.1497 - val_loss: 0.0502 - val_mae: 0.1519\n",
      "Epoch 53/500\n",
      "1220/1220 [==============================] - 1s 708us/step - loss: 0.0529 - mae: 0.1517 - val_loss: 0.0500 - val_mae: 0.1503\n",
      "Epoch 54/500\n",
      "1220/1220 [==============================] - 1s 712us/step - loss: 0.0503 - mae: 0.1497 - val_loss: 0.0495 - val_mae: 0.1490\n",
      "Epoch 55/500\n",
      "1220/1220 [==============================] - 1s 704us/step - loss: 0.0491 - mae: 0.1482 - val_loss: 0.0496 - val_mae: 0.1521\n",
      "Epoch 56/500\n",
      "1220/1220 [==============================] - 1s 719us/step - loss: 0.0484 - mae: 0.1479 - val_loss: 0.0496 - val_mae: 0.1506\n",
      "Epoch 57/500\n",
      "1220/1220 [==============================] - 1s 774us/step - loss: 0.0482 - mae: 0.1471 - val_loss: 0.0474 - val_mae: 0.1476\n",
      "Epoch 58/500\n",
      "1220/1220 [==============================] - 1s 735us/step - loss: 0.0499 - mae: 0.1495 - val_loss: 0.0477 - val_mae: 0.1487\n",
      "Epoch 59/500\n",
      "1220/1220 [==============================] - 1s 743us/step - loss: 0.0485 - mae: 0.1472 - val_loss: 0.0496 - val_mae: 0.1509\n",
      "Epoch 60/500\n",
      "1220/1220 [==============================] - 1s 778us/step - loss: 0.0485 - mae: 0.1481 - val_loss: 0.0485 - val_mae: 0.1489\n",
      "Epoch 61/500\n",
      "1220/1220 [==============================] - 1s 723us/step - loss: 0.0480 - mae: 0.1474 - val_loss: 0.0501 - val_mae: 0.1514\n",
      "Epoch 62/500\n",
      "1220/1220 [==============================] - 1s 704us/step - loss: 0.0478 - mae: 0.1463 - val_loss: 0.0479 - val_mae: 0.1480\n",
      "Epoch 63/500\n",
      "1220/1220 [==============================] - 1s 707us/step - loss: 0.0466 - mae: 0.1460 - val_loss: 0.0469 - val_mae: 0.1471\n",
      "Epoch 64/500\n",
      "1220/1220 [==============================] - 1s 713us/step - loss: 0.0475 - mae: 0.1466 - val_loss: 0.0479 - val_mae: 0.1475\n",
      "Epoch 65/500\n",
      "1220/1220 [==============================] - 1s 768us/step - loss: 0.0444 - mae: 0.1439 - val_loss: 0.0481 - val_mae: 0.1480\n",
      "Epoch 66/500\n",
      "1220/1220 [==============================] - 1s 778us/step - loss: 0.0466 - mae: 0.1455 - val_loss: 0.0482 - val_mae: 0.1477\n",
      "Epoch 67/500\n",
      "1220/1220 [==============================] - 1s 737us/step - loss: 0.0473 - mae: 0.1460 - val_loss: 0.0472 - val_mae: 0.1484\n",
      "Epoch 68/500\n",
      "1220/1220 [==============================] - 1s 708us/step - loss: 0.0476 - mae: 0.1467 - val_loss: 0.0468 - val_mae: 0.1467\n",
      "Epoch 69/500\n",
      "1220/1220 [==============================] - 1s 1ms/step - loss: 0.0453 - mae: 0.1437 - val_loss: 0.0542 - val_mae: 0.1516\n",
      "Epoch 70/500\n",
      "1220/1220 [==============================] - 1s 878us/step - loss: 0.0468 - mae: 0.1447 - val_loss: 0.0474 - val_mae: 0.1471\n",
      "Epoch 71/500\n",
      "1220/1220 [==============================] - 1s 886us/step - loss: 0.0464 - mae: 0.1446 - val_loss: 0.0471 - val_mae: 0.1471\n",
      "Epoch 72/500\n",
      "1220/1220 [==============================] - 1s 836us/step - loss: 0.0464 - mae: 0.1453 - val_loss: 0.0563 - val_mae: 0.1524\n",
      "Epoch 73/500\n",
      "1220/1220 [==============================] - 1s 780us/step - loss: 0.0484 - mae: 0.1459 - val_loss: 0.0464 - val_mae: 0.1470\n",
      "Epoch 74/500\n",
      "1220/1220 [==============================] - 1s 768us/step - loss: 0.0449 - mae: 0.1431 - val_loss: 0.0467 - val_mae: 0.1473\n",
      "Epoch 75/500\n",
      "1220/1220 [==============================] - 1s 772us/step - loss: 0.0463 - mae: 0.1445 - val_loss: 0.0477 - val_mae: 0.1474\n",
      "Epoch 76/500\n",
      "1220/1220 [==============================] - 1s 765us/step - loss: 0.0474 - mae: 0.1447 - val_loss: 0.0453 - val_mae: 0.1446\n",
      "Epoch 77/500\n",
      "1220/1220 [==============================] - 1s 787us/step - loss: 0.0447 - mae: 0.1435 - val_loss: 0.0466 - val_mae: 0.1450\n",
      "Epoch 78/500\n",
      "1220/1220 [==============================] - 1s 780us/step - loss: 0.0452 - mae: 0.1437 - val_loss: 0.0510 - val_mae: 0.1514\n",
      "Epoch 79/500\n",
      "1220/1220 [==============================] - 1s 811us/step - loss: 0.0490 - mae: 0.1461 - val_loss: 0.0454 - val_mae: 0.1438\n",
      "Epoch 80/500\n",
      "1220/1220 [==============================] - 1s 762us/step - loss: 0.0464 - mae: 0.1439 - val_loss: 0.0467 - val_mae: 0.1471\n",
      "Epoch 81/500\n",
      "1220/1220 [==============================] - 1s 799us/step - loss: 0.0450 - mae: 0.1433 - val_loss: 0.0485 - val_mae: 0.1491\n",
      "Epoch 82/500\n",
      "1220/1220 [==============================] - 1s 771us/step - loss: 0.0460 - mae: 0.1434 - val_loss: 0.0577 - val_mae: 0.1518\n",
      "Epoch 83/500\n",
      "1220/1220 [==============================] - 1s 784us/step - loss: 0.0448 - mae: 0.1430 - val_loss: 0.0479 - val_mae: 0.1471\n",
      "Epoch 84/500\n",
      "1220/1220 [==============================] - 1s 766us/step - loss: 0.0461 - mae: 0.1441 - val_loss: 0.0457 - val_mae: 0.1441\n",
      "Epoch 85/500\n",
      "1220/1220 [==============================] - 1s 818us/step - loss: 0.0455 - mae: 0.1430 - val_loss: 0.0452 - val_mae: 0.1448\n",
      "Epoch 86/500\n",
      "1220/1220 [==============================] - 1s 748us/step - loss: 0.0452 - mae: 0.1432 - val_loss: 0.0449 - val_mae: 0.1437\n",
      "Epoch 87/500\n",
      "1220/1220 [==============================] - 1s 757us/step - loss: 0.0450 - mae: 0.1426 - val_loss: 0.0454 - val_mae: 0.1451\n",
      "Epoch 88/500\n",
      "1220/1220 [==============================] - 1s 737us/step - loss: 0.0452 - mae: 0.1416 - val_loss: 0.0462 - val_mae: 0.1474\n",
      "Epoch 89/500\n",
      "1220/1220 [==============================] - 1s 742us/step - loss: 0.0453 - mae: 0.1424 - val_loss: 0.0457 - val_mae: 0.1452\n",
      "Epoch 90/500\n",
      "1220/1220 [==============================] - 1s 758us/step - loss: 0.0450 - mae: 0.1418 - val_loss: 0.0450 - val_mae: 0.1439\n",
      "Epoch 91/500\n",
      "1220/1220 [==============================] - 1s 746us/step - loss: 0.0442 - mae: 0.1414 - val_loss: 0.0465 - val_mae: 0.1443\n",
      "Epoch 92/500\n",
      "1220/1220 [==============================] - 1s 753us/step - loss: 0.0433 - mae: 0.1403 - val_loss: 0.0485 - val_mae: 0.1520\n",
      "Epoch 93/500\n",
      "1220/1220 [==============================] - 1s 752us/step - loss: 0.0435 - mae: 0.1414 - val_loss: 0.0449 - val_mae: 0.1443\n",
      "Epoch 94/500\n",
      "1220/1220 [==============================] - 1s 741us/step - loss: 0.0437 - mae: 0.1414 - val_loss: 0.0464 - val_mae: 0.1461\n",
      "Epoch 95/500\n",
      "1220/1220 [==============================] - 1s 763us/step - loss: 0.0439 - mae: 0.1409 - val_loss: 0.0463 - val_mae: 0.1461\n",
      "Epoch 96/500\n",
      "1220/1220 [==============================] - 1s 754us/step - loss: 0.0447 - mae: 0.1420 - val_loss: 0.0457 - val_mae: 0.1444\n",
      "Epoch 97/500\n",
      "1220/1220 [==============================] - 1s 761us/step - loss: 0.0435 - mae: 0.1409 - val_loss: 0.0460 - val_mae: 0.1461\n",
      "Epoch 98/500\n",
      "1220/1220 [==============================] - 1s 840us/step - loss: 0.0438 - mae: 0.1408 - val_loss: 0.0449 - val_mae: 0.1438\n",
      "Epoch 99/500\n",
      "1220/1220 [==============================] - 1s 795us/step - loss: 0.0443 - mae: 0.1410 - val_loss: 0.0447 - val_mae: 0.1432\n",
      "Epoch 100/500\n",
      "1220/1220 [==============================] - 1s 744us/step - loss: 0.0435 - mae: 0.1401 - val_loss: 0.0446 - val_mae: 0.1436\n",
      "Epoch 101/500\n",
      "1220/1220 [==============================] - 1s 749us/step - loss: 0.0433 - mae: 0.1403 - val_loss: 0.0460 - val_mae: 0.1459\n",
      "Epoch 102/500\n",
      "1220/1220 [==============================] - 1s 782us/step - loss: 0.0435 - mae: 0.1404 - val_loss: 0.0516 - val_mae: 0.1531\n",
      "Epoch 103/500\n",
      "1220/1220 [==============================] - 1s 745us/step - loss: 0.0432 - mae: 0.1408 - val_loss: 0.0457 - val_mae: 0.1442\n",
      "Epoch 104/500\n",
      "1220/1220 [==============================] - 1s 753us/step - loss: 0.0431 - mae: 0.1405 - val_loss: 0.0469 - val_mae: 0.1447\n",
      "Epoch 105/500\n",
      "1220/1220 [==============================] - 1s 795us/step - loss: 0.0438 - mae: 0.1404 - val_loss: 0.0439 - val_mae: 0.1421\n",
      "Epoch 106/500\n",
      "1220/1220 [==============================] - 1s 1ms/step - loss: 0.0424 - mae: 0.1398 - val_loss: 0.0459 - val_mae: 0.1439\n",
      "Epoch 107/500\n",
      "1220/1220 [==============================] - 1s 888us/step - loss: 0.0416 - mae: 0.1394 - val_loss: 0.0454 - val_mae: 0.1441\n",
      "Epoch 108/500\n",
      "1220/1220 [==============================] - 1s 824us/step - loss: 0.0427 - mae: 0.1398 - val_loss: 0.0436 - val_mae: 0.1420\n",
      "Epoch 109/500\n",
      "1220/1220 [==============================] - 1s 778us/step - loss: 0.0426 - mae: 0.1394 - val_loss: 0.0457 - val_mae: 0.1444\n",
      "Epoch 110/500\n",
      "1220/1220 [==============================] - 1s 775us/step - loss: 0.0424 - mae: 0.1391 - val_loss: 0.0486 - val_mae: 0.1465\n",
      "Epoch 111/500\n",
      "1220/1220 [==============================] - 1s 950us/step - loss: 0.0434 - mae: 0.1397 - val_loss: 0.0440 - val_mae: 0.1428\n",
      "Epoch 112/500\n",
      "1220/1220 [==============================] - 1s 925us/step - loss: 0.0426 - mae: 0.1392 - val_loss: 0.0433 - val_mae: 0.1403\n",
      "Epoch 113/500\n",
      "1220/1220 [==============================] - 1s 771us/step - loss: 0.0426 - mae: 0.1391 - val_loss: 0.0449 - val_mae: 0.1430\n",
      "Epoch 114/500\n",
      "1220/1220 [==============================] - 1s 735us/step - loss: 0.0415 - mae: 0.1387 - val_loss: 0.0450 - val_mae: 0.1447\n",
      "Epoch 115/500\n",
      "1220/1220 [==============================] - 1s 771us/step - loss: 0.0427 - mae: 0.1397 - val_loss: 0.0445 - val_mae: 0.1436\n",
      "Epoch 116/500\n",
      "1220/1220 [==============================] - 1s 787us/step - loss: 0.0423 - mae: 0.1400 - val_loss: 0.0479 - val_mae: 0.1471\n",
      "Epoch 117/500\n",
      "1220/1220 [==============================] - 1s 753us/step - loss: 0.0421 - mae: 0.1386 - val_loss: 0.0438 - val_mae: 0.1429\n",
      "Epoch 118/500\n",
      "1220/1220 [==============================] - 1s 765us/step - loss: 0.0415 - mae: 0.1383 - val_loss: 0.0453 - val_mae: 0.1433\n",
      "Epoch 119/500\n",
      "1220/1220 [==============================] - 1s 737us/step - loss: 0.0426 - mae: 0.1394 - val_loss: 0.0455 - val_mae: 0.1439\n",
      "Epoch 120/500\n",
      "1220/1220 [==============================] - 1s 761us/step - loss: 0.0424 - mae: 0.1386 - val_loss: 0.0468 - val_mae: 0.1459\n",
      "Epoch 121/500\n",
      "1220/1220 [==============================] - 1s 740us/step - loss: 0.0427 - mae: 0.1390 - val_loss: 0.0436 - val_mae: 0.1423\n",
      "Epoch 122/500\n",
      "1220/1220 [==============================] - 1s 737us/step - loss: 0.0417 - mae: 0.1389 - val_loss: 0.0463 - val_mae: 0.1445\n",
      "Epoch 123/500\n",
      "1220/1220 [==============================] - 1s 739us/step - loss: 0.0426 - mae: 0.1390 - val_loss: 0.0439 - val_mae: 0.1428\n",
      "Epoch 124/500\n",
      "1220/1220 [==============================] - 1s 771us/step - loss: 0.0415 - mae: 0.1385 - val_loss: 0.0456 - val_mae: 0.1449\n",
      "Epoch 125/500\n",
      "1220/1220 [==============================] - 1s 756us/step - loss: 0.0424 - mae: 0.1395 - val_loss: 0.0433 - val_mae: 0.1407\n",
      "Epoch 126/500\n",
      "1220/1220 [==============================] - 1s 746us/step - loss: 0.0421 - mae: 0.1385 - val_loss: 0.0433 - val_mae: 0.1412\n",
      "Epoch 127/500\n",
      "1220/1220 [==============================] - 1s 744us/step - loss: 0.0413 - mae: 0.1379 - val_loss: 0.0447 - val_mae: 0.1454\n",
      "Epoch 128/500\n",
      "1220/1220 [==============================] - 1s 753us/step - loss: 0.0426 - mae: 0.1391 - val_loss: 0.0440 - val_mae: 0.1411\n",
      "Epoch 129/500\n",
      "1220/1220 [==============================] - 1s 735us/step - loss: 0.0415 - mae: 0.1384 - val_loss: 0.0429 - val_mae: 0.1411\n",
      "Epoch 130/500\n",
      "1220/1220 [==============================] - 1s 760us/step - loss: 0.0413 - mae: 0.1375 - val_loss: 0.0454 - val_mae: 0.1424\n",
      "Epoch 131/500\n",
      "1220/1220 [==============================] - 1s 761us/step - loss: 0.0423 - mae: 0.1387 - val_loss: 0.0443 - val_mae: 0.1404\n",
      "Epoch 132/500\n",
      "1220/1220 [==============================] - 1s 754us/step - loss: 0.0414 - mae: 0.1386 - val_loss: 0.0440 - val_mae: 0.1428\n",
      "Epoch 133/500\n",
      "1220/1220 [==============================] - 1s 752us/step - loss: 0.0417 - mae: 0.1387 - val_loss: 0.0446 - val_mae: 0.1431\n",
      "Epoch 134/500\n",
      "1220/1220 [==============================] - 1s 748us/step - loss: 0.0416 - mae: 0.1379 - val_loss: 0.0432 - val_mae: 0.1418\n",
      "Epoch 135/500\n",
      "1220/1220 [==============================] - 1s 757us/step - loss: 0.0410 - mae: 0.1375 - val_loss: 0.0442 - val_mae: 0.1424\n",
      "Epoch 136/500\n",
      "1220/1220 [==============================] - 1s 802us/step - loss: 0.0414 - mae: 0.1378 - val_loss: 0.0431 - val_mae: 0.1405\n",
      "Epoch 137/500\n",
      "1220/1220 [==============================] - 1s 760us/step - loss: 0.0407 - mae: 0.1376 - val_loss: 0.0428 - val_mae: 0.1409\n",
      "Epoch 138/500\n",
      "1220/1220 [==============================] - 1s 738us/step - loss: 0.0427 - mae: 0.1386 - val_loss: 0.0441 - val_mae: 0.1424\n",
      "Epoch 139/500\n",
      "1220/1220 [==============================] - 1s 733us/step - loss: 0.0411 - mae: 0.1377 - val_loss: 0.0466 - val_mae: 0.1438\n",
      "Epoch 140/500\n",
      "1220/1220 [==============================] - 1s 737us/step - loss: 0.0407 - mae: 0.1377 - val_loss: 0.0446 - val_mae: 0.1443\n",
      "Epoch 141/500\n",
      "1220/1220 [==============================] - 1s 775us/step - loss: 0.0411 - mae: 0.1371 - val_loss: 0.0426 - val_mae: 0.1408\n",
      "Epoch 142/500\n",
      "1220/1220 [==============================] - 1s 740us/step - loss: 0.0405 - mae: 0.1364 - val_loss: 0.0423 - val_mae: 0.1398\n",
      "Epoch 143/500\n",
      "1220/1220 [==============================] - 1s 749us/step - loss: 0.0398 - mae: 0.1357 - val_loss: 0.0512 - val_mae: 0.1443\n",
      "Epoch 144/500\n",
      "1220/1220 [==============================] - 1s 742us/step - loss: 0.0415 - mae: 0.1374 - val_loss: 0.0433 - val_mae: 0.1419\n",
      "Epoch 145/500\n",
      "1220/1220 [==============================] - 1s 747us/step - loss: 0.0416 - mae: 0.1378 - val_loss: 0.0491 - val_mae: 0.1440\n",
      "Epoch 146/500\n",
      "1220/1220 [==============================] - 1s 755us/step - loss: 0.0436 - mae: 0.1394 - val_loss: 0.0427 - val_mae: 0.1391\n",
      "Epoch 147/500\n",
      "1220/1220 [==============================] - 1s 763us/step - loss: 0.0412 - mae: 0.1374 - val_loss: 0.0431 - val_mae: 0.1420\n",
      "Epoch 148/500\n",
      "1220/1220 [==============================] - 1s 747us/step - loss: 0.0402 - mae: 0.1367 - val_loss: 0.0417 - val_mae: 0.1386\n",
      "Epoch 149/500\n",
      "1220/1220 [==============================] - 1s 740us/step - loss: 0.0394 - mae: 0.1351 - val_loss: 0.0425 - val_mae: 0.1405\n",
      "Epoch 150/500\n",
      "1220/1220 [==============================] - 1s 861us/step - loss: 0.0403 - mae: 0.1363 - val_loss: 0.0433 - val_mae: 0.1408\n",
      "Epoch 151/500\n",
      "1220/1220 [==============================] - 1s 736us/step - loss: 0.0409 - mae: 0.1366 - val_loss: 0.0445 - val_mae: 0.1436\n",
      "Epoch 152/500\n",
      "1220/1220 [==============================] - 1s 756us/step - loss: 0.0396 - mae: 0.1365 - val_loss: 0.0443 - val_mae: 0.1437\n",
      "Epoch 153/500\n",
      "1220/1220 [==============================] - 1s 737us/step - loss: 0.0416 - mae: 0.1377 - val_loss: 0.0462 - val_mae: 0.1444\n",
      "Epoch 154/500\n",
      "1220/1220 [==============================] - 1s 761us/step - loss: 0.0407 - mae: 0.1363 - val_loss: 0.0432 - val_mae: 0.1428\n",
      "Epoch 155/500\n",
      "1220/1220 [==============================] - 1s 746us/step - loss: 0.0404 - mae: 0.1368 - val_loss: 0.0417 - val_mae: 0.1385\n",
      "Epoch 156/500\n",
      "1220/1220 [==============================] - 1s 742us/step - loss: 0.0392 - mae: 0.1358 - val_loss: 0.0435 - val_mae: 0.1403\n",
      "Epoch 157/500\n",
      "1220/1220 [==============================] - 1s 764us/step - loss: 0.0414 - mae: 0.1377 - val_loss: 0.0449 - val_mae: 0.1410\n",
      "Epoch 158/500\n",
      "1220/1220 [==============================] - 1s 762us/step - loss: 0.0406 - mae: 0.1369 - val_loss: 0.0457 - val_mae: 0.1443\n",
      "Epoch 159/500\n",
      "1220/1220 [==============================] - 1s 746us/step - loss: 0.0402 - mae: 0.1364 - val_loss: 0.0447 - val_mae: 0.1451\n",
      "Epoch 160/500\n",
      "1220/1220 [==============================] - 1s 750us/step - loss: 0.0400 - mae: 0.1358 - val_loss: 0.0425 - val_mae: 0.1396\n",
      "Epoch 161/500\n",
      "1220/1220 [==============================] - 1s 748us/step - loss: 0.0405 - mae: 0.1367 - val_loss: 0.0431 - val_mae: 0.1424\n",
      "Epoch 162/500\n",
      "1220/1220 [==============================] - 1s 782us/step - loss: 0.0412 - mae: 0.1372 - val_loss: 0.0447 - val_mae: 0.1430\n",
      "Epoch 163/500\n",
      "1220/1220 [==============================] - 1s 744us/step - loss: 0.0395 - mae: 0.1349 - val_loss: 0.0451 - val_mae: 0.1417\n",
      "Epoch 164/500\n",
      "1220/1220 [==============================] - 1s 738us/step - loss: 0.0392 - mae: 0.1352 - val_loss: 0.0455 - val_mae: 0.1439\n",
      "Epoch 165/500\n",
      "1220/1220 [==============================] - 1s 745us/step - loss: 0.0415 - mae: 0.1378 - val_loss: 0.0431 - val_mae: 0.1408\n",
      "Epoch 166/500\n",
      "1220/1220 [==============================] - 1s 747us/step - loss: 0.0399 - mae: 0.1357 - val_loss: 0.0442 - val_mae: 0.1420\n",
      "Epoch 167/500\n",
      "1220/1220 [==============================] - 1s 765us/step - loss: 0.0402 - mae: 0.1359 - val_loss: 0.0429 - val_mae: 0.1391\n",
      "Epoch 168/500\n",
      "1220/1220 [==============================] - 1s 738us/step - loss: 0.0402 - mae: 0.1359 - val_loss: 0.0429 - val_mae: 0.1422\n",
      "Epoch 169/500\n",
      "1220/1220 [==============================] - 1s 740us/step - loss: 0.0394 - mae: 0.1353 - val_loss: 0.0421 - val_mae: 0.1390\n",
      "Epoch 170/500\n",
      "1220/1220 [==============================] - 1s 751us/step - loss: 0.0395 - mae: 0.1359 - val_loss: 0.0427 - val_mae: 0.1391\n",
      "Epoch 171/500\n",
      "1220/1220 [==============================] - 1s 737us/step - loss: 0.0391 - mae: 0.1351 - val_loss: 0.0414 - val_mae: 0.1379\n",
      "Epoch 172/500\n",
      "1220/1220 [==============================] - 1s 795us/step - loss: 0.0393 - mae: 0.1350 - val_loss: 0.0425 - val_mae: 0.1397\n",
      "Epoch 173/500\n",
      "1220/1220 [==============================] - 1s 738us/step - loss: 0.0392 - mae: 0.1352 - val_loss: 0.0416 - val_mae: 0.1389\n",
      "Epoch 174/500\n",
      "1220/1220 [==============================] - 1s 753us/step - loss: 0.0399 - mae: 0.1354 - val_loss: 0.0409 - val_mae: 0.1372\n",
      "Epoch 175/500\n",
      "1220/1220 [==============================] - 1s 744us/step - loss: 0.0390 - mae: 0.1351 - val_loss: 0.0426 - val_mae: 0.1408\n",
      "Epoch 176/500\n",
      "1220/1220 [==============================] - 1s 748us/step - loss: 0.0398 - mae: 0.1362 - val_loss: 0.0426 - val_mae: 0.1413\n",
      "Epoch 177/500\n",
      "1220/1220 [==============================] - 1s 783us/step - loss: 0.0404 - mae: 0.1360 - val_loss: 0.0423 - val_mae: 0.1408\n",
      "Epoch 178/500\n",
      "1220/1220 [==============================] - 1s 822us/step - loss: 0.0410 - mae: 0.1368 - val_loss: 0.0429 - val_mae: 0.1403\n",
      "Epoch 179/500\n",
      "1220/1220 [==============================] - 1s 740us/step - loss: 0.0393 - mae: 0.1347 - val_loss: 0.0413 - val_mae: 0.1374\n",
      "Epoch 180/500\n",
      "1220/1220 [==============================] - 1s 763us/step - loss: 0.0403 - mae: 0.1359 - val_loss: 0.0457 - val_mae: 0.1448\n",
      "Epoch 181/500\n",
      "1220/1220 [==============================] - 1s 738us/step - loss: 0.0406 - mae: 0.1361 - val_loss: 0.0420 - val_mae: 0.1388\n",
      "Epoch 182/500\n",
      "1220/1220 [==============================] - 1s 755us/step - loss: 0.0390 - mae: 0.1348 - val_loss: 0.0422 - val_mae: 0.1391\n",
      "Epoch 183/500\n",
      "1220/1220 [==============================] - 1s 759us/step - loss: 0.0401 - mae: 0.1354 - val_loss: 0.0431 - val_mae: 0.1395\n",
      "Epoch 184/500\n",
      "1220/1220 [==============================] - 1s 790us/step - loss: 0.0411 - mae: 0.1359 - val_loss: 0.0421 - val_mae: 0.1386\n",
      "Epoch 185/500\n",
      "1220/1220 [==============================] - 1s 740us/step - loss: 0.0400 - mae: 0.1362 - val_loss: 0.0454 - val_mae: 0.1426\n",
      "Epoch 186/500\n",
      "1220/1220 [==============================] - 1s 762us/step - loss: 0.0407 - mae: 0.1358 - val_loss: 0.0438 - val_mae: 0.1400\n",
      "Epoch 187/500\n",
      "1220/1220 [==============================] - 1s 749us/step - loss: 0.0399 - mae: 0.1352 - val_loss: 0.0418 - val_mae: 0.1393\n",
      "Epoch 188/500\n",
      "1220/1220 [==============================] - 1s 777us/step - loss: 0.0389 - mae: 0.1344 - val_loss: 0.0431 - val_mae: 0.1392\n",
      "Epoch 189/500\n",
      "1220/1220 [==============================] - 1s 762us/step - loss: 0.0389 - mae: 0.1344 - val_loss: 0.0413 - val_mae: 0.1377\n",
      "Epoch 190/500\n",
      "1220/1220 [==============================] - 1s 753us/step - loss: 0.0389 - mae: 0.1343 - val_loss: 0.0420 - val_mae: 0.1378\n",
      "Epoch 191/500\n",
      "1220/1220 [==============================] - 1s 783us/step - loss: 0.0389 - mae: 0.1347 - val_loss: 0.0415 - val_mae: 0.1387\n",
      "Epoch 192/500\n",
      "1220/1220 [==============================] - 1s 787us/step - loss: 0.0385 - mae: 0.1340 - val_loss: 0.0423 - val_mae: 0.1389\n",
      "Epoch 193/500\n",
      "1220/1220 [==============================] - 1s 759us/step - loss: 0.0389 - mae: 0.1346 - val_loss: 0.0465 - val_mae: 0.1415\n",
      "Epoch 194/500\n",
      "1220/1220 [==============================] - 1s 748us/step - loss: 0.0387 - mae: 0.1346 - val_loss: 0.0431 - val_mae: 0.1403\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00194: early stopping\n",
      "191/191 [==============================] - 0s 417us/step\n",
      "\n",
      "PoseNet_to_Kinect model (optimizer=Adam, learning_rate=0.001):\n",
      "MSE:  0.0008544281825131349\n",
      "MSA:  0.017847552019074318\n",
      "R-Squared:  0.9580490212460114\n",
      "Explained Variance Score:  0.9585112722880281\n",
      "INFO:tensorflow:Assets written to: /var/folders/l9/_j4ypcyn1ps8hgcdkjk4v2r00000gn/T/tmpzv06vhfy/model/data/model/assets\n",
      "INFO:tensorflow:Assets written to: /var/folders/l9/_j4ypcyn1ps8hgcdkjk4v2r00000gn/T/tmpzv06vhfy/model/data/model/assets\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-37debf25b64b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"variance\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gs://mlflow-atlas/mlflow_artifacts/0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/keras.py\u001b[0m in \u001b[0;36mlog_model\u001b[0;34m(keras_model, artifact_path, conda_env, custom_objects, keras_module, registered_model_name, signature, input_example, await_registration_for, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \"\"\"\n\u001b[0;32m--> 377\u001b[0;31m     Model.log(\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/models/model.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mmlflow_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mflavor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlflow_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_logged_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlflow_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36mlog_artifacts\u001b[0;34m(local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \"\"\"\n\u001b[1;32m    560\u001b[0m     \u001b[0mrun_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_or_start_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m     \u001b[0mMlflowClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/client.py\u001b[0m in \u001b[0;36mlog_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mis_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \"\"\"\n\u001b[0;32m--> 919\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracking_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py\u001b[0m in \u001b[0;36mlog_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0martifact_uri\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[0mwrite\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_artifact_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py\u001b[0m in \u001b[0;36m_get_artifact_repo\u001b[0;34m(self, run_id)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking_uri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         )\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_artifact_repository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/artifact/artifact_repository_registry.py\u001b[0m in \u001b[0;36mget_artifact_repository\u001b[0;34m(artifact_uri)\u001b[0m\n\u001b[1;32m    100\u001b[0m              \u001b[0mrequirements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_artifact_repository_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_artifact_repository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/artifact/artifact_repository_registry.py\u001b[0m in \u001b[0;36mget_artifact_repository\u001b[0;34m(self, artifact_uri)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 )\n\u001b[1;32m     70\u001b[0m             )\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrepository\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/mlflow/store/artifact/gcs_artifact_repo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, artifact_uri, client)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstorage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgcs_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcs_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Model parameters\n",
    "    learning_rate = 0.001\n",
    "    optimizer = 'Adam'\n",
    "    loss = 'mse'\n",
    "    metrics = ['mae']\n",
    "    epochs = 500\n",
    "    batch_size = 16\n",
    "    layers = [ \n",
    "        { 'type': 'Dense', 'nodes':64, 'activation': 'relu' },\n",
    "        { 'type': 'Dense', 'nodes':64, 'activation': 'relu' },\n",
    "        { 'type': 'Dense', 'nodes':26, 'activation': ''}\n",
    "    ]\n",
    "\n",
    "    model = create_model(optimizer=optimizer)\n",
    "    history = model.fit(x=X_train, y=y_train, validation_split=0.2, shuffle=True, epochs=epochs, verbose=1, batch_size=batch_size, callbacks=[early_stopping])\n",
    "\n",
    "    predictions = model.predict(X_test, verbose=1)\n",
    "    # Invert transform on predictions\n",
    "    predictions = y_scaler.inverse_transform(predictions)\n",
    "    (mse, msa, r2, variance) = eval_metrics(y_test, predictions)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\nPoseNet_to_Kinect model (optimizer={}, learning_rate={}):\".format(optimizer, learning_rate))\n",
    "    print('MSE: ', mse)\n",
    "    print('MSA: ', msa)\n",
    "    print('R-Squared: ', r2)\n",
    "    print('Explained Variance Score: ', variance)\n",
    "\n",
    "    # Log parameter, metrics, and model to MLflow\n",
    "    mlflow.log_param(\"optimizer\", optimizer)\n",
    "    mlflow.log_param(\"learning rate\", learning_rate)\n",
    "    mlflow.log_param(\"batch size\", batch_size)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"msa\", msa)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "    mlflow.log_metric(\"variance\", variance)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"gs://mlflow-atlas/mlflow_artifacts/0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = pd.DataFrame(history.history)\n",
    "training_history['epochs'] = range(len(training_history['mae']))"
   ]
  },
  {
   "source": [
    "### Plot training and validation MAE & loss per epoch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '_name'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b4908afb21df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m331\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\nBatch size: {}\\nOptimizer: {}\\nLoss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"large\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizontalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverticalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'top'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '_name'"
     ]
    }
   ],
   "source": [
    "plots = [\n",
    "           {'cols':['mae', 'val_mae'], 'title':'Training and validation MAE', 'yLabel':'MAE'},\n",
    "           {'cols':['loss', 'val_loss'], 'title':'Training and validation loss', 'yLabel':'MSE'},\n",
    "]\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "fig_no = 331\n",
    "title = '\\nBatch size: {}\\nOptimizer: {}\\nLoss: {}'.format(batch_size,optimizer, loss)\n",
    "fig.suptitle(title, fontsize=\"large\", horizontalalignment='left', verticalalignment='top')\n",
    "\n",
    "for i in range(len(plots)):\n",
    "    ax = fig.add_subplot(str(fig_no))\n",
    "    sns.lineplot(data=training_history[plots[i]['cols']], ax=ax)\n",
    "    plt.title(plots[i]['title'])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(plots[i]['yLabel'])\n",
    "    fig_no += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ]
}