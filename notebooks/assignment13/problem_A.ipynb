{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Problem A (Kinect)\n",
    "\n",
    "Section for configurations and imports."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://35.228.45.76:5000')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='./mlflow-312506-8cfad529f4fd.json'\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# Import data augmentation\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from augmentation.methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 47\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices( 'GPU' )\n",
    "print( 'Num GPUs Available: ', len( physical_devices ) )\n",
    "if len( physical_devices ) > 0:\n",
    "    tf.config.experimental.set_memory_growth( physical_devices[0], True )"
   ]
  },
  {
   "source": [
    "# 1. Data Preparation\n",
    "\n",
    "## 1.1 Load files and classify each sample into good or bad depending on the file name\n",
    "\n",
    "W is the start for file names with bad exercises, and all others are classified as \"good\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'https://raw.githubusercontent.com/digitacs/4dv652-ml/main/datasets/all_good_bad_videos/kinect_good_vs_bad_not_preprocessed/'\n",
    "\n",
    "good_videos = []\n",
    "bad_videos = []"
   ]
  },
  {
   "source": [
    "### Cut leading and trailing frames\n",
    "\n",
    "Method for removing leading and trailing frames from each data sample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_start_model = mlflow.keras.load_model('gs://mlflow-atlas/mlflow_artifacts/0/de66919788d44ed8a4106c95de1aaa1a/artifacts/cut_start_kinect')\n",
    "cut_stop_model = mlflow.keras.load_model('gs://mlflow-atlas/mlflow_artifacts/0/5bc55dc1d2534a259459bc711d10cac9/artifacts/cut_start_kinect')\n",
    "\n",
    "def cut_leading_trailing(data):\n",
    "    trimmed_data = data.copy()\n",
    "\n",
    "    predictions = cut_start_model.predict(data)\n",
    "    predictions = predictions.round().astype(int)\n",
    "    n = 0\n",
    "    for pred in predictions:\n",
    "        # TODO: Add handling of start/stop predictions when models have better performance\n",
    "        n = n + 1\n",
    "\n",
    "    return trimmed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Could not find file:  G67.csv\n",
      "Could not find file:  G70.csv\n",
      "(26259, 40)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path + 'A1.csv')\n",
    "df.drop(columns=['FrameNo'], inplace=True)\n",
    "df['quality'] = 1 # Good\n",
    "good_videos.append('A1.csv')\n",
    "\n",
    "numbers = ['01', '02', '03', '04', '05', '06', '07', '08', '09']\n",
    "\n",
    "for i in numbers:\n",
    "  try:\n",
    "    file_name = 'G{}.csv'.format(i)\n",
    "    temp = pd.read_csv(file_path +  file_name)\n",
    "    temp.drop(columns=['FrameNo'], inplace=True)\n",
    "    temp = cut_leading_trailing(temp)\n",
    "    temp['quality'] = 1 # Good\n",
    "    good_videos.append(file_name)\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "\n",
    "    file_name = 'W{}.csv'.format(i)\n",
    "    temp = pd.read_csv(file_path +  file_name)\n",
    "    temp.drop(columns=['FrameNo'], inplace=True)\n",
    "    temp = cut_leading_trailing(temp)\n",
    "    temp['quality'] = 0 # Bad\n",
    "    bad_videos.append(file_name)\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "  except IOError as e:\n",
    "    print('Could not find file: ', file_name)\n",
    "\n",
    "for i in range(20, 83):\n",
    "  try:\n",
    "    file_name = 'G{}.csv'.format(i)\n",
    "    temp = pd.read_csv(file_path +  file_name)\n",
    "    temp.drop(columns=['FrameNo'], inplace=True)\n",
    "    temp = cut_leading_trailing(temp)\n",
    "    temp['quality'] = 1 # Good\n",
    "    good_videos.append(file_name)\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "  except IOError as e:\n",
    "    print('Could not find file: ', file_name)\n",
    "\n",
    "for i in range(10, 44):\n",
    "  try:\n",
    "    file_name = 'W{}.csv'.format(i)\n",
    "    temp = pd.read_csv(file_path +  file_name)\n",
    "    temp.drop(columns=['FrameNo'], inplace=True)\n",
    "    temp = cut_leading_trailing(temp)\n",
    "    temp['quality'] = 0 # Bad\n",
    "    bad_videos.append(file_name)\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "  except IOError as e:\n",
    "    print('Could not find file: ', file_name)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "source": [
    "## 1.2 Check class imbalance\n",
    "\n",
    "To see if we need to use any dataset imbalanced techniques. We do not consider that there's a need for that in this case."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total videos:  114\nGood videos: 71\nBad videos: 43\n"
     ]
    }
   ],
   "source": [
    "print('Total videos: ', len(good_videos + bad_videos))\n",
    "print('Good videos:', len(good_videos))\n",
    "print('Bad videos:', len(bad_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total: 26259\n\nGood: 17563 (0.67% of total)\nBad: 8696 (0.33% of total)\n\n"
     ]
    }
   ],
   "source": [
    "df_gc = df.groupby(['quality']).size()\n",
    "print(\n",
    "    'Total: {}\\n\\nGood: {} ({:.2f}% of total)\\nBad: {} ({:.2f}% of total)\\n'\n",
    "    .format(\n",
    "      len(df), \n",
    "      df_gc[1],\n",
    "      df_gc[1] / len(df),\n",
    "      df_gc[0],\n",
    "      df_gc[0] / len(df)\n",
    "    )\n",
    "  )"
   ]
  },
  {
   "source": [
    "## 1.3 Data Augmentation\n",
    "\n",
    "### Mirror X coordinate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(52518, 40)\n"
     ]
    }
   ],
   "source": [
    "df = mirror(df,'x', append=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "source": [
    "### Stretch X coordinate by 50%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(52518, 40)\n"
     ]
    }
   ],
   "source": [
    "df_temp = augMultiplier(df.drop(columns=['quality']), multiplier=1.5)\n",
    "df_temp['quality'] = df['quality']\n",
    "df = df.append(df_temp, ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "source": [
    "### Stretch Y coordinate by 25%"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(52518, 40)\n"
     ]
    }
   ],
   "source": [
    "df_temp = augMultiplier(df.drop(columns=['quality']), multiplier=0.25)\n",
    "df_temp['quality'] = df['quality']\n",
    "df = df.append(df_temp, ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "source": [
    "### Rotate around the Y axis by p/7"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 3.1415 / 7\n",
    "df_temp = rotate2(df.drop(columns=['quality']), angle=angle,posenet=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "source": [
    "### Rotate around the Y axis by -p/9"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 3.1415 / -9\n",
    "df_temp = rotate2(df.drop(columns=['quality']), angle=angle,posenet=False)\n",
    "print(df.shape)"
   ]
  },
  {
   "source": [
    "### Save dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../datasets/Problem_A_agumented.csv')"
   ]
  },
  {
   "source": [
    "## 1.4 Split into sets for training, validation, and testing + use and save scaler"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['quality'])\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=random_state)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training features shape: (37812, 39)\nTraining labels shape: (37812,) \n\nValidation features shape: (9454, 39)\nValidation labels shape: (9454,) \n\nTest features shape: (5252, 39)\nTest labels shape: (5252,) \n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Training labels shape:', y_train.shape, '\\n')\n",
    "\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Validation labels shape:', y_val.shape, '\\n')\n",
    "\n",
    "print('Test features shape:', X_test.shape)\n",
    "print('Test labels shape:', y_test.shape, '\\n')"
   ]
  },
  {
   "source": [
    "# 2. Dense Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here"
   ]
  },
  {
   "source": [
    "# 3. CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here"
   ]
  },
  {
   "source": [
    "# 4. Comparison: Dense Model vs CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here"
   ]
  }
 ]
}