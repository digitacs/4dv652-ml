{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model for Kinect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import tempfile\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import MaxPool1D\n",
    "\n",
    "# MLflow dashboard\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://35.228.45.76:5000')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='../../mlflow-312506-8cfad529f4fd.json'\n",
    "\n",
    "# Import data augmentation\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 47\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "#monitor='val_accuracy',\n",
    "#monitor='val_prc', \n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Prepared Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111416, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/digitacs/4dv652-ml/main/datasets/all_good_bad_problemA_kinect/good_bad_kinect.csv')\n",
    "\n",
    "df.fillna(0, inplace=True) # Replace NaN with 0\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split into sets for training, validation, and testing + use and save scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['quality'])\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=random_state)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (80219, 39)\n",
      "Training labels shape: (80219,) \n",
      "\n",
      "Validation features shape: (20055, 39)\n",
      "Validation labels shape: (20055,) \n",
      "\n",
      "Test features shape: (11142, 39)\n",
      "Test labels shape: (11142,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('Training features shape:', X_train.shape)\n",
    "print('Training labels shape:', y_train.shape, '\\n')\n",
    "\n",
    "print('Validation features shape:', X_val.shape)\n",
    "print('Validation labels shape:', y_val.shape, '\\n')\n",
    "\n",
    "print('Test features shape:', X_test.shape)\n",
    "print('Test labels shape:', y_test.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the Model\n",
    "\n",
    "### 3.1 Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (39,)\n",
      "After: (39, 1)\n",
      "Classes: 1\n"
     ]
    }
   ],
   "source": [
    "from numpy import unique\n",
    "orig_shape = X_train.shape[1:]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "in_shape = X_train.shape[1:]\n",
    "print(\"Before: {0}\".format(orig_shape))\n",
    "print(\"After: {0}\".format(in_shape))\n",
    "\n",
    "\n",
    "\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 2050\n",
    "\n",
    "n_classes = len(unique(y_train))\n",
    "n_classes = 1\n",
    "print(\"Classes: {0}\".format(n_classes))\n",
    "\n",
    "units = 64\n",
    "activation = 'relu'\n",
    "kernel_initializer = 'he_uniform'\n",
    "output_activation = 'sigmoid'\n",
    "#output_activation = 'softmax'\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 1e-3\n",
    "filters = 12\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "strides = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Dropout, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(loss, optimizer, learning_rate=0.001, metrics=METRICS):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters= filters, kernel_size = kernel_size, activation=activation, kernel_initializer=kernel_initializer, input_shape=in_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(MaxPool1D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "    #model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(4, activation='relu', kernel_initializer='he_uniform'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(n_classes, activation=output_activation))\n",
    "    \n",
    "    \n",
    "    optimizer = tf.keras.optimizers.get(optimizer)\n",
    "    optimizer.learning_rate.assign(learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=optimizer,\n",
    "      loss=loss,\n",
    "      metrics=metrics)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MLflow Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve\n",
    "\n",
    "def plot_loss(history, label, n):\n",
    "  plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=colors[n], label='Train ' + label)\n",
    "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=colors[n], label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('True Negatives: ', cm[0][0])\n",
    "    print('False Positives: ', cm[0][1])\n",
    "    print('False Negatives: ', cm[1][0])\n",
    "    print('True Positives: ', cm[1][1])\n",
    "    print('Total: ', np.sum(cm[1]))\n",
    "\n",
    "\n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = roc_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "def plot_prc(name, labels, predictions, **kwargs):\n",
    "    precision, recall, _ = precision_recall_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(precision, recall, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Start Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 37, 12)            48        \n",
      "_________________________________________________________________\n",
      "module_wrapper (ModuleWrappe (None, 37, 12)            48        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 444)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1780      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,881\n",
      "Trainable params: 1,857\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      "40/40 [==============================] - 3s 42ms/step - loss: 0.6878 - tp: 27957.1707 - fp: 7826.6585 - tn: 2760.0488 - fn: 4369.2439 - accuracy: 0.6810 - precision: 0.7741 - recall: 0.8129 - auc: 0.5606 - prc: 0.7764 - val_loss: 0.8966 - val_tp: 5707.0000 - val_fp: 954.0000 - val_tn: 4072.0000 - val_fn: 9322.0000 - val_accuracy: 0.4876 - val_precision: 0.8568 - val_recall: 0.3797 - val_auc: 0.6994 - val_prc: 0.8559\n",
      "Epoch 2/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.4546 - tp: 32006.4634 - fp: 7360.5854 - tn: 3304.8780 - fn: 241.1951 - accuracy: 0.8202 - precision: 0.8106 - recall: 0.9923 - auc: 0.7664 - prc: 0.8948 - val_loss: 0.6397 - val_tp: 7933.0000 - val_fp: 1200.0000 - val_tn: 3826.0000 - val_fn: 7096.0000 - val_accuracy: 0.5863 - val_precision: 0.8686 - val_recall: 0.5278 - val_auc: 0.7691 - val_prc: 0.8921\n",
      "Epoch 3/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.3919 - tp: 32080.6829 - fp: 6704.8049 - tn: 3907.0976 - fn: 220.5366 - accuracy: 0.8372 - precision: 0.8258 - recall: 0.9934 - auc: 0.8434 - prc: 0.9302 - val_loss: 0.4846 - val_tp: 11586.0000 - val_fp: 1666.0000 - val_tn: 3360.0000 - val_fn: 3443.0000 - val_accuracy: 0.7453 - val_precision: 0.8743 - val_recall: 0.7709 - val_auc: 0.8238 - val_prc: 0.9200\n",
      "Epoch 4/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.3612 - tp: 31859.1951 - fp: 6087.9024 - tn: 4528.7561 - fn: 437.2683 - accuracy: 0.8471 - precision: 0.8387 - recall: 0.9867 - auc: 0.8724 - prc: 0.9432 - val_loss: 0.4041 - val_tp: 13970.0000 - val_fp: 2021.0000 - val_tn: 3005.0000 - val_fn: 1059.0000 - val_accuracy: 0.8464 - val_precision: 0.8736 - val_recall: 0.9295 - val_auc: 0.8592 - val_prc: 0.9357\n",
      "Epoch 5/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.3369 - tp: 31829.8780 - fp: 5645.9268 - tn: 4947.6585 - fn: 489.6585 - accuracy: 0.8572 - precision: 0.8494 - recall: 0.9855 - auc: 0.8925 - prc: 0.9533 - val_loss: 0.3527 - val_tp: 14488.0000 - val_fp: 2118.0000 - val_tn: 2908.0000 - val_fn: 541.0000 - val_accuracy: 0.8674 - val_precision: 0.8725 - val_recall: 0.9640 - val_auc: 0.8889 - val_prc: 0.9502\n",
      "Epoch 6/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.3246 - tp: 31781.0244 - fp: 5404.2683 - tn: 5219.3902 - fn: 508.4390 - accuracy: 0.8617 - precision: 0.8538 - recall: 0.9845 - auc: 0.9016 - prc: 0.9562 - val_loss: 0.3292 - val_tp: 14563.0000 - val_fp: 2049.0000 - val_tn: 2977.0000 - val_fn: 466.0000 - val_accuracy: 0.8746 - val_precision: 0.8767 - val_recall: 0.9690 - val_auc: 0.9010 - val_prc: 0.9560\n",
      "Epoch 7/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.3094 - tp: 31693.4390 - fp: 5049.9512 - tn: 5588.0244 - fn: 581.7073 - accuracy: 0.8686 - precision: 0.8627 - recall: 0.9816 - auc: 0.9113 - prc: 0.9616 - val_loss: 0.3057 - val_tp: 14650.0000 - val_fp: 2075.0000 - val_tn: 2951.0000 - val_fn: 379.0000 - val_accuracy: 0.8776 - val_precision: 0.8759 - val_recall: 0.9748 - val_auc: 0.9126 - val_prc: 0.9617\n",
      "Epoch 8/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.2951 - tp: 31725.1463 - fp: 4819.4146 - tn: 5822.3902 - fn: 546.1707 - accuracy: 0.8749 - precision: 0.8676 - recall: 0.9838 - auc: 0.9195 - prc: 0.9656 - val_loss: 0.2902 - val_tp: 14672.0000 - val_fp: 2062.0000 - val_tn: 2964.0000 - val_fn: 357.0000 - val_accuracy: 0.8794 - val_precision: 0.8768 - val_recall: 0.9762 - val_auc: 0.9215 - val_prc: 0.9663\n",
      "Epoch 9/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.2794 - tp: 31691.9024 - fp: 4593.0732 - tn: 6024.2927 - fn: 603.8537 - accuracy: 0.8797 - precision: 0.8741 - recall: 0.9817 - auc: 0.9286 - prc: 0.9702 - val_loss: 0.2766 - val_tp: 14729.0000 - val_fp: 2021.0000 - val_tn: 3005.0000 - val_fn: 300.0000 - val_accuracy: 0.8843 - val_precision: 0.8793 - val_recall: 0.9800 - val_auc: 0.9302 - val_prc: 0.9701\n",
      "Epoch 10/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.2712 - tp: 31731.0488 - fp: 4434.1463 - tn: 6200.4146 - fn: 547.5122 - accuracy: 0.8840 - precision: 0.8775 - recall: 0.9833 - auc: 0.9331 - prc: 0.9720 - val_loss: 0.2641 - val_tp: 14731.0000 - val_fp: 1986.0000 - val_tn: 3040.0000 - val_fn: 298.0000 - val_accuracy: 0.8861 - val_precision: 0.8812 - val_recall: 0.9802 - val_auc: 0.9370 - val_prc: 0.9739\n",
      "Epoch 11/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.2590 - tp: 31645.4390 - fp: 4021.7561 - tn: 6560.0488 - fn: 685.8780 - accuracy: 0.8897 - precision: 0.8860 - recall: 0.9801 - auc: 0.9389 - prc: 0.9754 - val_loss: 0.2536 - val_tp: 14574.0000 - val_fp: 1587.0000 - val_tn: 3439.0000 - val_fn: 455.0000 - val_accuracy: 0.8982 - val_precision: 0.9018 - val_recall: 0.9697 - val_auc: 0.9432 - val_prc: 0.9765\n",
      "Epoch 12/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.2488 - tp: 31405.6829 - fp: 3375.3659 - tn: 7237.5610 - fn: 894.5122 - accuracy: 0.9013 - precision: 0.9038 - recall: 0.9725 - auc: 0.9454 - prc: 0.9779 - val_loss: 0.2495 - val_tp: 14550.0000 - val_fp: 1477.0000 - val_tn: 3549.0000 - val_fn: 479.0000 - val_accuracy: 0.9025 - val_precision: 0.9078 - val_recall: 0.9681 - val_auc: 0.9441 - val_prc: 0.9772\n",
      "Epoch 13/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.2450 - tp: 31435.0000 - fp: 3262.4634 - tn: 7357.1220 - fn: 858.5366 - accuracy: 0.9033 - precision: 0.9056 - recall: 0.9728 - auc: 0.9453 - prc: 0.9777 - val_loss: 0.2347 - val_tp: 14586.0000 - val_fp: 1460.0000 - val_tn: 3566.0000 - val_fn: 443.0000 - val_accuracy: 0.9051 - val_precision: 0.9090 - val_recall: 0.9705 - val_auc: 0.9516 - val_prc: 0.9804\n",
      "Epoch 14/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.2306 - tp: 31383.3902 - fp: 3031.8780 - tn: 7596.9024 - fn: 900.9512 - accuracy: 0.9088 - precision: 0.9128 - recall: 0.9715 - auc: 0.9530 - prc: 0.9812 - val_loss: 0.2284 - val_tp: 14675.0000 - val_fp: 1538.0000 - val_tn: 3488.0000 - val_fn: 354.0000 - val_accuracy: 0.9057 - val_precision: 0.9051 - val_recall: 0.9764 - val_auc: 0.9556 - val_prc: 0.9825\n",
      "Epoch 15/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.2237 - tp: 31472.6829 - fp: 2979.7073 - tn: 7630.3659 - fn: 830.3659 - accuracy: 0.9101 - precision: 0.9122 - recall: 0.9743 - auc: 0.9565 - prc: 0.9829 - val_loss: 0.2183 - val_tp: 14614.0000 - val_fp: 1353.0000 - val_tn: 3673.0000 - val_fn: 415.0000 - val_accuracy: 0.9118 - val_precision: 0.9153 - val_recall: 0.9724 - val_auc: 0.9584 - val_prc: 0.9834\n",
      "Epoch 16/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.2165 - tp: 31444.5366 - fp: 2836.6098 - tn: 7782.6098 - fn: 849.3659 - accuracy: 0.9144 - precision: 0.9178 - recall: 0.9737 - auc: 0.9584 - prc: 0.9835 - val_loss: 0.2138 - val_tp: 14672.0000 - val_fp: 1400.0000 - val_tn: 3626.0000 - val_fn: 357.0000 - val_accuracy: 0.9124 - val_precision: 0.9129 - val_recall: 0.9762 - val_auc: 0.9602 - val_prc: 0.9843\n",
      "Epoch 17/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.2090 - tp: 31491.5366 - fp: 2730.4878 - tn: 7882.5610 - fn: 808.5366 - accuracy: 0.9178 - precision: 0.9201 - recall: 0.9756 - auc: 0.9619 - prc: 0.9850 - val_loss: 0.2070 - val_tp: 14655.0000 - val_fp: 1340.0000 - val_tn: 3686.0000 - val_fn: 374.0000 - val_accuracy: 0.9145 - val_precision: 0.9162 - val_recall: 0.9751 - val_auc: 0.9625 - val_prc: 0.9853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.2041 - tp: 31425.1707 - fp: 2636.9512 - tn: 8047.9268 - fn: 803.0732 - accuracy: 0.9193 - precision: 0.9221 - recall: 0.9748 - auc: 0.9634 - prc: 0.9855 - val_loss: 0.2005 - val_tp: 14655.0000 - val_fp: 1267.0000 - val_tn: 3759.0000 - val_fn: 374.0000 - val_accuracy: 0.9182 - val_precision: 0.9204 - val_recall: 0.9751 - val_auc: 0.9647 - val_prc: 0.9863\n",
      "Epoch 19/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1962 - tp: 31500.3902 - fp: 2507.4146 - tn: 8118.7561 - fn: 786.5610 - accuracy: 0.9237 - precision: 0.9264 - recall: 0.9761 - auc: 0.9664 - prc: 0.9867 - val_loss: 0.1954 - val_tp: 14641.0000 - val_fp: 1158.0000 - val_tn: 3868.0000 - val_fn: 388.0000 - val_accuracy: 0.9229 - val_precision: 0.9267 - val_recall: 0.9742 - val_auc: 0.9664 - val_prc: 0.9867\n",
      "Epoch 20/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1918 - tp: 31573.0732 - fp: 2439.2195 - tn: 8139.8537 - fn: 760.9756 - accuracy: 0.9255 - precision: 0.9282 - recall: 0.9768 - auc: 0.9672 - prc: 0.9872 - val_loss: 0.1902 - val_tp: 14624.0000 - val_fp: 1101.0000 - val_tn: 3925.0000 - val_fn: 405.0000 - val_accuracy: 0.9249 - val_precision: 0.9300 - val_recall: 0.9731 - val_auc: 0.9679 - val_prc: 0.9875\n",
      "Epoch 21/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1873 - tp: 31517.0000 - fp: 2332.7805 - tn: 8271.9268 - fn: 791.4146 - accuracy: 0.9275 - precision: 0.9315 - recall: 0.9755 - auc: 0.9683 - prc: 0.9877 - val_loss: 0.1876 - val_tp: 14576.0000 - val_fp: 1035.0000 - val_tn: 3991.0000 - val_fn: 453.0000 - val_accuracy: 0.9258 - val_precision: 0.9337 - val_recall: 0.9699 - val_auc: 0.9687 - val_prc: 0.9878\n",
      "Epoch 22/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1843 - tp: 31409.7317 - fp: 2276.5366 - tn: 8416.1707 - fn: 810.6829 - accuracy: 0.9275 - precision: 0.9320 - recall: 0.9745 - auc: 0.9703 - prc: 0.9884 - val_loss: 0.1813 - val_tp: 14596.0000 - val_fp: 1031.0000 - val_tn: 3995.0000 - val_fn: 433.0000 - val_accuracy: 0.9270 - val_precision: 0.9340 - val_recall: 0.9712 - val_auc: 0.9701 - val_prc: 0.9884\n",
      "Epoch 23/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1757 - tp: 31575.9268 - fp: 2180.3415 - tn: 8386.0488 - fn: 770.8049 - accuracy: 0.9315 - precision: 0.9360 - recall: 0.9760 - auc: 0.9714 - prc: 0.9888 - val_loss: 0.1747 - val_tp: 14624.0000 - val_fp: 1028.0000 - val_tn: 3998.0000 - val_fn: 405.0000 - val_accuracy: 0.9285 - val_precision: 0.9343 - val_recall: 0.9731 - val_auc: 0.9721 - val_prc: 0.9892\n",
      "Epoch 24/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1702 - tp: 31567.4146 - fp: 2084.4390 - tn: 8494.1220 - fn: 767.1463 - accuracy: 0.9335 - precision: 0.9380 - recall: 0.9763 - auc: 0.9732 - prc: 0.9895 - val_loss: 0.1695 - val_tp: 14582.0000 - val_fp: 899.0000 - val_tn: 4127.0000 - val_fn: 447.0000 - val_accuracy: 0.9329 - val_precision: 0.9419 - val_recall: 0.9703 - val_auc: 0.9734 - val_prc: 0.9896\n",
      "Epoch 25/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1648 - tp: 31554.9512 - fp: 2034.0976 - tn: 8547.2195 - fn: 776.8537 - accuracy: 0.9347 - precision: 0.9398 - recall: 0.9760 - auc: 0.9742 - prc: 0.9900 - val_loss: 0.1695 - val_tp: 14569.0000 - val_fp: 795.0000 - val_tn: 4231.0000 - val_fn: 460.0000 - val_accuracy: 0.9374 - val_precision: 0.9483 - val_recall: 0.9694 - val_auc: 0.9735 - val_prc: 0.9895\n",
      "Epoch 26/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1644 - tp: 31498.2439 - fp: 1983.0000 - tn: 8659.7805 - fn: 772.0976 - accuracy: 0.9362 - precision: 0.9417 - recall: 0.9756 - auc: 0.9744 - prc: 0.9899 - val_loss: 0.1638 - val_tp: 14668.0000 - val_fp: 1081.0000 - val_tn: 3945.0000 - val_fn: 361.0000 - val_accuracy: 0.9281 - val_precision: 0.9314 - val_recall: 0.9760 - val_auc: 0.9752 - val_prc: 0.9906\n",
      "Epoch 27/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1638 - tp: 31494.3415 - fp: 2018.1951 - tn: 8606.3659 - fn: 794.2195 - accuracy: 0.9334 - precision: 0.9384 - recall: 0.9755 - auc: 0.9741 - prc: 0.9898 - val_loss: 0.1584 - val_tp: 14586.0000 - val_fp: 792.0000 - val_tn: 4234.0000 - val_fn: 443.0000 - val_accuracy: 0.9384 - val_precision: 0.9485 - val_recall: 0.9705 - val_auc: 0.9769 - val_prc: 0.9910\n",
      "Epoch 28/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1566 - tp: 31525.2683 - fp: 1923.8537 - tn: 8711.4146 - fn: 752.5854 - accuracy: 0.9375 - precision: 0.9423 - recall: 0.9766 - auc: 0.9765 - prc: 0.9908 - val_loss: 0.1554 - val_tp: 14650.0000 - val_fp: 915.0000 - val_tn: 4111.0000 - val_fn: 379.0000 - val_accuracy: 0.9355 - val_precision: 0.9412 - val_recall: 0.9748 - val_auc: 0.9771 - val_prc: 0.9913\n",
      "Epoch 29/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1539 - tp: 31463.8780 - fp: 1856.6585 - tn: 8845.1220 - fn: 747.4634 - accuracy: 0.9388 - precision: 0.9440 - recall: 0.9763 - auc: 0.9776 - prc: 0.9912 - val_loss: 0.1548 - val_tp: 14687.0000 - val_fp: 988.0000 - val_tn: 4038.0000 - val_fn: 342.0000 - val_accuracy: 0.9337 - val_precision: 0.9370 - val_recall: 0.9772 - val_auc: 0.9777 - val_prc: 0.9915\n",
      "Epoch 30/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1494 - tp: 31591.0488 - fp: 1852.6341 - tn: 8765.3415 - fn: 704.0976 - accuracy: 0.9402 - precision: 0.9444 - recall: 0.9783 - auc: 0.9785 - prc: 0.9917 - val_loss: 0.1539 - val_tp: 14601.0000 - val_fp: 728.0000 - val_tn: 4298.0000 - val_fn: 428.0000 - val_accuracy: 0.9424 - val_precision: 0.9525 - val_recall: 0.9715 - val_auc: 0.9784 - val_prc: 0.9917\n",
      "Epoch 31/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1474 - tp: 31606.9024 - fp: 1780.9024 - tn: 8799.0000 - fn: 726.3171 - accuracy: 0.9422 - precision: 0.9474 - recall: 0.9776 - auc: 0.9794 - prc: 0.9922 - val_loss: 0.1472 - val_tp: 14639.0000 - val_fp: 800.0000 - val_tn: 4226.0000 - val_fn: 390.0000 - val_accuracy: 0.9407 - val_precision: 0.9482 - val_recall: 0.9741 - val_auc: 0.9793 - val_prc: 0.9922\n",
      "Epoch 32/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1455 - tp: 31536.6341 - fp: 1760.5122 - tn: 8895.9512 - fn: 720.0244 - accuracy: 0.9424 - precision: 0.9473 - recall: 0.9777 - auc: 0.9800 - prc: 0.9923 - val_loss: 0.1432 - val_tp: 14713.0000 - val_fp: 825.0000 - val_tn: 4201.0000 - val_fn: 316.0000 - val_accuracy: 0.9431 - val_precision: 0.9469 - val_recall: 0.9790 - val_auc: 0.9809 - val_prc: 0.9927\n",
      "Epoch 33/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1393 - tp: 31627.4146 - fp: 1709.5854 - tn: 8900.2927 - fn: 675.8293 - accuracy: 0.9450 - precision: 0.9495 - recall: 0.9791 - auc: 0.9819 - prc: 0.9931 - val_loss: 0.1406 - val_tp: 14688.0000 - val_fp: 791.0000 - val_tn: 4235.0000 - val_fn: 341.0000 - val_accuracy: 0.9436 - val_precision: 0.9489 - val_recall: 0.9773 - val_auc: 0.9816 - val_prc: 0.9931\n",
      "Epoch 34/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1395 - tp: 31601.1707 - fp: 1659.4146 - tn: 8972.4390 - fn: 680.0976 - accuracy: 0.9452 - precision: 0.9503 - recall: 0.9784 - auc: 0.9819 - prc: 0.9932 - val_loss: 0.1387 - val_tp: 14691.0000 - val_fp: 752.0000 - val_tn: 4274.0000 - val_fn: 338.0000 - val_accuracy: 0.9456 - val_precision: 0.9513 - val_recall: 0.9775 - val_auc: 0.9824 - val_prc: 0.9934\n",
      "Epoch 35/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1365 - tp: 31626.0732 - fp: 1642.8537 - tn: 8988.1707 - fn: 656.0244 - accuracy: 0.9469 - precision: 0.9512 - recall: 0.9797 - auc: 0.9827 - prc: 0.9935 - val_loss: 0.1366 - val_tp: 14679.0000 - val_fp: 718.0000 - val_tn: 4308.0000 - val_fn: 350.0000 - val_accuracy: 0.9467 - val_precision: 0.9534 - val_recall: 0.9767 - val_auc: 0.9829 - val_prc: 0.9936\n",
      "Epoch 36/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1340 - tp: 31627.9268 - fp: 1637.1707 - tn: 9036.8293 - fn: 611.1951 - accuracy: 0.9474 - precision: 0.9504 - recall: 0.9812 - auc: 0.9837 - prc: 0.9939 - val_loss: 0.1361 - val_tp: 14717.0000 - val_fp: 808.0000 - val_tn: 4218.0000 - val_fn: 312.0000 - val_accuracy: 0.9442 - val_precision: 0.9480 - val_recall: 0.9792 - val_auc: 0.9831 - val_prc: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1334 - tp: 31668.1220 - fp: 1665.1951 - tn: 8983.5122 - fn: 596.2927 - accuracy: 0.9464 - precision: 0.9488 - recall: 0.9817 - auc: 0.9839 - prc: 0.9940 - val_loss: 0.1324 - val_tp: 14693.0000 - val_fp: 724.0000 - val_tn: 4302.0000 - val_fn: 336.0000 - val_accuracy: 0.9471 - val_precision: 0.9530 - val_recall: 0.9776 - val_auc: 0.9842 - val_prc: 0.9942\n",
      "Epoch 38/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1282 - tp: 31673.3415 - fp: 1572.2683 - tn: 9047.0244 - fn: 620.4878 - accuracy: 0.9493 - precision: 0.9534 - recall: 0.9805 - auc: 0.9852 - prc: 0.9944 - val_loss: 0.1329 - val_tp: 14684.0000 - val_fp: 794.0000 - val_tn: 4232.0000 - val_fn: 345.0000 - val_accuracy: 0.9432 - val_precision: 0.9487 - val_recall: 0.9770 - val_auc: 0.9840 - val_prc: 0.9941\n",
      "Epoch 39/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1269 - tp: 31709.5854 - fp: 1579.5122 - tn: 9053.0000 - fn: 571.0244 - accuracy: 0.9500 - precision: 0.9522 - recall: 0.9827 - auc: 0.9853 - prc: 0.9945 - val_loss: 0.1354 - val_tp: 14642.0000 - val_fp: 538.0000 - val_tn: 4488.0000 - val_fn: 387.0000 - val_accuracy: 0.9539 - val_precision: 0.9646 - val_recall: 0.9742 - val_auc: 0.9836 - val_prc: 0.9937\n",
      "Epoch 40/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1264 - tp: 31753.9512 - fp: 1504.0976 - tn: 9099.7317 - fn: 555.3415 - accuracy: 0.9520 - precision: 0.9558 - recall: 0.9817 - auc: 0.9850 - prc: 0.9943 - val_loss: 0.1282 - val_tp: 14873.0000 - val_fp: 866.0000 - val_tn: 4160.0000 - val_fn: 156.0000 - val_accuracy: 0.9490 - val_precision: 0.9450 - val_recall: 0.9896 - val_auc: 0.9854 - val_prc: 0.9947\n",
      "Epoch 41/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1238 - tp: 31992.7073 - fp: 1602.0488 - tn: 8965.9512 - fn: 352.4146 - accuracy: 0.9542 - precision: 0.9514 - recall: 0.9899 - auc: 0.9858 - prc: 0.9947 - val_loss: 0.1307 - val_tp: 14770.0000 - val_fp: 578.0000 - val_tn: 4448.0000 - val_fn: 259.0000 - val_accuracy: 0.9583 - val_precision: 0.9623 - val_recall: 0.9828 - val_auc: 0.9848 - val_prc: 0.9943\n",
      "Epoch 42/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1248 - tp: 31869.0976 - fp: 1521.4878 - tn: 9116.0000 - fn: 406.5366 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9869 - auc: 0.9855 - prc: 0.9946 - val_loss: 0.1276 - val_tp: 14853.0000 - val_fp: 838.0000 - val_tn: 4188.0000 - val_fn: 176.0000 - val_accuracy: 0.9494 - val_precision: 0.9466 - val_recall: 0.9883 - val_auc: 0.9854 - val_prc: 0.9947\n",
      "Epoch 43/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1212 - tp: 31917.6585 - fp: 1550.2927 - tn: 9086.7561 - fn: 358.4146 - accuracy: 0.9552 - precision: 0.9531 - recall: 0.9890 - auc: 0.9869 - prc: 0.9951 - val_loss: 0.1201 - val_tp: 14852.0000 - val_fp: 689.0000 - val_tn: 4337.0000 - val_fn: 177.0000 - val_accuracy: 0.9568 - val_precision: 0.9557 - val_recall: 0.9882 - val_auc: 0.9872 - val_prc: 0.9953\n",
      "Epoch 44/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1207 - tp: 31907.1220 - fp: 1544.7805 - tn: 9088.6341 - fn: 372.5854 - accuracy: 0.9547 - precision: 0.9532 - recall: 0.9883 - auc: 0.9868 - prc: 0.9951 - val_loss: 0.1202 - val_tp: 14831.0000 - val_fp: 711.0000 - val_tn: 4315.0000 - val_fn: 198.0000 - val_accuracy: 0.9547 - val_precision: 0.9543 - val_recall: 0.9868 - val_auc: 0.9870 - val_prc: 0.9953\n",
      "Epoch 45/500\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.1185 - tp: 31933.4634 - fp: 1520.9756 - tn: 9131.9268 - fn: 326.7561 - accuracy: 0.9565 - precision: 0.9538 - recall: 0.9900 - auc: 0.9874 - prc: 0.9953 - val_loss: 0.1237 - val_tp: 14823.0000 - val_fp: 788.0000 - val_tn: 4238.0000 - val_fn: 206.0000 - val_accuracy: 0.9504 - val_precision: 0.9495 - val_recall: 0.9863 - val_auc: 0.9865 - val_prc: 0.9952\n",
      "Epoch 46/500\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.1159 - tp: 31921.3659 - fp: 1455.4390 - tn: 9202.8537 - fn: 333.4634 - accuracy: 0.9580 - precision: 0.9558 - recall: 0.9898 - auc: 0.9880 - prc: 0.9956 - val_loss: 0.1149 - val_tp: 14851.0000 - val_fp: 648.0000 - val_tn: 4378.0000 - val_fn: 178.0000 - val_accuracy: 0.9588 - val_precision: 0.9582 - val_recall: 0.9882 - val_auc: 0.9884 - val_prc: 0.9957\n",
      "Epoch 47/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1101 - tp: 31957.8049 - fp: 1407.8049 - tn: 9217.1707 - fn: 330.3415 - accuracy: 0.9598 - precision: 0.9582 - recall: 0.9897 - auc: 0.9896 - prc: 0.9962 - val_loss: 0.1207 - val_tp: 14873.0000 - val_fp: 826.0000 - val_tn: 4200.0000 - val_fn: 156.0000 - val_accuracy: 0.9510 - val_precision: 0.9474 - val_recall: 0.9896 - val_auc: 0.9873 - val_prc: 0.9954\n",
      "Epoch 48/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1160 - tp: 31930.3659 - fp: 1498.7805 - tn: 9154.0732 - fn: 329.9024 - accuracy: 0.9566 - precision: 0.9541 - recall: 0.9899 - auc: 0.9878 - prc: 0.9955 - val_loss: 0.1128 - val_tp: 14851.0000 - val_fp: 614.0000 - val_tn: 4412.0000 - val_fn: 178.0000 - val_accuracy: 0.9605 - val_precision: 0.9603 - val_recall: 0.9882 - val_auc: 0.9886 - val_prc: 0.9958\n",
      "Epoch 49/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1117 - tp: 31938.8537 - fp: 1399.4146 - tn: 9236.9024 - fn: 337.9512 - accuracy: 0.9592 - precision: 0.9572 - recall: 0.9899 - auc: 0.9887 - prc: 0.9957 - val_loss: 0.1140 - val_tp: 14894.0000 - val_fp: 787.0000 - val_tn: 4239.0000 - val_fn: 135.0000 - val_accuracy: 0.9540 - val_precision: 0.9498 - val_recall: 0.9910 - val_auc: 0.9892 - val_prc: 0.9961\n",
      "Epoch 50/500\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.1105 - tp: 31896.4146 - fp: 1433.6585 - tn: 9284.5122 - fn: 298.5366 - accuracy: 0.9585 - precision: 0.9552 - recall: 0.9911 - auc: 0.9892 - prc: 0.9958 - val_loss: 0.1108 - val_tp: 14882.0000 - val_fp: 739.0000 - val_tn: 4287.0000 - val_fn: 147.0000 - val_accuracy: 0.9558 - val_precision: 0.9527 - val_recall: 0.9902 - val_auc: 0.9897 - val_prc: 0.9962\n",
      "Epoch 51/500\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.1125 - tp: 31907.8293 - fp: 1477.3171 - tn: 9188.7561 - fn: 339.2195 - accuracy: 0.9571 - precision: 0.9548 - recall: 0.9898 - auc: 0.9886 - prc: 0.9957 - val_loss: 0.1097 - val_tp: 14864.0000 - val_fp: 642.0000 - val_tn: 4384.0000 - val_fn: 165.0000 - val_accuracy: 0.9598 - val_precision: 0.9586 - val_recall: 0.9890 - val_auc: 0.9893 - val_prc: 0.9960\n",
      "Epoch 52/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1050 - tp: 31936.2683 - fp: 1337.0000 - tn: 9314.1463 - fn: 325.7073 - accuracy: 0.9606 - precision: 0.9591 - recall: 0.9897 - auc: 0.9905 - prc: 0.9964 - val_loss: 0.1067 - val_tp: 14868.0000 - val_fp: 612.0000 - val_tn: 4414.0000 - val_fn: 161.0000 - val_accuracy: 0.9615 - val_precision: 0.9605 - val_recall: 0.9893 - val_auc: 0.9901 - val_prc: 0.9963\n",
      "Epoch 53/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1028 - tp: 31971.2683 - fp: 1302.3902 - tn: 9323.8537 - fn: 315.6098 - accuracy: 0.9627 - precision: 0.9616 - recall: 0.9900 - auc: 0.9906 - prc: 0.9965 - val_loss: 0.1131 - val_tp: 14871.0000 - val_fp: 774.0000 - val_tn: 4252.0000 - val_fn: 158.0000 - val_accuracy: 0.9535 - val_precision: 0.9505 - val_recall: 0.9895 - val_auc: 0.9894 - val_prc: 0.9962\n",
      "Epoch 54/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1049 - tp: 31987.3171 - fp: 1360.7317 - tn: 9248.6341 - fn: 316.4390 - accuracy: 0.9602 - precision: 0.9581 - recall: 0.9904 - auc: 0.9905 - prc: 0.9965 - val_loss: 0.1051 - val_tp: 14861.0000 - val_fp: 554.0000 - val_tn: 4472.0000 - val_fn: 168.0000 - val_accuracy: 0.9640 - val_precision: 0.9641 - val_recall: 0.9888 - val_auc: 0.9903 - val_prc: 0.9964\n",
      "Epoch 55/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.1047 - tp: 31958.0000 - fp: 1268.9024 - tn: 9363.1707 - fn: 323.0488 - accuracy: 0.9631 - precision: 0.9623 - recall: 0.9897 - auc: 0.9902 - prc: 0.9964 - val_loss: 0.1026 - val_tp: 14880.0000 - val_fp: 605.0000 - val_tn: 4421.0000 - val_fn: 149.0000 - val_accuracy: 0.9624 - val_precision: 0.9609 - val_recall: 0.9901 - val_auc: 0.9909 - val_prc: 0.9966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1014 - tp: 31978.1220 - fp: 1271.0000 - tn: 9339.1951 - fn: 324.8049 - accuracy: 0.9624 - precision: 0.9612 - recall: 0.9899 - auc: 0.9909 - prc: 0.9965 - val_loss: 0.1011 - val_tp: 14886.0000 - val_fp: 616.0000 - val_tn: 4410.0000 - val_fn: 143.0000 - val_accuracy: 0.9622 - val_precision: 0.9603 - val_recall: 0.9905 - val_auc: 0.9914 - val_prc: 0.9968\n",
      "Epoch 57/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0971 - tp: 31970.4146 - fp: 1212.5122 - tn: 9402.8537 - fn: 327.3415 - accuracy: 0.9647 - precision: 0.9641 - recall: 0.9900 - auc: 0.9920 - prc: 0.9969 - val_loss: 0.1007 - val_tp: 14854.0000 - val_fp: 528.0000 - val_tn: 4498.0000 - val_fn: 175.0000 - val_accuracy: 0.9649 - val_precision: 0.9657 - val_recall: 0.9884 - val_auc: 0.9916 - val_prc: 0.9969\n",
      "Epoch 58/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.1006 - tp: 31927.4390 - fp: 1235.6829 - tn: 9387.0244 - fn: 362.9756 - accuracy: 0.9634 - precision: 0.9635 - recall: 0.9890 - auc: 0.9909 - prc: 0.9967 - val_loss: 0.0995 - val_tp: 14786.0000 - val_fp: 452.0000 - val_tn: 4574.0000 - val_fn: 243.0000 - val_accuracy: 0.9653 - val_precision: 0.9703 - val_recall: 0.9838 - val_auc: 0.9915 - val_prc: 0.9968\n",
      "Epoch 59/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0978 - tp: 31870.5122 - fp: 1144.1707 - tn: 9474.6829 - fn: 423.7561 - accuracy: 0.9634 - precision: 0.9656 - recall: 0.9863 - auc: 0.9916 - prc: 0.9968 - val_loss: 0.0968 - val_tp: 14833.0000 - val_fp: 542.0000 - val_tn: 4484.0000 - val_fn: 196.0000 - val_accuracy: 0.9632 - val_precision: 0.9647 - val_recall: 0.9870 - val_auc: 0.9922 - val_prc: 0.9971\n",
      "Epoch 60/500\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0990 - tp: 31908.3902 - fp: 1143.7805 - tn: 9431.0244 - fn: 429.9268 - accuracy: 0.9639 - precision: 0.9663 - recall: 0.9866 - auc: 0.9912 - prc: 0.9967 - val_loss: 0.1022 - val_tp: 14832.0000 - val_fp: 636.0000 - val_tn: 4390.0000 - val_fn: 197.0000 - val_accuracy: 0.9585 - val_precision: 0.9589 - val_recall: 0.9869 - val_auc: 0.9914 - val_prc: 0.9969\n",
      "Epoch 61/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0974 - tp: 31911.7561 - fp: 1167.7805 - tn: 9442.3659 - fn: 391.2195 - accuracy: 0.9629 - precision: 0.9639 - recall: 0.9879 - auc: 0.9916 - prc: 0.9969 - val_loss: 0.0990 - val_tp: 14847.0000 - val_fp: 631.0000 - val_tn: 4395.0000 - val_fn: 182.0000 - val_accuracy: 0.9595 - val_precision: 0.9592 - val_recall: 0.9879 - val_auc: 0.9921 - val_prc: 0.9971\n",
      "Epoch 62/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0937 - tp: 31939.2683 - fp: 1095.6098 - tn: 9504.2927 - fn: 373.9512 - accuracy: 0.9654 - precision: 0.9661 - recall: 0.9888 - auc: 0.9923 - prc: 0.9971 - val_loss: 0.0954 - val_tp: 14809.0000 - val_fp: 515.0000 - val_tn: 4511.0000 - val_fn: 220.0000 - val_accuracy: 0.9634 - val_precision: 0.9664 - val_recall: 0.9854 - val_auc: 0.9924 - val_prc: 0.9972\n",
      "Epoch 63/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0928 - tp: 31917.0732 - fp: 1070.5610 - tn: 9530.2683 - fn: 395.2195 - accuracy: 0.9660 - precision: 0.9680 - recall: 0.9875 - auc: 0.9926 - prc: 0.9972 - val_loss: 0.0944 - val_tp: 14880.0000 - val_fp: 599.0000 - val_tn: 4427.0000 - val_fn: 149.0000 - val_accuracy: 0.9627 - val_precision: 0.9613 - val_recall: 0.9901 - val_auc: 0.9931 - val_prc: 0.9975\n",
      "Epoch 64/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0889 - tp: 31884.8537 - fp: 1027.8049 - tn: 9632.2927 - fn: 368.1707 - accuracy: 0.9674 - precision: 0.9687 - recall: 0.9886 - auc: 0.9936 - prc: 0.9976 - val_loss: 0.0937 - val_tp: 14823.0000 - val_fp: 467.0000 - val_tn: 4559.0000 - val_fn: 206.0000 - val_accuracy: 0.9664 - val_precision: 0.9695 - val_recall: 0.9863 - val_auc: 0.9927 - val_prc: 0.9973\n",
      "Epoch 65/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0909 - tp: 31915.8537 - fp: 1032.0732 - tn: 9585.6585 - fn: 379.5366 - accuracy: 0.9674 - precision: 0.9690 - recall: 0.9883 - auc: 0.9928 - prc: 0.9973 - val_loss: 0.0952 - val_tp: 14902.0000 - val_fp: 660.0000 - val_tn: 4366.0000 - val_fn: 127.0000 - val_accuracy: 0.9608 - val_precision: 0.9576 - val_recall: 0.9915 - val_auc: 0.9933 - val_prc: 0.9976\n",
      "Epoch 66/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0929 - tp: 31957.2683 - fp: 1062.8293 - tn: 9519.4878 - fn: 373.5366 - accuracy: 0.9657 - precision: 0.9664 - recall: 0.9889 - auc: 0.9925 - prc: 0.9972 - val_loss: 0.1010 - val_tp: 14873.0000 - val_fp: 685.0000 - val_tn: 4341.0000 - val_fn: 156.0000 - val_accuracy: 0.9581 - val_precision: 0.9560 - val_recall: 0.9896 - val_auc: 0.9921 - val_prc: 0.9972\n",
      "Epoch 67/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0914 - tp: 31874.8537 - fp: 1051.6585 - tn: 9617.1463 - fn: 369.4634 - accuracy: 0.9662 - precision: 0.9670 - recall: 0.9886 - auc: 0.9929 - prc: 0.9974 - val_loss: 0.0898 - val_tp: 14836.0000 - val_fp: 480.0000 - val_tn: 4546.0000 - val_fn: 193.0000 - val_accuracy: 0.9664 - val_precision: 0.9687 - val_recall: 0.9872 - val_auc: 0.9933 - val_prc: 0.9975\n",
      "Epoch 68/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0876 - tp: 31939.0000 - fp: 1044.4146 - tn: 9566.7805 - fn: 362.9268 - accuracy: 0.9674 - precision: 0.9682 - recall: 0.9893 - auc: 0.9934 - prc: 0.9975 - val_loss: 0.0908 - val_tp: 14880.0000 - val_fp: 557.0000 - val_tn: 4469.0000 - val_fn: 149.0000 - val_accuracy: 0.9648 - val_precision: 0.9639 - val_recall: 0.9901 - val_auc: 0.9934 - val_prc: 0.9976\n",
      "Epoch 69/500\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.0869 - tp: 31960.9512 - fp: 1020.9268 - tn: 9567.5854 - fn: 363.6585 - accuracy: 0.9681 - precision: 0.9691 - recall: 0.9892 - auc: 0.9936 - prc: 0.9976 - val_loss: 0.0898 - val_tp: 14774.0000 - val_fp: 384.0000 - val_tn: 4642.0000 - val_fn: 255.0000 - val_accuracy: 0.9681 - val_precision: 0.9747 - val_recall: 0.9830 - val_auc: 0.9932 - val_prc: 0.9975\n",
      "Epoch 70/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0872 - tp: 31887.6585 - fp: 968.4634 - tn: 9672.3171 - fn: 384.6829 - accuracy: 0.9685 - precision: 0.9711 - recall: 0.9876 - auc: 0.9933 - prc: 0.9974 - val_loss: 0.0875 - val_tp: 14805.0000 - val_fp: 415.0000 - val_tn: 4611.0000 - val_fn: 224.0000 - val_accuracy: 0.9681 - val_precision: 0.9727 - val_recall: 0.9851 - val_auc: 0.9937 - val_prc: 0.9977\n",
      "Epoch 71/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0871 - tp: 31922.4634 - fp: 963.3659 - tn: 9665.9268 - fn: 361.3659 - accuracy: 0.9691 - precision: 0.9709 - recall: 0.9886 - auc: 0.9934 - prc: 0.9975 - val_loss: 0.0866 - val_tp: 14809.0000 - val_fp: 390.0000 - val_tn: 4636.0000 - val_fn: 220.0000 - val_accuracy: 0.9696 - val_precision: 0.9743 - val_recall: 0.9854 - val_auc: 0.9939 - val_prc: 0.9978\n",
      "Epoch 72/500\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0844 - tp: 31881.9512 - fp: 926.2927 - tn: 9721.0000 - fn: 383.8780 - accuracy: 0.9698 - precision: 0.9727 - recall: 0.9876 - auc: 0.9942 - prc: 0.9979 - val_loss: 0.0868 - val_tp: 14841.0000 - val_fp: 450.0000 - val_tn: 4576.0000 - val_fn: 188.0000 - val_accuracy: 0.9682 - val_precision: 0.9706 - val_recall: 0.9875 - val_auc: 0.9938 - val_prc: 0.9978\n",
      "Epoch 73/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0867 - tp: 31896.0976 - fp: 941.6098 - tn: 9675.7805 - fn: 399.6341 - accuracy: 0.9694 - precision: 0.9725 - recall: 0.9873 - auc: 0.9934 - prc: 0.9975 - val_loss: 0.0856 - val_tp: 14815.0000 - val_fp: 408.0000 - val_tn: 4618.0000 - val_fn: 214.0000 - val_accuracy: 0.9690 - val_precision: 0.9732 - val_recall: 0.9858 - val_auc: 0.9939 - val_prc: 0.9977\n",
      "Epoch 74/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0827 - tp: 31921.1463 - fp: 900.4390 - tn: 9713.9756 - fn: 377.5610 - accuracy: 0.9704 - precision: 0.9728 - recall: 0.9884 - auc: 0.9940 - prc: 0.9978 - val_loss: 0.0885 - val_tp: 14732.0000 - val_fp: 334.0000 - val_tn: 4692.0000 - val_fn: 297.0000 - val_accuracy: 0.9685 - val_precision: 0.9778 - val_recall: 0.9802 - val_auc: 0.9938 - val_prc: 0.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0824 - tp: 31931.5610 - fp: 925.5366 - tn: 9687.0732 - fn: 368.9512 - accuracy: 0.9707 - precision: 0.9731 - recall: 0.9884 - auc: 0.9940 - prc: 0.9977 - val_loss: 0.0834 - val_tp: 14864.0000 - val_fp: 443.0000 - val_tn: 4583.0000 - val_fn: 165.0000 - val_accuracy: 0.9697 - val_precision: 0.9711 - val_recall: 0.9890 - val_auc: 0.9945 - val_prc: 0.9980\n",
      "Epoch 76/500\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0824 - tp: 31966.1463 - fp: 923.0976 - tn: 9680.8293 - fn: 343.0488 - accuracy: 0.9706 - precision: 0.9719 - recall: 0.9897 - auc: 0.9941 - prc: 0.9978 - val_loss: 0.0852 - val_tp: 14877.0000 - val_fp: 521.0000 - val_tn: 4505.0000 - val_fn: 152.0000 - val_accuracy: 0.9664 - val_precision: 0.9662 - val_recall: 0.9899 - val_auc: 0.9944 - val_prc: 0.9980\n",
      "Epoch 77/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0823 - tp: 31961.2683 - fp: 978.2195 - tn: 9623.7805 - fn: 349.8537 - accuracy: 0.9686 - precision: 0.9689 - recall: 0.9901 - auc: 0.9944 - prc: 0.9979 - val_loss: 0.0837 - val_tp: 14828.0000 - val_fp: 422.0000 - val_tn: 4604.0000 - val_fn: 201.0000 - val_accuracy: 0.9689 - val_precision: 0.9723 - val_recall: 0.9866 - val_auc: 0.9943 - val_prc: 0.9980\n",
      "Epoch 78/500\n",
      "40/40 [==============================] - 1s 20ms/step - loss: 0.0807 - tp: 31922.7073 - fp: 889.8049 - tn: 9727.1463 - fn: 373.4634 - accuracy: 0.9710 - precision: 0.9735 - recall: 0.9883 - auc: 0.9944 - prc: 0.9979 - val_loss: 0.0804 - val_tp: 14836.0000 - val_fp: 396.0000 - val_tn: 4630.0000 - val_fn: 193.0000 - val_accuracy: 0.9706 - val_precision: 0.9740 - val_recall: 0.9872 - val_auc: 0.9948 - val_prc: 0.9981\n",
      "Epoch 79/500\n",
      " 4/40 [==>...........................] - ETA: 0s - loss: 0.0809 - tp: 3765.2500 - fp: 111.0000 - tn: 1199.2500 - fn: 49.5000 - accuracy: 0.9693 - precision: 0.9730 - recall: 0.9861 - auc: 0.9945 - prc: 0.9978"
     ]
    }
   ],
   "source": [
    "model_name = 'cnn_model_kinect'\n",
    "#loss='sparse_categorical_crossentropy'\n",
    "#loss='categorical_crossentropy'\n",
    "#loss='binary_crossentropy'\n",
    "\n",
    "with mlflow.start_run(run_name=model_name) as run:\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    model = make_model(metrics=METRICS, \n",
    "                        loss='binary_crossentropy', \n",
    "                        optimizer=optimizer, \n",
    "                        learning_rate=learning_rate)\n",
    "    \n",
    "    with tf.device('/CPU:0'):\n",
    "        \n",
    "        history = model.fit(\n",
    "            x=X_train, \n",
    "            y=y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            shuffle=True, \n",
    "            epochs=EPOCHS, \n",
    "            verbose=1,\n",
    "            batch_size=BATCH_SIZE, \n",
    "            callbacks=[early_stopping])\n",
    "\n",
    "        # Plot training history\n",
    "        plot_loss(history, \"Bias\", 0)\n",
    "        plt.savefig(\"loss.jpg\")\n",
    "        #mlflow.log_artifact(\"loss.jpg\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot and log metrics\n",
    "        predictions_train = model.predict(X_train)\n",
    "        predictions_test = model.predict(X_test)\n",
    "\n",
    "        plot_metrics(history)\n",
    "        plt.savefig(\"metrics.jpg\")\n",
    "        #mlflow.log_artifact(\"metrics.jpg\")\n",
    "        plt.show()\n",
    "\n",
    "        # Confusion matrix\n",
    "        results = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=0)\n",
    "        for name, value in zip(model.metrics_names, results):\n",
    "            print(name, ': ', value, '/n')\n",
    "        plot_cm(y_test, predictions_test)\n",
    "        plt.savefig(\"cm.jpg\")\n",
    "        #mlflow.log_artifact(\"cm.jpg\")\n",
    "        plt.show()\n",
    "\n",
    "        # ROC Curve\n",
    "        plot_roc(\"Test Predictions\", y_test, predictions_test, color=colors[0], linestyle='--')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"roc.jpg\")\n",
    "        #mlflow.log_artifact(\"roc.jpg\")\n",
    "        plt.show()\n",
    "\n",
    "        # Precision-Recall Curve (PRC)\n",
    "        plot_prc(\"Train Predictions\", y_train, predictions_train, color=colors[0])\n",
    "        plot_prc(\"Test Predictions\", y_test, predictions_test, color=colors[0], linestyle='--')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"prc.jpg\")\n",
    "        #mlflow.log_artifact(\"prc.jpg\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Log model, scaler, model parameters to MLflow\n",
    "        #mlflow.log_param(\"units\", units)\n",
    "        #mlflow.log_param(\"activation\", activation)\n",
    "        #mlflow.log_param(\"kernel_initializer\", kernel_initializer)\n",
    "        #mlflow.log_param(\"output activation\", output_activation)\n",
    "        #mlflow.log_param(\"optimizer\", optimizer)\n",
    "        #mlflow.log_param(\"learning rate\", learning_rate)\n",
    "        #mlflow.log_param(\"batch size\", BATCH_SIZE)\n",
    "        #mlflow.log_metric(\"accuracy\", results[5])\n",
    "        #mlflow.log_metric(\"average precision score\", results[6])\n",
    "        #mlflow.log_metric(\"recall\", results[7])\n",
    "        #mlflow.log_metric(\"auc\", results[8])\n",
    "\n",
    "        #mlflow.keras.log_model(model, model_name, signature=signature)\n",
    "        #mlflow.sklearn.log_model(scaler, 'InputScaler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = \"runs:/{}/{}\".format(run.info.run_id, model_name)\n",
    "mv = mlflow.register_model(model_uri, model_name)\n",
    "print(\"Name: {}\".format(mv.name))\n",
    "print(\"Version: {}\".format(mv.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
