{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem A (Kinect)\n",
    "\n",
    "Section for configurations and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri('http://35.228.45.76:5000')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='../../keys/mlflow-312506-8cfad529f4fd.json'\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# Import data augmentation\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from augmentation.methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 47\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices( 'GPU' )\n",
    "print( 'Num GPUs Available: ', len( physical_devices ) )\n",
    "if len( physical_devices ) > 0:\n",
    "    tf.config.experimental.set_memory_growth( physical_devices[0], True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Kinect files and classify each sample into good or bad depending on the file name\n",
    "\n",
    "W is the start of file names containing a bad exercise, and all others file names are to be classified as good exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'https://raw.githubusercontent.com/digitacs/4dv652-ml/main/datasets/all_good_bad_videos/kinect_good_vs_bad_not_preprocessed/'\n",
    "\n",
    "good_videos = []\n",
    "bad_videos = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cut leading and trailing frames\n",
    "\n",
    "When loading the files, we'll use this method for removing leading and trailing frames from each data sample-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_start_scaler = mlflow.sklearn.load_model('gs://mlflow-atlas/mlflow_artifacts/0/14b3d62fe0ac449d98a19e883e57133c/artifacts/InputScaler')\n",
    "cut_start_model = mlflow.keras.load_model('gs://mlflow-atlas/mlflow_artifacts/0/14b3d62fe0ac449d98a19e883e57133c/artifacts/cut_start_kinect')\n",
    "\n",
    "cut_stop_scaler = mlflow.sklearn.load_model('gs://mlflow-atlas/mlflow_artifacts/0/550767846e1441389ca2c312d5b73355/artifacts/InputScaler')\n",
    "cut_stop_model = mlflow.keras.load_model('gs://mlflow-atlas/mlflow_artifacts/0/550767846e1441389ca2c312d5b73355/artifacts/cut_stop_kinect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_leading_trailing(data):\n",
    "    trimmed_data = data.copy()\n",
    "    scaled_data_start = cut_start_scaler.transform(data, copy=True)\n",
    "\n",
    "    # Remove start frames\n",
    "    predictions = cut_start_model.predict(scaled_data_start)\n",
    "    predictions = predictions.round().astype(int)\n",
    "    n = 0\n",
    "    drop = []\n",
    "    for pred in predictions:\n",
    "        if pred == 1:\n",
    "            drop.append(n)\n",
    "        else:\n",
    "            break\n",
    "        n = n + 1\n",
    "    try:\n",
    "        trimmed_data.drop(index=drop, inplace=True)\n",
    "    except:\n",
    "        print('Error trying to remove start frames')\n",
    "\n",
    "    # Remove stop frames\n",
    "    scaled_data_stop = cut_stop_scaler.transform(trimmed_data, copy=True)\n",
    "    predictions = cut_stop_model.predict(scaled_data_stop)\n",
    "    predictions = predictions.round().astype(int)\n",
    "\n",
    "    should_check = False\n",
    "    drop = []\n",
    "    for pred in predictions:\n",
    "        if pred == 1:\n",
    "            should_check = True\n",
    "        if should_check:\n",
    "            drop.append(n)\n",
    "        n = n + 1\n",
    "    try:\n",
    "        trimmed_data.drop(index=drop, inplace=True)\n",
    "    except:\n",
    "        print('Error trying to remove stop frames')\n",
    "\n",
    "    return trimmed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find file:  G67.csv\n",
      "Could not find file:  G70.csv\n",
      "(11427, 40)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file_path + 'A1.csv')\n",
    "df.drop(columns=['FrameNo'], inplace=True)\n",
    "df['quality'] = 1 # Good\n",
    "good_videos.append('A1.csv')\n",
    "\n",
    "numbers = ['01', '02', '03', '04', '05', '06', '07', '08', '09']\n",
    "\n",
    "for i in numbers:\n",
    "  try:\n",
    "    file_name = 'G{}.csv'.format(i)\n",
    "    temp = pd.read_csv(file_path +  file_name)\n",
    "    temp.drop(columns=['FrameNo'], inplace=True)\n",
    "    temp = cut_leading_trailing(temp)\n",
    "    temp['quality'] = 1 # Good\n",
    "    good_videos.append(file_name)\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "\n",
    "    file_name = 'W{}.csv'.format(i)\n",
    "    temp = pd.read_csv(file_path +  file_name)\n",
    "    temp.drop(columns=['FrameNo'], inplace=True)\n",
    "    temp = cut_leading_trailing(temp)\n",
    "    temp['quality'] = 0 # Bad\n",
    "    bad_videos.append(file_name)\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "  except IOError as e:\n",
    "    print('Could not find file: ', file_name)\n",
    "\n",
    "for i in range(20, 83):\n",
    "  try:\n",
    "    file_name = 'G{}.csv'.format(i)\n",
    "    temp = pd.read_csv(file_path +  file_name)\n",
    "    temp.drop(columns=['FrameNo'], inplace=True)\n",
    "    temp = cut_leading_trailing(temp)\n",
    "    temp['quality'] = 1 # Good\n",
    "    good_videos.append(file_name)\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "  except IOError as e:\n",
    "    print('Could not find file: ', file_name)\n",
    "\n",
    "for i in range(10, 44):\n",
    "  try:\n",
    "    file_name = 'W{}.csv'.format(i)\n",
    "    temp = pd.read_csv(file_path +  file_name)\n",
    "    temp.drop(columns=['FrameNo'], inplace=True)\n",
    "    temp = cut_leading_trailing(temp)\n",
    "    temp['quality'] = 0 # Bad\n",
    "    bad_videos.append(file_name)\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "  except IOError as e:\n",
    "    print('Could not find file: ', file_name)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check class imbalance\n",
    "\n",
    "To see if we need to use any dataset imbalanced techniques. We do not consider that there's a need for that in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos:  114\n",
      "Good videos: 71\n",
      "Bad videos: 43\n"
     ]
    }
   ],
   "source": [
    "print('Total videos: ', len(good_videos + bad_videos))\n",
    "print('Good videos:', len(good_videos))\n",
    "print('Bad videos:', len(bad_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 11427\n",
      "\n",
      "Good: 8586 (0.75% of total)\n",
      "Bad: 2841 (0.25% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gc = df.groupby(['quality']).size()\n",
    "print(\n",
    "    'Total: {}\\n\\nGood: {} ({:.2f}% of total)\\nBad: {} ({:.2f}% of total)\\n'\n",
    "    .format(\n",
    "      len(df), \n",
    "      df_gc[1],\n",
    "      df_gc[1] / len(df),\n",
    "      df_gc[0],\n",
    "      df_gc[0] / len(df)\n",
    "    )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation\n",
    "\n",
    "### Mirror X coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22854, 40)\n"
     ]
    }
   ],
   "source": [
    "df = mirror(df,'x', append=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch by 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45708, 40)\n"
     ]
    }
   ],
   "source": [
    "df_temp = augMultiplier(df.drop(columns=['quality']), multiplier=1.5)\n",
    "df_temp['quality'] = df['quality']\n",
    "df = df.append(df_temp, ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress by 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91416, 40)\n"
     ]
    }
   ],
   "source": [
    "df_temp = augMultiplier(df.drop(columns=['quality']), multiplier=0.25)\n",
    "df_temp['quality'] = df['quality']\n",
    "df = df.append(df_temp, ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate by p/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101416, 40)\n"
     ]
    }
   ],
   "source": [
    "samples = df.sample(5000)\n",
    "\n",
    "angle = 3.1415 / 7\n",
    "samples_rotated = rotate(samples.drop(columns=['quality']), angle=angle, posenet=False)\n",
    "samples_rotated['quality'] = samples['quality'].append(samples['quality'], ignore_index=True)\n",
    "df = df.append(samples_rotated, ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate by -p/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111416, 40)\n"
     ]
    }
   ],
   "source": [
    "samples = df.sample(5000)\n",
    "\n",
    "angle = 3.1415 / -9\n",
    "samples_rotated = rotate(samples.drop(columns=['quality']), angle=angle, posenet=False)\n",
    "samples_rotated['quality'] = samples['quality'].append(samples['quality'], ignore_index=True)\n",
    "df = df.append(samples_rotated, ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save as New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../datasets/all_good_bad_problemA_kinect/good_bad_kinect.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
